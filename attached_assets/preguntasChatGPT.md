## Caso de estudio: Monitoreo de trabajos en Azure Machine Learning

---

## Pregunta 1

**Tipo:** Selecci√≥n √∫nica  
**Pregunta:**  
You need to monitor your jobs for training.  
**Solution:** From the *Monitor* tab in the Azure portal, you select *Diagnostic settings*, then select *+Add diagnostic setting* and, under *Category details*, you select `AmlRunStatusChangedEvent`, before configuring it to send to an Azure ML service workspace.  
**Does this solution meet the goal?**

- [x] Yes
- [ ] No

**Respuesta Correcta:** ‚úÖ Yes

**Explicaci√≥n:**  
Esta soluci√≥n es v√°lida. La manera correcta de habilitar el monitoreo de trabajos en Azure ML es a trav√©s del portal de Azure, usando el panel de *Monitor*. All√≠ se configuran las *diagnostic settings* con la categor√≠a `AmlRunStatusChangedEvent` para enviar los eventos a un *Log Analytics Workspace*. Esto permite visualizar el estado de los trabajos, alertas y errores del entrenamiento.

üìö **Referencia oficial:**  
[Monitor and analyze jobs in Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-monitor-view-training-log)

---

## Pregunta 2

**Tipo:** Selecci√≥n √∫nica  
**Pregunta:**  
You need to monitor your jobs for training.  
**Solution:** In the Azure portal, you create a *New alert rule* and receive the job status by email notification, by selecting the *Monitor* tab.  
**Does this solution meet the goal?**

- [ ] Yes
- [x] No

**Respuesta Correcta:** ‚ùå No

**Explicaci√≥n:**  
Aunque crear una alerta por correo electr√≥nico puede notificar cambios en estado, **no es suficiente para monitorear trabajos de entrenamiento** en Azure ML de forma integral. Esta soluci√≥n no permite el an√°lisis detallado de m√©tricas, logs ni visualizaci√≥n completa de eventos. El enfoque correcto es usar *diagnostic settings* con `AmlRunStatusChangedEvent`.

---

## Pregunta 3

**Tipo:** Selecci√≥n √∫nica  
**Pregunta:**  
You need to create a compute instance that would support running ML pipeline training using the Azure Machine Learning designer v2.  
**Solution:** You create a **Machine Learning compute cluster**.  
**Does this solution meet the goal?**

- [x] Yes
- [ ] No

**Respuesta Correcta:** ‚úÖ Yes

**Explicaci√≥n:**  
Los *Machine Learning compute clusters* son la infraestructura ideal para ejecutar pipelines dentro del Designer v2 en Azure Machine Learning. Son escalables y est√°n dise√±ados para trabajos de entrenamiento en lote o en flujo.

üìö **Referencia oficial:**  
[Azure ML Compute Targets](https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target)

---

## Pregunta 4

**Tipo:** Selecci√≥n √∫nica  
**Pregunta:**  
You need to create a compute instance that would support running ML pipeline training using the Azure Machine Learning designer v2.  
**Solution:** You create an **Azure Databricks environment**.  
**Does this solution meet the goal?**

- [ ] Yes
- [x] No

**Respuesta Correcta:** ‚ùå No

**Explicaci√≥n:**  
Azure Databricks puede integrarse con Azure ML pipelines, pero **no se puede usar directamente en Designer v2 como target de entrenamiento**. Databricks es m√°s adecuado para procesamiento distribuido con Spark.

üìö **Referencia oficial:**  
[What is Designer (v2) in Azure ML?](https://learn.microsoft.com/en-us/azure/machine-learning/concept-designer-overview)

---

## Pregunta 5

**Tipo:** Selecci√≥n √∫nica  
**Pregunta:**  
You need to create a compute instance that would support running ML pipeline training using the Azure Machine Learning designer v2.  
**Solution:** You create an **Azure HDInsight environment**.  
**Does this solution meet the goal?**

- [ ] Yes
- [x] No

**Respuesta Correcta:** ‚ùå No

**Explicaci√≥n:**  
HDInsight, al igual que Databricks, se basa en Apache Spark y puede ejecutar trabajos ML, pero **no es compatible como destino directo dentro de Azure ML Designer**. Designer requiere clusters de entrenamiento dedicados como *AML compute clusters*.

üìö **Referencia oficial:**  
[Configure and submit training jobs](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-train-cli)

---

## Caso de estudio: Seguimiento de m√©tricas y ejecuci√≥n de trabajos en Azure Machine Learning

---

## Pregunta 6

**Tipo:** Selecci√≥n √∫nica  
**Pregunta:**  
You need to monitor your jobs for training.  
**Solution:** You enable autologging by adding `mlflow.autolog()` in your code and subsequently view the metrics using the code shown below:

```python
import mlflow
run = mlflow.get_run("<RUN_ID>")
metrics = run.data.metrics
params = run.data.params
tags = run.data.tags
print(metrics, params, tags)
```

**Does this solution meet the goal?**

- [x] Yes  
- [ ] No

**Respuesta Correcta:** ‚úÖ Yes

**Explicaci√≥n:**  
La funci√≥n `mlflow.autolog()` permite capturar autom√°ticamente m√©tricas, par√°metros y artefactos de los entrenamientos sin necesidad de definirlos manualmente. Es ideal cuando trabajas con frameworks compatibles (como scikit-learn, TensorFlow, etc.). La informaci√≥n se puede consultar v√≠a c√≥digo o en el portal de Azure ML.

üìö [Referencia oficial - Track experiments and models with MLflow](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-log-view-metrics)

---

## Pregunta 7

**Tipo:** Selecci√≥n √∫nica  
**Pregunta:**  
You need to log metrics data from your job runs using MLflow.  
**Solution:** You use the `mlflow.log_metric()` MLflow API method.  
**Does this solution meet the goal?**

- [ ] No  
- [x] Yes

**Respuesta Correcta:** ‚úÖ Yes

**Explicaci√≥n:**  
La funci√≥n `mlflow.log_metric()` es la forma correcta de registrar m√©tricas como accuracy, p√©rdida, etc. Este m√©todo toma como argumentos el nombre de la m√©trica y su valor, y puede usarse varias veces para capturar la evoluci√≥n de una m√©trica a lo largo del entrenamiento.

üìö [Referencia oficial - Log metrics with MLflow](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_metric)

---

## Pregunta 8

**Tipo:** Selecci√≥n √∫nica  
**Pregunta:**  
You need to log data from your job runs using MLflow.  
**Solution:** Use the `Run.log()` Azure ML SDK method.  
**Does this solution meet the goal?**

- [x] No  
- [ ] Yes

**Respuesta Correcta:** ‚ùå No

**Explicaci√≥n:**  
`Run.log()` pertenece al SDK de Azure ML, no a MLflow. Aunque permite registrar informaci√≥n como artefactos, no es la herramienta adecuada cuando se usa MLflow como motor de tracking de m√©tricas. Por tanto, **no cumple el objetivo** de esta pregunta.

üìö [Referencia oficial - Azure ML SDK Run Class](https://learn.microsoft.com/en-us/python/api/azureml-core/azureml.core.run)

---

## Pregunta 9

**Tipo:** Selecci√≥n √∫nica  
**Pregunta:**  
You need to log data from your job runs using MLflow.  
**Solution:** Use the `mlflow.log_param()` MLflow API method.  
**Does this solution meet the goal?**

- [x] No  
- [ ] Yes

**Respuesta Correcta:** ‚ùå No

**Explicaci√≥n:**  
El m√©todo `mlflow.log_param()` sirve para registrar par√°metros (como hiperpar√°metros), no m√©tricas. Dado que la pregunta exige loguear m√©tricas, esta opci√≥n **no es v√°lida**.

üìö [Referencia oficial - Track experiments and models with MLflow](https://mlflow.org/docs/latest/tracking.html#logging-data-to-runs)

---

---

## Pregunta 10

**Tipo:** Selecci√≥n √∫nica  
**Pregunta:**  
You want to perform real-time scoring of the ML model and to deploy and debug locally by using local endpoints.  
You need to create a deployment named `mydep` under the local endpoint.  
**Solution:** You use Azure CLI version >= 2.38.0 to set up the local endpoints using the following commands:

```bash
az ml online-endpoint create --local -n $ENDPOINT_NAME -f endpoints/online/managed/sample/endpoint.yml

az ml online-deployment create --local -n mydep --endpoint $ENDPOINT_NAME -f endpoints/online/managed/sample/blue-deployment.yml
```

**Does this solution meet the goal?**  
- [x] Yes  
- [ ] No  

**Respuesta Correcta:** ‚úÖ Yes  
**Explicaci√≥n:**  
La soluci√≥n cumple el objetivo. Azure CLI >=2.38.0 permite crear endpoints locales y realizar despliegues con el flag `--local`, que usa el entorno Docker para pruebas locales. Se usan archivos YAML para definir los endpoints y despliegues.  

üìö Referencia: [Install and set up the CLI (v2)](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-local-endpoints-cli?view=azureml-api-2)

---

## Pregunta 11

**Tipo:** Selecci√≥n √∫nica  
**Pregunta:**  
You want to perform real-time scoring of the ML model and to deploy and debug locally by using local endpoints.  
You need to create a deployment named `mydep` under the local endpoint.  
**Solution:** You use Azure ML Python SDK v2 with the following:

```python
ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)

ml_client.online_deployments.begin_create_or_update(
    deployment=mydep,
    local=True
)
```

**Does this solution meet the goal?**  
- [x] Yes  
- [ ] No  

**Respuesta Correcta:** ‚úÖ Yes  
**Explicaci√≥n:**  
El SDK v2 de Azure ML permite la creaci√≥n y prueba de endpoints locales con el par√°metro `local=True`, ejecutando en un entorno Docker. `ml_client` gestiona recursos como endpoints, trabajos y despliegues.  

üìö Referencia: [MLClient Class](https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.mlclient)

---

## Pregunta 13

**Tipo:** Selecci√≥n √∫nica  
**Pregunta:**  
You want to perform real-time scoring of the ML model and to deploy and debug locally by using local endpoints.  
You need to create a deployment named `mydep` under the local endpoint.  
**Solution:** You use Azure ML Studio to set up and deploy `mydep` to the local endpoint.

**Does this solution meet the goal?**  
- [ ] Yes  
- [x] No  

**Respuesta Correcta:** ‚ùå No  
**Explicaci√≥n:**  
Azure ML Studio no permite configurar ni desplegar endpoints locales. Para hacerlo, se debe usar Azure CLI v2 o Azure ML Python SDK v2.  

üìö Referencia: [Deploy and score a machine learning model by using an online endpoint](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-local-endpoints-cli)

---
## Pregunta 12

Tipo:** Selecci√≥n √∫nica  
**Pregunta:**  
You want to implement a scalable and maintainable solution to automate the retraining of an image classification model using MLOps.  
**Solution:** You use Azure Data Factory.

**Does this solution meet the goal?**  
- [x] Yes  
- [ ] No  

**Respuesta Correcta:** ‚úÖ Yes  
**Explicaci√≥n:**  
Azure Data Factory permite crear pipelines que integran, transforman y disparan el reentrenamiento autom√°ticamente ante cambios en la base de datos. Es ideal para escenarios MLOps con grandes vol√∫menes de datos.  

üìö Referencia: [Retraining and Updating Azure ML models with Azure Data Factory](https://learn.microsoft.com/en-us/azure/machine-learning/tutorial-adf-ml-pipelines)

---


---

## ‚ùì Pregunta 1

**Contexto**: Tu organizaci√≥n usa Azure Machine Learning (ML). Necesitas registrar un modelo personalizado que combina varios elementos de diferentes frameworks.

**Pregunta**: ¬øQu√© deber√≠as usar para registrar el modelo?

**Opciones**:
- `mlflow.pyfunc`
- `mlflow.autolog()`
- `mlflow.log_params()`
- `mlflow.<flavor>.load_model()`

**‚úÖ Respuesta correcta**: `mlflow.pyfunc`

**Explicaci√≥n**:
El m√≥dulo `mlflow.pyfunc` permite definir utilidades para registrar modelos personalizados que combinan frameworks distintos. No deber√≠as usar `mlflow.autolog()` ni `mlflow.log_params()` ya que no manejan correctamente modelos personalizados, y `load_model()` se usa solo para cargar, no registrar.

---

## ‚ùì Pregunta 2

**Contexto**: Accedes a datos en formato Parquet dentro de una carpeta, no registrados como un dataset. Usas Azure ML SDK v2.

**Pregunta**: ¬øQu√© deber√≠as hacer para leer/escribir esta carpeta directamente desde un script de ML?

**Opciones**:
- Crear un trabajo v2 con `Dataset.File.from_files()` y `ml_client.jobs.create_or_update()`
- Crear un trabajo v2 con `AssetTypes.URI_FOLDER` y `ml_client.jobs.from_config()`
- Crear un trabajo v2 con `AssetTypes.URI_FILE` y `ml_client.jobs.create_or_update()`

**‚úÖ Respuesta correcta**: Crear un trabajo v2 con `AssetTypes.URI_FOLDER` y `ml_client.jobs.create_or_update()`

**Explicaci√≥n**:
Cuando el archivo Parquet est√° en una carpeta, debes usar `AssetTypes.URI_FOLDER` y crear el trabajo con `ml_client.jobs.create_or_update()` para enviar toda la carpeta al entorno de ejecuci√≥n.

---

## ‚ùì Pregunta 3

**Contexto**: Vas a crear recursos de c√≥mputo en Azure ML usando Azure CLI y necesitas asegurarte de que no haya costos cuando no haya trabajos corriendo.

**Pregunta**: ¬øQu√© acciones debes tomar?

**Opciones**:
- ‚úÖ Especificar "idle seconds before scale down" a 0.
- ‚úÖ Crear un destino de c√≥mputo tipo instancia.
- ‚ùå Crear un destino de c√≥mputo tipo cluster.
- ‚ùå Crear un destino de c√≥mputo en Azure Data Factory.

**‚úÖ Respuestas correctas**: 
- Especificar `idle_seconds_before_scaledown=0`
- Crear una instancia de c√≥mputo

**Explicaci√≥n**:
Las instancias se pueden pausar autom√°ticamente cuando no hay trabajos. El par√°metro de inactividad a 0 ayuda a escalar autom√°ticamente. No debes usar cl√∫steres ni ADF.

---

## Caso de estudio: Registro y uso de modelos personalizados con m√∫ltiples frameworks

---

## Pregunta 13po:** Selecci√≥n √∫nica  
**Pregunta:**  
You have built a custom model that uses multiple elements from different frameworks. You need to log the model. What should you use?

**Opciones:**
- mlflow.pyfunc ‚úÖ
- mlflow.autolog()
- mlflow.log_params()
- mlflow.<flavor>.load_model()

**Respuesta Correcta:** ‚úÖ mlflow.pyfunc

**Explicaci√≥n:**  
Debes usar el m√≥dulo `mlflow.pyfunc` para registrar modelos personalizados que usan m√∫ltiples frameworks o l√≥gica de inferencia no incluida de forma nativa en MLflow. Este m√≥dulo permite definir un formato de sistema de archivos gen√©rico para modelos de Python y ofrece utilidades para guardarlos y cargarlos desde este formato.

---

## Pregunta 14

tipo: Selecci√≥n √∫nica  
**Pregunta:**  
You have access to column-oriented data in Parquet format within a folder. The data is not registered in a dataset. You want to read/write the folder in a job using the Azure ML SDK v2. What should you do?

**Opciones:**
- Create a v2 job using Dataset.File.from_files() and submit with `ml_client.jobs.create_or_update()`
- Create a v2 job using `AssetTypes.URI_FOLDER` and submit with `ml_client.jobs.from_config()`
- Create a v2 job using `AssetTypes.URI_FILE` and submit with `ml_client.jobs.create_or_update()`
- Create a v2 job using `AssetTypes.URI_FOLDER` and submit with `ml_client.jobs.create_or_update()` ‚úÖ

**Respuesta Correcta:** ‚úÖ Create a v2 job using `AssetTypes.URI_FOLDER` and submit with `ml_client.jobs.create_or_update()`

**Explicaci√≥n:**  
`AssetTypes.URI_FOLDER` se usa para hacer referencia a carpetas (no archivos individuales) como en este caso con datos Parquet. Esta configuraci√≥n permite leer y escribir directamente los datos desde el script.

---

## Pregunta 15

**Tipo:** Selecci√≥n m√∫ltiple  
**Pregunta:**  
You want to ensure batch jobs do not incur cost when not running. What two actions should you perform?

**Opciones:**
- Specify an idle seconds before scale down. Set the number to 0 ‚ùå
- Create an Azure Machine Learning compute instance target ‚ùå
- Create an Azure Machine Learning compute target ‚úÖ
- Specify the minimum number of cluster nodes. Set the number to 0 ‚úÖ

**Respuesta Correcta:** ‚úÖ Create compute target + Set minimum nodes to 0

**Explicaci√≥n:**  
Al establecer el n√∫mero m√≠nimo de nodos del cl√∫ster en 0, Azure liberar√° recursos cuando no haya trabajos ejecut√°ndose. No se recomienda establecer `idle_seconds_before_scaledown` en 0 porque puede causar reprovisionamientos innecesarios.

---

## Pregunta 16

*Tipo:** Selecci√≥n m√∫ltiple  
**Pregunta:**  
You need to write a batch inference script using `ParallelRunStep`. Which two functions must be included?

**Opciones:**
- load()
- init() ‚úÖ
- run(mini_batch) ‚úÖ
- evaluate(mini_batch)
- execute(mini_batch)

**Respuesta Correcta:** ‚úÖ init(), ‚úÖ run(mini_batch)

**Explicaci√≥n:**  
`init()` se usa para preparar recursos (como cargar el modelo) y `run(mini_batch)` ejecuta la inferencia sobre los datos del lote. Las dem√°s funciones no son v√°lidas como entrada para un `ParallelRunStep`.

---

## Pregunta 17

**Tipo:** Selecci√≥n en men√∫ desplegable  
**Pregunta:**  
You are registering multiple trained models. Which compute target should be used for each usage scenario?

| Model usage scenario   | Deployment target                           |
|------------------------|---------------------------------------------|
| Batch inference        | Azure Machine Learning compute cluster ‚úÖ    |
| Real-time inference    | Azure Kubernetes Service (AKS) ‚úÖ            |
| Testing and debugging  | Azure ML compute instance web service ‚úÖ     |

**Respuesta Correcta:** Todas las asignaciones son correctas.

**Explicaci√≥n:**  
- **Batch:** usa cl√∫steres por su escalabilidad para tareas intermitentes.  
- **Realtime:** AKS permite escalado horizontal y disponibilidad.  
- **Debugging:** compute instance es ideal para pruebas de bajo costo y AutoML.

## Pregunta 24: Programaci√≥n de trabajos recurrentes con SDK v2

**Tipo:** Pregunta tipo tabla (selecci√≥n m√∫ltiple por fila)  
**Tema:** Azure Machine Learning - Programaci√≥n de trabajos con SDK v2

**Pregunta:**  
You have been tasked with scheduling ML pipeline jobs using the Azure ML Python SDK v2. You have the following code:

```python
schedule_name = "sched_recurrence_with_python_sdkv2"
recurrence_trigger = RecurrenceTrigger(
    frequency="day",
    interval=1,
    schedule=RecurrencePattern(hours=7, minutes=[0, 1]),
)
job_schedule = JobSchedule(
    name=schedule_name,
    trigger=recurrence_trigger,
    create_job=pipeline_job
)
```

You are asked to validate the following statements:

| Statement | Yes | No |
|-----------|-----|----|
| The schedule fires every day with the recurrence set in the UTC time zone. | ‚úÖ | ‚ùå |
| The first job will run instantly and the future job triggers are based on the schedule. | ‚úÖ | ‚ùå |
| The frequency for this schedule can be updated to hour, day, week, month and year. | ‚ùå | ‚úÖ |

---

**Respuesta Correcta:**

‚úÖ  
‚úÖ  
‚ùå  

---

**Explicaci√≥n t√©cnica:**

La programaci√≥n de trabajos en Azure ML con el SDK v2 se realiza usando objetos como `RecurrenceTrigger`, que permiten definir una recurrencia de ejecuci√≥n basada en frecuencia e intervalos. En este caso:

1. **Frecuencia diaria (frequency="day") con intervalo 1** significa que el trabajo se ejecutar√° todos los d√≠as. Como **no se especifica el par√°metro `time_zone`**, el SDK usa por defecto **UTC**, por lo tanto la afirmaci√≥n es **verdadera**.  
   üìñ [Documentaci√≥n oficial sobre RecurrenceTrigger](https://learn.microsoft.com/en-us/azure/machine-learning/reference-yaml-job-schedule#recurrencetrigger-object)

2. Si no se define el par√°metro `start_time`, el primer trabajo se lanza de forma **instant√°nea**, y luego los siguientes trabajos se disparan seg√∫n la programaci√≥n definida. Esta afirmaci√≥n tambi√©n es **correcta**.  
   üëâ Esto est√° documentado [aqu√≠](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-schedule-pipelines-v2#recurrencetrigger-object)

3. La clave `frequency` **no puede** tomar el valor `"year"` (seg√∫n la documentaci√≥n solo puede ser `"minute"`, `"hour"`, `"day"`, `"week"`, `"month"`), por lo tanto la afirmaci√≥n es **falsa**.

---

**Resumen de por qu√© descartar las otras:**

- ‚ùå `"year"` no es un valor aceptado para `frequency`.
- ‚ùå No se define `start_time`, por lo tanto el primer job se ejecuta inmediatamente.
- ‚úÖ La zona horaria por defecto es UTC si no se especifica.

---

**Referencias adicionales:**

- üìò [Schedule jobs with SDK v2 (Azure ML)](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-schedule-pipelines-v2)
- üìò [CLI (v2) schedule YAML schema](https://learn.microsoft.com/en-us/azure/machine-learning/reference-yaml-job-schedule)


## Pregunta 25:  sobre lectura de archivos Parquet desde Azure Blob con Apache Spark (SDK v2)

**Tipo:** Selecci√≥n √∫nica  
**Pregunta:**  
Tu empresa usa Azure Machine Learning. Planeas leer un conjunto de datos desde Azure Blob Storage para tu proyecto de aprendizaje autom√°tico. El conjunto de datos est√° almacenado en un archivo de formato columnar (Parquet) en la siguiente ubicaci√≥n:  
`wasbs://mycontainer.blob.core.windows.net`

Est√°s utilizando un Apache Spark pool respaldado por Azure Synapse.  
Necesitas usar una funci√≥n de wrangling de datos de Apache Spark para leer este archivo.

**¬øQu√© funci√≥n deber√≠as usar?**

**Opciones:**  
- [ ] `spark.read.text("wasbs://mycontainer.blob.core.windows.net")`  
- [x] `spark.read.format("parquet").load("wasbs://mycontainer.blob.core.windows.net")`  
- [ ] `spark.read.format("avro").load("wasbs://mycontainer.blob.core.windows.net")`  
- [ ] `spark.read.format("csv").load("wasbs://mycontainer.blob.core.windows.net")`

**Respuesta correcta:** ‚úÖ `spark.read.format("parquet").load("wasbs://mycontainer.blob.core.windows.net")`

---

### üß† Explicaci√≥n:

En este caso, el archivo que se va a leer est√° en formato Parquet, que es un formato columnar com√∫nmente utilizado en big data y ML por su eficiencia en compresi√≥n y lectura.

- La funci√≥n `spark.read.format("parquet")` le indica a Spark que el archivo a cargar est√° en formato Parquet.
- `.load("wasbs://...")` especifica la ubicaci√≥n del archivo en Azure Blob Storage usando el protocolo `wasbs://`, que es compatible con Spark.

üí° Los DataFrames de Spark permiten trabajar eficientemente con datos estructurados, facilitando tareas de wrangling como filtrar, agrupar, transformar, y alimentar modelos de ML.

---

### ‚ùå Por qu√© se descartan las otras opciones:

- `spark.read.text(...)` est√° dise√±ado para leer archivos de texto plano l√≠nea por l√≠nea, no Parquet.
- `spark.read.format("avro")...` solo aplica si el archivo est√° en formato Avro, lo cual no es el caso.
- `spark.read.format("csv")...` genera un error si el archivo realmente est√° en formato Parquet.

---

üìö **Referencia oficial:**

- [Spark read formats - Parquet](https://spark.apache.org/docs/latest/sql-data-sources-parquet.html)  
- [Access Azure Blob Storage with Spark](https://learn.microsoft.com/en-us/azure/synapse-analytics/spark/apache-spark-azure-blob-storage)

## Pregunta 26: Programar trabajos de pipeline con Azure ML SDK v2

**Tipo:** Selecci√≥n m√∫ltiple (tabla de veracidad)

**Pregunta:**

You have been tasked with scheduling ML pipeline jobs using the Azure ML Python SDK v2. You have the following code:

```python
schedule_name = "sched_recurrence_with_python_sdkv2"
recurrence_trigger = RecurrenceTrigger(
    frequency="day",
    interval=1,
    schedule=RecurrencePattern(hours=7, minutes=[0, 1]),
)
job_schedule = JobSchedule(
    name=schedule_name,
    trigger=recurrence_trigger,
    create_job=pipeline_job
)
```

**Afirmaciones a evaluar:**

| Statement                                                                 | Yes | No  |
|---------------------------------------------------------------------------|-----|-----|
| The schedule fires every day with the recurrence set in the UTC time zone. | ‚úÖ  |     |
| The first job will run instantly and the future job triggers are based on the schedule. | ‚úÖ  |     |
| The frequency for this schedule can be updated to hour, day, week, month and year. |     | ‚úÖ  |

**Respuesta Correcta:**

- ‚úÖ Primera afirmaci√≥n
- ‚úÖ Segunda afirmaci√≥n
- ‚ùå Tercera afirmaci√≥n

---

### Explicaci√≥n:

1. **Frecuencia y zona horaria:** El `RecurrenceTrigger` con `frequency="day"` e `interval=1` indica que la ejecuci√≥n ocurre diariamente. Si no se especifica expl√≠citamente la zona horaria, se usa por defecto UTC (`time_zone=TimeZone.UTC`).

2. **Primera ejecuci√≥n:** Como no se proporciona el par√°metro `start_time`, la primera ejecuci√≥n ocurre inmediatamente, y las siguientes se programan de acuerdo al intervalo y patr√≥n definido.

3. **Limitaciones en la frecuencia:** El par√°metro `frequency` solo acepta: `minute`, `hour`, `day`, `week`, `month`. No se admite `year` como frecuencia v√°lida.

> ‚ùå La afirmaci√≥n que dice que se puede actualizar a `year` es falsa, y por eso debe marcarse como incorrecta.

---

üìö **Referencias:**

- [üìÑ Schedule pipeline jobs - Microsoft Learn](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-schedule-pipelines)
- [üìÑ RecurrenceTrigger YAML schema](https://learn.microsoft.com/en-us/azure/machine-learning/reference-yaml-job-schedule-v2)

## Pregunta 27: Comportamiento de componentes en un pipeline de predicci√≥n de autom√≥viles

**Tipo:** Veracidad (selecci√≥n m√∫ltiple tipo tabla)

**Contexto:**  
Tu equipo ha creado un pipeline de predicci√≥n de precios de autom√≥viles. Necesitas enviar la ejecuci√≥n y entender c√≥mo funcionan los componentes.

**Pregunta:**  
Para cada una de las siguientes afirmaciones, selecciona "Yes" si es verdadera. En caso contrario, selecciona "No".

| Afirmaci√≥n | Yes | No |
|-----------|-----|----|
| The Split Data component splits the columns in your dataset, based on how you configure the component. | ‚ùå | ‚úÖ |
| The model classifies automobiles into various price categories. | ‚ùå | ‚úÖ |
| The Score Model component generates scores for prices predicted versus prices provided for the test data features. | ‚úÖ | ‚ùå |

---

**Respuesta Correcta:**  
- ‚ùå Primera afirmaci√≥n  
- ‚ùå Segunda afirmaci√≥n  
- ‚úÖ Tercera afirmaci√≥n

---

**Explicaci√≥n t√©cnica:**

1. **Split Data component**: Este componente no divide columnas, sino que divide **filas** del conjunto de datos en dos particiones: t√≠picamente, un set de entrenamiento y otro de prueba. El comportamiento de divisi√≥n se basa en proporciones o reglas definidas por el usuario, pero **no** por columnas.  
   üìö [Referencia oficial - Transform data (Split Data)](https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/split-data)

2. **Clasificaci√≥n vs regresi√≥n**: El modelo en el escenario utiliza **regresi√≥n lineal**, no un algoritmo de clasificaci√≥n. Por tanto, **no clasifica** autom√≥viles en categor√≠as de precio. En su lugar, predice un **valor num√©rico continuo**.  
   üìö [Referencia oficial - Linear Regression component](https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/linear-regression)

3. **Score Model component**: Este componente toma como entrada un modelo ya entrenado y el conjunto de prueba. Luego **compara las predicciones del modelo con los valores reales** de la variable objetivo. Es perfectamente adecuado para tareas de regresi√≥n como esta.  
   üìö [Referencia oficial - Score Model](https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/score-model)

---

**Resumen:**  
Solo la tercera afirmaci√≥n es correcta, porque es la √∫nica que describe con precisi√≥n c√≥mo trabaja el componente dentro del pipeline de regresi√≥n.

## Pregunta 27: Comportamiento de componentes en Azure ML Designer

**Tipo:** Selecci√≥n m√∫ltiple (tabla de veracidad)

**Pregunta:**
Tu equipo est√° creando un pipeline de predicci√≥n de autom√≥viles. Debes enviar la ejecuci√≥n y comprender el modelo. Para cada afirmaci√≥n, indica si es verdadera o falsa:

| Statement                                                                                       | Yes | No  |
|--------------------------------------------------------------------------------------------------|-----|-----|
| The Split Data component splits the columns in your dataset, based on how you configure the component. |     | ‚úÖ  |
| The model classifies automobiles into various price categories.                                |     | ‚úÖ  |
| The Score Model component generates scores for prices predicted versus prices provided for the test data features. | ‚úÖ  |     |

**Respuesta Correcta:**
- ‚ùå Afirmaci√≥n 1: Incorrecta
- ‚ùå Afirmaci√≥n 2: Incorrecta
- ‚úÖ Afirmaci√≥n 3: Correcta

**Explicaci√≥n T√©cnica:**

1. **Split Data** no divide columnas, sino que divide **filas** del dataset en subconjuntos como entrenamiento y prueba. Por tanto, la afirmaci√≥n 1 es **incorrecta**.
2. El modelo descrito utiliza **regresi√≥n lineal**, no un algoritmo de clasificaci√≥n. Clasificar autom√≥viles en categor√≠as de precio ser√≠a una tarea de **clasificaci√≥n**, lo cual **no aplica aqu√≠**.
3. El componente **Score Model** toma el modelo entrenado y los datos de prueba, ejecuta las predicciones y **compara los valores predichos** contra los verdaderos. Esto valida el rendimiento del modelo.

üìö [Linear Regression component](https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/linear-regression)
üìö [Score Model](https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/score-model)
üìö [Transform data - Azure ML Designer](https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/split-data)

---

## Pregunta 28: Monitoreo de logs en Azure ML con OpenCensus y Application Insights

**Tipo:** Emparejamiento de requerimiento con campo (drop-down)

**Pregunta:**
Deseas monitorear y depurar pipelines redirigiendo logs de Azure Machine Learning a Application Insights mediante la librer√≠a **OpenCensus para Python**. ¬øQu√© campos debes incluir para cada requerimiento?

| Query Requirement                              | Field           |
|------------------------------------------------|-----------------|
| Differentiate between training and scoring runs | `run_type`      |
| Focus on a specific issue                      | `step_id`       |
| View logs for all steps over time              | `parent_run_id` |

**Respuesta Correcta:**
- ‚úÖ `run_type` permite diferenciar entre ejecuciones de entrenamiento y evaluaci√≥n.
- ‚úÖ `step_id` filtra por problemas espec√≠ficos en pasos individuales.
- ‚úÖ `parent_run_id` agrupa todos los pasos de una ejecuci√≥n de pipeline para su an√°lisis conjunto.

**Explicaci√≥n T√©cnica:**

- `run_type`: identifica si una ejecuci√≥n es de entrenamiento o scoring. Es esencial para an√°lisis comparativo entre fases de desarrollo y despliegue.
- `step_id`: cada paso del pipeline tiene un identificador √∫nico. Este campo ayuda a **aislar errores o analizar tiempos de ejecuci√≥n**.
- `parent_run_id`: vincula los logs de pasos individuales a la ejecuci√≥n principal del pipeline. Es √∫til para tener una vista integral y cronol√≥gica.

üìö [Troubleshooting machine learning pipelines](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-pipeline)
üìö [Application Insights overview](https://learn.microsoft.com/en-us/azure/azure-monitor/app/app-insights-overview)

---

## Pregunta 30: Uso de ThresholdOptimizer con Fairlearn y Azure ML SDK v2

**Tipo:** Selecci√≥n m√∫ltiple (tabla de veracidad)

**Pregunta:**
Est√°s usando Azure Machine Learning con el SDK v2 y la librer√≠a **Fairlearn** para evaluar y mitigar sesgos en tu modelo, utilizando el constraint de **Equal Opportunity Parity**.

Tu modelo emplea `ThresholdOptimizer`, como se ve en el siguiente fragmento de c√≥digo:

```python
# __init__.py
from ._plotting import plot_threshold_optimizer
from ._threshold_optimizer import ThresholdOptimizer

__all__ = ["ThresholdOptimizer", "plot_threshold_optimizer"]

# fairlearn/postprocessing/_threshold_optimizer.py (fragmento)
import logging
from warnings import warn
import numpy as np
import pandas as pd
from sklearn import clone
from sklearn.base import BaseEstimator, MetaEstimatorMixin
from sklearn.exceptions import NotFittedError
from sklearn.utils import Bunch
from sklearn.utils.validation import check_is_fitted
from ..utils._common import _get_soft_predictions
from ..utils._input_validation import _KW_CONTROL_FEATURES, _validate_and_reformat_input
from ._constants import (
    BASE_ESTIMATOR_NONE_ERROR_MESSAGE,
    BASE_ESTIMATOR_NOT_FITTED_WARNING,
    LABEL_KEY,
    OUTPUT_SEPARATOR,
    SCORE_KEY,
    SENSITIVE_FEATURE_KEY,
)
from ._interpolated_thresholder import InterpolatedThresholder
from ._tradeoff_curve_utilities import (
    METRIC_DICT,
    _extend_confusion_matrix,
    _interpolate_curve,
    _tradeoff_curve,
)
```

Basado en este contexto, responde si las siguientes afirmaciones son verdaderas o falsas:

| Afirmaci√≥n | Verdadera | Falsa |
|-----------|-----------|-------|
|1. You are using a ThresholdOptimizer algorithm, which takes as input an existing classifier and a sensitive feature.|	‚úÖ	||
|2. Your algorithm would generate a set of retrained models by using a sequence of reweighted training datasets.|		|‚úÖ|
|3. Your algorithm uses a binary classification as a machine learning task in this scenario.|		‚úÖ||

‚úÖ Explicaci√≥n t√©cnica detallada
ThresholdOptimizer y sensitive features
La afirmaci√≥n es verdadera.
ThresholdOptimizer es un m√©todo de postprocesamiento que toma como entrada un clasificador existente y una feature sensible, y ajusta su umbral de decisi√≥n para satisfacer una constraint de equidad como Equal Opportunity.
No se reentrena el modelo, solo se ajustan las decisiones de predicci√≥n.

üîó Referencia: Fairlearn API ‚Äì ThresholdOptimizer

Generaci√≥n de modelos reentrenados
Esto es falso.
El ThresholdOptimizer no reentrena modelos.
El ajuste del sesgo ocurre al modificar el umbral de predicci√≥n.
Los algoritmos que s√≠ reentrenan modelos con datasets reponderados son los de reducci√≥n, como ExponentiatedGradient, que pertenecen a otra categor√≠a en Fairlearn.

üîó Referencia: Fairlearn mitigation techniques

Uso de clasificaci√≥n binaria
Esto es cierto.
La constraint Equal Opportunity requiere tareas de clasificaci√≥n binaria, ya que se enfoca en igualar la tasa de verdaderos positivos (TPR) entre grupos sensibles.

üîó M√©tricas en Fairlearn: Equal Opportunity

---
## Pregunta 31: Selecci√≥n del recurso de c√≥mputo para despliegue en tiempo real

**Tipo:** Selecci√≥n √∫nica

**Pregunta:**

You create, train, and test a linear regression model.

You plan to deploy the model as a web service endpoint that users can use to get real-time outcomes based on the features they select.

You need to create the compute resource. You want to ensure that the cluster that runs the pipeline is managed by Azure.

**Which compute option should you use?**

**Opciones:**
- [ ] Attached compute
- [ ] Compute cluster
- ‚úÖ Inference cluster
- [ ] Compute instance

**Respuesta correcta:** ‚úÖ Inference cluster

---

**Explicaci√≥n detallada:**

Para alojar un **servicio web en tiempo real**, debes crear un *Inference cluster* en Azure Machine Learning. Este tipo de cl√∫ster puede estar compuesto por:

- **AKS (Azure Kubernetes Service)**: recomendado para ambientes de producci√≥n.
- **ACI (Azure Container Instance)**: √∫til en entornos de desarrollo o para modelos peque√±os.

Este es el **√∫nico tipo de cl√∫ster** que **admite el despliegue de un servicio de inferencia en tiempo real** manejado completamente por Azure.

Las otras opciones no son v√°lidas:
- **Compute instance**: es para desarrollo interactivo, no para hosting de servicios.
- **Compute cluster**: se usa para entrenamiento de modelos o trabajos batch, pero no para inferencia en tiempo real.
- **Attached compute**: se refiere a cl√∫steres externos conectados a Azure, pero que no son administrados por Azure directamente.

üß† En resumen, si necesitas escalar autom√°ticamente y garantizar una infraestructura gestionada, tu mejor opci√≥n es un **Inference Cluster**.

---

üìö **Referencias oficiales:**
- [Tutorial: Use the designer to deploy a machine learning model](https://learn.microsoft.com/en-us/azure/machine-learning/tutorial-designer-automobile-price-deployment)
- [Configure and submit training jobs](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets)
## Pregunta 32: Elecci√≥n de pol√≠tica de terminaci√≥n anticipada en hiperpar√°metro tuning con SDK v2

**Tipo:** Selecci√≥n √∫nica

**Pregunta:**

Est√°s realizando la sintonizaci√≥n de hiperpar√°metros de un modelo de ML usando el SDK v2 de Azure Machine Learning.

Debes cumplir con las siguientes tres condiciones:

- La pol√≠tica cancela un porcentaje de los trabajos de menor rendimiento en cada intervalo de evaluaci√≥n.
- `evaluation_interval = 1`
- `delay_evaluation = 6`

¬øQu√© pol√≠tica de terminaci√≥n anticipada deber√≠as usar?

**Opciones:**

- [ ] Bandit  
- [ ] Median stopping  
- [x] Truncation selection  

---

**Respuesta Correcta:** ‚úÖ Truncation selection

---

**Explicaci√≥n t√©cnica detallada:**

La pol√≠tica **Truncation Selection** es la indicada cuando:

- Necesitas cancelar un **porcentaje** de los trabajos con peor desempe√±o en cada intervalo de evaluaci√≥n (`evaluation_interval`).
- Se desea **esperar** a que pasen ciertos intervalos antes de aplicar la pol√≠tica (`delay_evaluation`).
- No te interesa usar promedios m√≥viles como lo har√≠as con Median Stopping.

```python
from azure.ai.ml.sweep import TruncationSelectionPolicy

sweep_job.early_termination = TruncationSelectionPolicy(
    evaluation_interval=1,
    truncation_percentage=20,
    delay_evaluation=6,
    exclude_finished_jobs=True
)
```
Esta configuraci√≥n significa que:

Se eval√∫an los trabajos cada intervalo (evaluation_interval=1),

Pero se empieza a aplicar la pol√≠tica desde el intervalo 6 (delay_evaluation=6),

Se eliminan los trabajos en el percentil inferior (por ejemplo, 20% m√°s bajos),

Y no se tocan los trabajos que ya han finalizado.

¬øPor qu√© se descartan las otras opciones?

‚ùå Median Stopping: cancela trabajos si su rendimiento est√° por debajo de la mediana, no permite configurar truncation_percentage ni funciona igual para cancelaci√≥n por percentil.

‚ùå Bandit: esta opci√≥n no se menciona en la explicaci√≥n ni corresponde con los criterios dados en la pregunta.

Referencias oficiales:

üìò [Azure ML Early Termination PoliciesAzure ML Early Termination Policie](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters?view=azureml-api-2)

üìò SDK v2 - Hyperparameter sweep

## Pregunta 33: Configurar conexi√≥n segura con ADLS Gen2 en Spark usando Azure ML Notebooks

**Tipo:** Selecci√≥n √∫nica

### Pregunta
You are configuring a Spark session in Azure Machine Learning Notebooks to process data stored in an Azure Data Lake Storage (ADLS) Gen 2 account.

You need to securely connect to this storage account without adding excessive complexity to your configuration.

**What should you do?**

### Opciones:

- ‚ùå Use a service principal for OAuth-based authentication by configuring the client ID, client secret, and tenant ID.
- ‚ùå Use OAuth for authentication by configuring the `fs.azure.account.auth.type` and related properties.
- ‚ùå Use a SAS token for authentication by setting the `fs.azure.sas` property.
- ‚úÖ **Use the storage account‚Äôs access key to authenticate and set the `fs.azure.account.key` property.**

---

### ‚úÖ Respuesta correcta:
**Use the storage account‚Äôs access key to authenticate and set the `fs.azure.account.key` property.**

---

### Explicaci√≥n:

La opci√≥n correcta es usar la **clave de acceso (Access Key)** de la cuenta de almacenamiento para autenticarse en Spark y configurar la propiedad:

```python
sc._jsc.hadoopConfiguration().set(
    "fs.azure.account.key.<STORAGE_ACCOUNT_NAME>.dfs.core.windows.net",
    "<ACCESS_KEY>"
)
```
Esta forma de autenticaci√≥n:

Es segura y directa.

No requiere configurar m√∫ltiples credenciales o tokens externos.

Es ideal si quieres evitar la complejidad de manejar OAuth, service principals o SAS tokens.

Por qu√© se descartan las otras opciones:
‚ùå Service Principal con OAuth: implica manejar client ID, secret y tenant ID, lo que requiere m√°s configuraci√≥n, rotaci√≥n de claves y mantenimiento regular.

‚ùå OAuth (fs.azure.account.auth.type): requiere configuraci√≥n adicional y es m√°s complejo para escenarios b√°sicos.

‚ùå SAS Token: aunque es seguro, requiere gestionar tokens con permisos y expiraciones, lo cual agrega complejidad innecesaria.

## Pregunta 34: Selecci√≥n de tipo de almacenamiento para datos relacionales en Azure ML Studio

**Tipo:** Selecci√≥n √∫nica  
**Pregunta:**  
Quieres crear un *datastore* en Azure Machine Learning (ML) Studio. Antes de eso, necesitas crear una instancia del almacenamiento donde deseas que residan tus datos **relacionales**. Navegas a la opci√≥n "Datastore" en Azure ML Studio.

¬øCu√°l tipo de almacenamiento fuente deber√≠as seleccionar?

**Opciones:**

- [ ] Azure Data Lake Gen2  
- [ ] Azure Blob Container  
- [ ] Databricks File System  
- [x] Azure Database for PostgreSQL

**Respuesta correcta:** ‚úÖ Azure Database for PostgreSQL

**Explicaci√≥n t√©cnica:**  
Azure ML Studio permite registrar distintos or√≠genes de datos como *datastores*. Para datos **relacionales**, se debe seleccionar una base de datos relacional soportada, como **Azure Database for PostgreSQL**.  
Los contenedores como Azure Blob Storage o ADLS Gen2 **no est√°n dise√±ados para almacenar datos relacionales estructurados**, sino m√°s bien archivos, blobs o datos no estructurados.

Azure ML admite los siguientes servicios de almacenamiento como *datastore*:

- Azure Blob Container  
- Azure File Share  
- Azure Data Lake / Gen2  
- Azure SQL Database  
- Databricks File System  
- Azure Database for MySQL  
- ‚úÖ Azure Database for PostgreSQL (ideal para datos relacionales)

‚ùå No debes seleccionar **Azure Blob Container** u otros servicios de archivos si planeas trabajar directamente con datos relacionales.

üìö [Referencia oficial - Datastore Module](https://learn.microsoft.com/en-us/python/api/azureml-core/azureml.core.datastore.datastore?view=azure-ml-py)


## Pregunta 35: Actualizaci√≥n de claves de almacenamiento en Azure ML Workspace

**Tipo:** Selecci√≥n √∫nica  
**Pregunta:**  
Identificas que la cuenta de almacenamiento usada por tu Azure Machine Learning (ML) Workspace ha sido comprometida.  
Para prevenir una posible brecha de datos, regeneras las claves de esa cuenta de almacenamiento.  
Los usuarios del workspace reportan errores inmediatamente despu√©s del cambio de claves.

Necesitas actualizar las claves de almacenamiento en el workspace para restaurar su funcionamiento.

**¬øQu√© comando de CLI deber√≠as ejecutar?**

**Opciones:**

- [ ] `az ml workspace update`  
- [ ] `az ml workspace share`  
- [x] `az ml workspace sync-keys`

**Respuesta correcta:** ‚úÖ `az ml workspace sync-keys`

**Explicaci√≥n t√©cnica:**  
Cuando se regeneran las claves de una cuenta de almacenamiento asociada a un workspace de Azure ML, el workspace pierde acceso inmediato a los recursos de almacenamiento (como blobs o archivos de datos).

Para resolver esto, se debe usar el comando:

```bash
az ml workspace sync-keys \
  --name <workspace-name> \
  --resource-group <resource-group-name>
```

Este comando sincroniza las claves actualizadas del recurso de almacenamiento asociado (como Azure Blob o ADLS Gen2) con el Azure ML Workspace.  
Esto es esencial para evitar interrupciones en la ejecuci√≥n de notebooks, experimentos o pipelines que dependen del almacenamiento.

üîí **Importante:**  
No basta con regenerar la clave en el recurso; el workspace debe ser actualizado con esas nuevas credenciales de forma expl√≠cita mediante `sync-keys`.

üìö [Documentaci√≥n oficial de az ml workspace sync-keys](https://learn.microsoft.com/en-us/cli/azure/ml/workspace?view=azure-cli-latest#az-ml-workspace-sync-keys)

## Pregunta 36: Notificaciones en caso de falla en el despliegue del modelo

**Tipo:** Selecci√≥n √∫nica

**Pregunta:**
You use Azure Machine Learning to deploy machine learning models.  
You need to be notified when a model deployment fails.  

What should you do?

**Opciones:**
- [ ] Query AmlComputeJobEvents using the ExecutionState property.
- [ ] Query AmlComputeJobEvents using the ProvisionState property.
- [ ] Stream Azure Machine Learning metric information to Azure Event Hubs.
- [x] Stream Azure Machine Learning logs to Azure Monitor.

**Respuesta Correcta:** ‚úÖ Stream Azure Machine Learning logs to Azure Monitor.

**Explicaci√≥n:**

- **Azure Monitor** es una plataforma independiente que permite ingerir logs desde diversos servicios de Azure, incluyendo Azure Machine Learning.
- Una vez que configuras AML para enviar los logs a Azure Monitor, puedes consultar los logs usando KQL (lenguaje similar a SQL) y crear **alertas** cuando ocurra una falla, como una **falla en el despliegue del modelo**.

**Por qu√© las otras opciones NO son correctas:**

- **ExecutionState**: Aunque permite consultar el estado de los jobs, no genera alertas autom√°ticamente.
- **ProvisionState**: Solo indica el estado de la sumisi√≥n del job, no de su ejecuci√≥n.
- **Event Hubs**: Es para an√°lisis de datos, no para generar alertas. No es el objetivo aqu√≠.

üìö [M√°s info sobre integraci√≥n con Azure Monitor](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-enable-app-insights)

## Pregunta 37: Probar un pipeline de inferencia online con datos locales

**Tipo:** Selecci√≥n √∫nica  
**¬øPertenece al SDK v2?:** ‚ùå No. Esta pregunta se basa en el uso del Azure ML Designer (interfaz visual), el cual pertenece a flujos que dependen mayoritariamente del SDK v1. Esta pregunta puede omitirse para el estudio del examen DP-100 basado √∫nicamente en el SDK v2.  
**Estado:** üìå Ignorada por no ser parte del SDK v2  

**Pregunta:**  
You have an online inference pipeline, as shown in the exhibit. The pipeline takes comma-separated features related to an automobile and predicts its price.

You need to test the pipeline with minimal costs and effort against some test data, which is located in a text file on your machine.

What module should you use?

**Opciones:**

- [ ] Export Data  
- [ ] Import Data  
- [ ] Join Data  
- [x] Enter Data Manually ‚úÖ

**Respuesta Correcta:**  
‚úÖ Enter Data Manually

**Explicaci√≥n:**  
El m√≥dulo **Enter Data Manually** permite copiar y pegar datos desde un archivo de texto local directamente al pipeline, evitando as√≠ el costo adicional de subir archivos a la nube.  
- No se debe usar **Import Data**, ya que eso implicar√≠a subir el archivo local a un recurso de almacenamiento en Azure (como ADLS, Blob, etc.).  
- **Export Data** se usa para enviar datos desde el pipeline hacia una ubicaci√≥n en la nube, lo cual no aplica en este escenario.  
- **Join Data** est√° dise√±ado para combinar m√∫ltiples fuentes de datos, no para enviar datos de prueba al pipeline.

üìö **Referencia oficial:**  
[What is Azure Machine Learning?](https://learn.microsoft.com/en-us/azure/machine-learning/overview-what-is-azure-ml)

---

üõë **Nota:** Esta pregunta se basa en flujos del **Azure Machine Learning Designer**, que pertenece al **SDK v1**. Si te est√°s preparando exclusivamente para el SDK v2 (como indica tu enfoque), puedes omitir esta pregunta del banco de estudio.

## Pregunta 38: Validar despliegue de modelo como servicio web con autenticaci√≥n

**Tipo:** Ordenar pasos

**Pregunta:**

You use Azure Machine Learning to train and deploy a machine learning model as a web service. Your web service requires authentication.

You need to test the deployment to ensure that requests to the web service will be successful.

**¬øQu√© tres acciones deber√≠as ejecutar en orden?**

---

### ‚úÖ Orden correcto:

1. **Retrieve the `scoring_uri` property of a WebService object.**
2. **Specify bearer authentication in the header.**
3. **Issue an HTTP POST request with JSON data.**

---

### ‚ùå Acciones incorrectas:

- **Query AmlComputeJobEvents to determine ExecutionState:** Esta acci√≥n se usa para monitorear trabajos de c√≥mputo, no para consumir un servicio desplegado.

---

### üß† Explicaci√≥n:

Cuando despliegas un modelo como servicio web en Azure Machine Learning:

1. **scoring_uri** representa el endpoint al cual puedes hacer peticiones REST.
2. Si el servicio est√° autenticado, necesitas incluir un token tipo *Bearer* en el encabezado de tu petici√≥n.
3. Finalmente, puedes hacer una solicitud `POST` al `scoring_uri` con los datos en formato JSON.

Esto garantiza que puedes enviar datos al modelo correctamente y recibir respuestas predichas.

üìö **Referencia:** [Deploy and consume a model as a web service - Microsoft Learn](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where)

## Pregunta 39: Exportaci√≥n de etiquetas de datos para clasificaci√≥n de im√°genes

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Azure Machine Learning ‚Äì Exportaci√≥n de datos etiquetados  
**Tecnolog√≠a:** Compatible con SDK v2  

---

### üß† Pregunta:

Your organization provides you with a set of images for a learning set for an image classification model. You complete the labeling exercise with the multi-label classification option.

You are asked to provide a tabular view of the image and the class the image belongs to for your users.

You need to retrieve the data to display the tabular view with minimal effort.

**What should you do?**

---

### üîò Opciones:

- [ ] Export data labels to the binary file format.  
- [x] Export data labels to the COCO file format.  
- [ ] Name the files with the label that was associated with it during classification.  
- [ ] Add the file name to the labels dataset.

---

### ‚úÖ Respuesta Correcta:
**Export data labels to the COCO file format.**

---

### üßæ Explicaci√≥n:

Exportar las etiquetas en formato **COCO** permite capturar tanto la referencia a los datos (nombre o URI de la imagen) como sus etiquetas. Este formato es ampliamente soportado por librer√≠as como `PyTorch`, `TorchVision` o `pandas`, y se puede transformar f√°cilmente en una vista tabular con funciones como `to_pandas_dataframe()`.

- ‚ùå **Binary format:** No est√° disponible en Azure para clasificaci√≥n de im√°genes.
- ‚ùå **Renombrar archivos:** Requiere trabajo manual adicional y no se integra directamente con los servicios de Azure ML.
- ‚ùå **Modificar dataset a√±adiendo nombres de archivo:** Pr√°ctica no recomendada y requiere edici√≥n manual.

---

### üìö Referencias:


- [Labeling images and text documents](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-label-data)  
- [Create and explore Azure Machine Learning dataset with labels](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-labeling-projects)

## Pregunta 41: Selecci√≥n de destino de implementaci√≥n de bajo costo para pruebas en tiempo real

**Tipo:** Selecci√≥n m√∫ltiple  
**Tema:** Azure Machine Learning ‚Äì Despliegue de modelos  
**Tecnolog√≠a:** Compatible con SDK v2  

---

### üß† Pregunta:

You complete training a linear regression model using Azure Machine Learning studio. You want to test the model by having users of your organization call an endpoint. The outcomes of the model should be provided in real time for users. All workload will be CPU based.

You need to determine a deployment target compute resource that can be used for testing and debugging while incurring minimal cost.

**Which two deployment targets should you select? Each correct answer presents a complete solution.**

---

### üîò Opciones:

- [x] Azure Container Instances  
- [ ] Azure Machine Learning Kubernetes  
- [x] Local web service  
- [ ] Azure Machine Learning compute clusters

---

### ‚úÖ Respuesta Correcta:
**Azure Container Instances** y **Local web service**

---

### üßæ Explicaci√≥n:

Para realizar pruebas y depuraci√≥n de modelos de inferencia con cargas CPU en tiempo real, lo ideal es usar opciones **de bajo costo y f√°ciles de aprovisionar**:

- ‚úÖ **Azure Container Instances (ACI):** Ideal para despliegues ligeros, pruebas, y desarrollo. F√°cil de configurar y econ√≥mica.
- ‚úÖ **Local Web Service:** Perfecta para probar el modelo localmente sin incurrir en ning√∫n costo.

- ‚ùå **Azure Machine Learning Kubernetes:** Aunque ofrece escalabilidad y baja latencia, es costoso y m√°s adecuado para producci√≥n.
- ‚ùå **Compute clusters:** Se utilizan para *batch inference pipelines*, no son apropiados para despliegues en tiempo real.

| Compute Target               | Mejor para                          | Escenarios t√≠picos                          | Costo  | Escalado | Tiempo de inicio | Requiere gesti√≥n |
|------------------------------|-------------------------------------|---------------------------------------------|--------|----------|------------------|------------------|
| **Local Web Service**        | Pruebas/debug local                 | Desarrollo inicial, pruebas r√°pidas         | Gratis | Manual   | Instant√°neo       | No               |
| **Azure Container Instances (ACI)** | Pruebas temporales, bajos costos | Validaci√≥n de modelos, cargas peque√±as      | Bajo   | Manual   | 1-3 minutos      | No               |
| **Azure Kubernetes Service (AKS)** | Producci√≥n (alta demanda)        | Servicios en tiempo real, alto tr√°fico      | Alto   | Auto     | 5-10 minutos     | S√≠               |
| **AML Compute Clusters**      | Procesamiento por lotes (batch)     | Inferencia batch, entrenamiento distribuido | Medio  | Auto     | 3-5 minutos      | Parcial          |
| **Azure Functions**           | Microservicios event-driven         | Escenarios serverless, peque√±as cargas      | Bajo   | Auto     | Variable         | No               |
| **IoT Edge**                  | Edge computing                      | Dispositivos perif√©ricos                    | Variable | No      | Variable         | S√≠               |

**Leyenda de uso recomendado:**
- ‚úÖ **Local/ACI**: Pruebas/debug (como en tu caso de estudio)
- üöÄ **AKS**: Producci√≥n con tr√°fico sostenido
- üì¶ **Compute Clusters**: Trabajos batch pesados
- ‚ö° **Functions**: Cargas espor√°dicas o event-driven
- üåê **IoT Edge**: Modelos en dispositivos remotos

**Factores clave para elegir:**
1. **Costo**: Local < ACI < Clusters < AKS
2. **Disponibilidad**: Local (0%) < ACI (no garantizada) < AKS (99.9%)
3. **Escalado**: Solo AKS/AutoML Clusters escalan autom√°ticamente
4. **SLA**: Solo AKS ofrece Acuerdo de Nivel de Servicio completo

### Compute Targets para Despliegue en Azure ML

```mermaid
pie
    title Cuando Usar Cada Compute Target
    "Local Web Service" : 15
    "ACI (Pruebas/Debug)" : 30
    "AKS (Producci√≥n)" : 40
    "Compute Clusters (Batch)" : 15
```

---

### üìö Referencias:

- [What are compute targets in Azure Machine Learning?](https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target)  
- [Introduction to Kubernetes compute target in Azure Machine Learning](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-kubernetes)

## Pregunta 42: M√©todo adecuado para el ajuste de hiperpar√°metros

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Azure Machine Learning ‚Äì Optimizaci√≥n de hiperpar√°metros  
**Tecnolog√≠a:** Compatible con SDK v2  

---

### üß† Pregunta:

You are building a model to perform binary classification on a large dataset. You plan to tune the hyperparameters of the model in order to optimize its performance. You have defined a search space that includes the learning rate, the number of hidden layers, and the number of neurons in each hidden layer.

You need to balance the trade-off between exploration and exploitation in your search for the best hyperparameters.

**Which method should you use to tune the hyperparameters?**

---

### üîò Opciones:

- [ ] Gradient-based optimization  
- [ ] Grid sampling  
- [ ] Random sampling  
- [x] Bayesian sampling  

---

### ‚úÖ Respuesta Correcta:
**Bayesian sampling**

---

### üßæ Explicaci√≥n:

La t√©cnica de **Bayesian sampling** es ideal para balancear **exploraci√≥n** (buscar en todo el espacio de hiperpar√°metros) y **explotaci√≥n** (enfocarse en zonas prometedoras). Este m√©todo:

- Usa un modelo probabil√≠stico y t√©cnicas de inferencia bayesiana.
- Aprende de resultados previos para proponer nuevos conjuntos de hiperpar√°metros.
- Reduce los costos computacionales mientras maximiza la posibilidad de hallar un √≥ptimo global.

Comparaciones:

- ‚ùå **Grid sampling**: prueba combinaciones exhaustivas sin usar resultados anteriores. Muy costoso.
- ‚ùå **Random sampling**: ignora los resultados previos, por lo que es menos eficiente.
- ‚ùå **Gradient-based optimization**: se usa para actualizar pesos durante el entrenamiento, **no** para optimizar hiperpar√°metros.

---

### üìö Referencias:

- [Hyperparameter tuning a model (v2)](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters-v2)  
- [Gradient Descent For Machine Learning](https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/gradient-descent)  
- [Linear Regression component](https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/linear-regression)


## Pregunta 46: Importar datos desde Amazon S3 usando SDK v2

**Tipo:** Opci√≥n m√∫ltiple (S√≠/No por afirmaci√≥n)  
**Tema:** Azure Machine Learning ‚Äì Ingesta de datos desde recursos externos  
**Tecnolog√≠a:** Compatible con SDK v2  

---

### üß† Pregunta:

Your organization is using Azure Machine Learning (ML) services. You have been asked to write a Python script which imports data from an Amazon S3 external resource.

You are using Azure ML Python Software Development Kit (SDK) v2.

The code that you have written is as exhibited below:

```python
from azure.ai.ml.entities import DataImport
from azure.ai.ml.data_transfer import FileSystem
from azure.ai.ml import MLClient

ml_client = MLClient.from_config()

data_import = DataImport(
    name="<name>",
    source=FileSystem(connection="<connection>", path="<path_on_source>"),
    path="<path>"
)

ml_client.data.import_data(data_import=data_import)
```

You need to implement the solution.  
For each of the following statements, select **Yes** if the statement is true. Otherwise, select **No**.

---

### üîò Afirmaciones:

| Afirmaci√≥n                                                                                   | Yes | No  |
|----------------------------------------------------------------------------------------------|:---:|:---:|
| The `"<connection>"` value handles the data import action, which determines the details of S3. | ‚úÖ  |     |
| The `path=""` value is optional.                                                              |     | ‚úÖ  |
| Amazon S3 will be registered as a data asset with type of `uri_file`.                         |     | ‚úÖ  |

---

### ‚úÖ Respuestas Correctas:

- ‚úîÔ∏è El valor `"<connection>"` determina los detalles de Amazon S3.
- ‚ùå El campo `path` es obligatorio para indicar el destino en el almac√©n.
- ‚ùå Amazon S3 se registra como tipo `uri_folder`, no como `uri_file`.

---

### üßæ Explicaci√≥n:

- El par√°metro `connection` define el recurso externo (S3 bucket).
- El par√°metro `path` es obligatorio para establecer el destino del asset importado.
- Amazon S3, al ser un sistema de archivos externo, siempre se registra como un `uri_folder` (directorio), no como archivo √∫nico.

---

### üìö Referencias:

- [Import data from Amazon S3](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-import-data-s3)  
- [DataImport class ‚Äì SDK v2](https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.dataimport)

## Pregunta 48: Error por columnas sin seleccionar en Azure ML pipeline

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Azure Machine Learning ‚Äì Limpieza y transformaci√≥n de datos  
**Tecnolog√≠a:** Compatible con SDK v2  

---

### üß† Pregunta:

You use Azure Machine Learning to create a machine learning pipeline. Your dataset includes sparse string and numeric data. While working with pipeline components, you receive an error indicating that a value is required.

You need to resolve this issue.

**What should you do?**

---

### üîò Opciones:

- [ ] Configure the Select Columns in Dataset component to exclude string data.  
- [x] Use the Select Columns in Dataset component to choose a column.  
- [ ] Configure a custom substitution value in the Clean Missing Data component.  
- [ ] Specify the columns to be cleaned in the Clean Missing Data component.

---

### ‚úÖ Respuesta Correcta:
**Use the Select Columns in Dataset component to choose a column.**

---

### üßæ Explicaci√≥n:

Est√°s trabajando en un pipeline de Azure Machine Learning. Este pipeline utiliza datos que incluyen columnas de tipo cadena (string) y columnas num√©ricas.
Mientras armas tu flujo (pipeline), recibes un error que dice que se requiere un valor. Eso significa que Azure ML est√° esperando que selecciones expl√≠citamente columnas para trabajar, pero no lo has hecho.

 ¬øCu√°l es el error?
‚ÄúA value is required‚Äù
Significa que no has seleccionado ninguna columna para que el componente del pipeline pueda trabajar. Por defecto, los componentes como ‚ÄúSelect Columns in Dataset‚Äù no hacen nada si t√∫ no les dices qu√© columnas usar.

El componente **Select Columns in Dataset** permite especificar expl√≠citamente qu√© columnas ser√°n procesadas en un pipeline de Azure ML.  
Si no se selecciona ninguna columna, se produce un error indicando que se requiere un valor, ya que por defecto no se pasa ninguna columna al siguiente paso del pipeline.

Comparaci√≥n de opciones:

- ‚ùå **Exclude string data:** Esta configuraci√≥n no resuelve el error si no se ha seleccionado al menos una columna.
- ‚ùå **Custom substitution:** Esto reemplaza valores faltantes, pero no resuelve el error de columnas no seleccionadas.
- ‚ùå **Specify columns in Clean Missing Data:** Este paso requiere columnas ya seleccionadas para funcionar correctamente. No soluciona el problema ra√≠z del error.

---

### üìö Referencia:
- [Select Columns in Dataset](https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/select-columns-in-dataset)

## Pregunta 49: Recomendaci√≥n de memoria m√≠nima para procesamiento con Pandas

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Azure Machine Learning ‚Äì Recomendaciones de recursos computacionales  
**Tecnolog√≠a:** Compatible con SDK v2  

---

### üß† Pregunta:

You are planning the size of the compute resources required for data provided by your marketing team. Your team will run experiments and create dataframes using pandas.

The marketing team provides a 1-GB CSV file with the data. All processing is required to happen in memory.

You need to recommend the minimum memory (RAM) configuration required to support processing these files.

**What should you recommend?**

---

### üîò Opciones:

- [ ] 2 GB  
- [ ] 8 GB  
- [ ] 10 GB  
- [x] 20 GB  

---

### ‚úÖ Respuesta Correcta:
**20 GB**

---

### üßæ Explicaci√≥n:

Aunque el archivo CSV tiene un tama√±o de solo 1 GB, al cargarse en un DataFrame con `pandas`, este puede expandirse hasta ocupar **aproximadamente 10 GB** de RAM. Para realizar operaciones en memoria de forma eficiente (filtrados, transformaciones, uniones, etc.), se recomienda tener **el doble de RAM disponible**, es decir **20 GB**.

Otras opciones como 2 GB, 8 GB o 10 GB no ser√≠an suficientes para garantizar un procesamiento fluido, especialmente con pandas, que no est√° optimizado para manejo fuera de memoria.

---

### üìö Referencias:

- [Create and manage data assets](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-register-data-assets)  
- [Scaling to large datasets](https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target#scaling-to-large-datasets)

## Pregunta 50: M√©todos de autenticaci√≥n seg√∫n el destino de c√≥mputo

**Tipo:** Selecci√≥n m√∫ltiple  
**Tema:** Azure Machine Learning ‚Äì Despliegue y seguridad de servicios  
**Tecnolog√≠a:** Compatible con SDK v2  

---

### üß† Pregunta:

You use Azure Machine Learning to create machine learning models. You plan to deploy your models as web services using various compute targets.

You need to ensure that each deployment is configured to require authentication.

**Based on compute target, which authentication method should you configure?**  
To answer, select the appropriate authentication method from the drop-down menus.

---

### üßæ Opciones:

| Compute target                       | Authentication methods                             |
|-------------------------------------|----------------------------------------------------|
| Azure Container Instances (ACI)     | üîò Key authentication only                         |
| Azure Kubernetes Service (AKS)      | üîò Key or token authentication                     |

---

### ‚úÖ Respuesta Correcta:
- **ACI:** Key authentication only  
- **AKS:** Key or token authentication

---

### üßæ Explicaci√≥n:

En Azure Machine Learning, el m√©todo de autenticaci√≥n que se puede usar para los endpoints depende del destino de c√≥mputo que utilices para desplegar tu modelo:

#### üîê **Azure Container Instances (ACI)**

- **Solo admite autenticaci√≥n por clave (API key).**
- Esto significa que cualquier solicitud al endpoint deber√° incluir una clave predefinida.
- ACI es una opci√≥n ligera y temporal, ideal para pruebas o despliegues de bajo costo.
- No tiene soporte para tokens, lo cual lo limita para escenarios de autenticaci√≥n m√°s avanzada.

#### üß∞ **Azure Kubernetes Service (AKS)**

- **Admite autenticaci√≥n por clave o token.**
- Es m√°s avanzado, permite escalar din√°micamente e integrar GPUs o FPGAs.
- Soporta autenticaci√≥n por token mediante **Azure Machine Learning JSON Web Tokens (JWT)**, ideales para sesiones temporales y control granular de acceso.
- Tambi√©n puede seguir usando claves, seg√∫n lo prefieras.

---

### üìö Conocimientos necesarios para entender esta pregunta:

- En Azure ML, cuando despliegas modelos como endpoints (reales o de prueba), puedes controlar el **m√©todo de autenticaci√≥n** que regula el acceso.
- ACI = opci√≥n simple, ligera ‚Üí solo clave.  
- AKS = opci√≥n robusta, escalable ‚Üí clave o token.

---

### üìò Referencias oficiales:

- [Deploy ML models to ACI and AKS](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=python#authentication)  
- [Endpoint authentication options](https://learn.microsoft.com/en-us/azure/machine-learning/concept-endpoints#authentication)  

## Pregunta 51: Compute target adecuado para AutoML, pipelines y ML designer

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Azure Machine Learning ‚Äì Configuraci√≥n de entornos de entrenamiento  
**Tecnolog√≠a:** Compatible con SDK v2  

---

### üß† Pregunta:

You need to determine the appropriate compute specifications for a training workload.  
Your solution must support automated machine learning (AutoML), machine learning pipelines, and Azure Machine Learning designer.

**What should you do?**

---

### üîò Opciones:

- [x] Deploy an Azure Machine Learning compute cluster.  
- [ ] Install the Azure Machine Learning SDK on your local computer.  
- [ ] Create and deploy a remote virtual machine.  
- [ ] Deploy Azure Databricks as a compute target.

---

### ‚úÖ Respuesta Correcta:
**Deploy an Azure Machine Learning compute cluster.**

---

### üßæ Explicaci√≥n:

Un **Azure ML compute cluster** es el recurso adecuado cuando necesitas escalar trabajos de entrenamiento y soportar herramientas como:

- **AutoML**: automatiza el entrenamiento y ajuste de modelos ML.
- **ML Pipelines**: permite orquestar flujos de trabajo completos.
- **Azure ML Designer**: interfaz gr√°fica drag-and-drop para crear modelos sin escribir c√≥digo.

Estos clusters ofrecen capacidad el√°stica, m√∫ltiples nodos y se integran completamente en el workspace.

#### ‚ùå ¬øPor qu√© no las otras?

- **Azure ML SDK en tu equipo local**: solo sirve para desarrollo ligero o pruebas, no para workloads grandes ni para pipelines o ML Designer.
- **Remote VM**: no est√° integrada nativamente en Azure ML como compute target escalable.
- **Azure Databricks**: aunque permite AutoML y pipelines, **NO es compatible con ML Designer** y requiere configuraci√≥n adicional por fuera del portal.

---

### üìö Referencias:

- [Compute targets in Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target)  
- [Create compute cluster in Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-attach-compute-cluster)

## Pregunta 52: Pol√≠tica de terminaci√≥n temprana para HyperDrive

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Azure Machine Learning ‚Äì Hyperparameter Tuning  
**Tecnolog√≠a:** Compatible con SDK v2  

---

### üß† Pregunta:

You tune hyperparameters on your Hyperdrive Experiment based on Random sampling. You want to terminate 30 percent of the lowest performing runs at each evaluation interval, based on their performance of the primary metric.

You need to associate an early termination policy to your Hyperdrive Experiment.  
**Which termination policy should you use?**

---

### üîò Opciones:

- [ ] Median stopping policy  
- [ ] Bandit policy  
- [ ] No termination policy  
- [x] Truncation selection policy  

---

### ‚úÖ Respuesta Correcta:
**Truncation selection policy**

---

### üßæ Explicaci√≥n:

La pol√≠tica de **Truncation selection** cancela un porcentaje de las ejecuciones con peor rendimiento en intervalos de evaluaci√≥n definidos. Se recomienda cuando se quiere optimizar el uso de recursos eliminando ejecuciones poco prometedoras.

#### Esta pol√≠tica permite definir:
- `truncation_percentage`: porcentaje de ejecuciones a terminar (por ejemplo, 30%).
- `evaluation_interval`: cada cu√°ntas iteraciones se eval√∫an los modelos.
- `delay_evaluation`: cu√°ntas iteraciones esperar antes de empezar a evaluar.

---

### ‚ùå Opciones incorrectas:

- **Bandit policy**: termina ejecuciones usando un margen de holgura (slack factor), no un porcentaje. No cumple con el requerimiento de "terminar el 30% inferior".
- **Median stopping policy**: usa la mediana del rendimiento como referencia, pero **no permite definir un porcentaje** de terminaci√≥n expl√≠citamente.
- **No termination policy**: permite que todas las ejecuciones finalicen, incluso si su rendimiento es bajo. No es √∫til para optimizaci√≥n eficiente de recursos.

---

### üìö Referencias:

- [HyperDrive early termination policies](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters#early-termination-policies)

## Pregunta 53: Configuraci√≥n YAML para Azure Machine Learning Registry

**Tipo:** Selecci√≥n m√∫ltiple  
**Tema:** Azure Machine Learning ‚Äì Configuraci√≥n de registries  
**Tecnolog√≠a:** Compatible con SDK v2  

---

### üß† Pregunta:

You are planning to create an Azure Machine Learning registry to facilitate sharing machine learning assets across multiple workspaces.

You need to configure the registry using a YAML configuration file to be deployed via the Azure CLI.

**How should you complete the YAML configuration? To answer, select the appropriate options from the drop-down menus.**

---

### üìÑ YAML Final:

```yaml
name: Registry
tags:
  description: Configurations
  foo: bar
location: westus
replication_locations:
  - location: westus
    storage_config:
      storage_account_hns: False
      storage_account_type: Standard_LRS
```

---

### ‚úÖ Respuesta Correcta:
- `storage_account_hns: False`  
- `storage_account_type: Standard_LRS`

---

### üßæ Explicaci√≥n:

- `storage_account_hns` activa o desactiva el **Hierarchical Namespace (HNS)**, una funcionalidad necesaria cuando trabajas con Data Lake Storage Gen2 para manejar datos en un registry de ML de forma eficiente. Es clave para habilitar estructuras tipo directorio en los blobs.
- `storage_account_type` especifica el tipo de cuenta de almacenamiento. En este caso, `Standard_LRS` (Locally Redundant Storage) es ideal por su bajo costo y redundancia dentro de una sola regi√≥n.

No debes usar:

- ‚ùå `storage_blob_encryption`: se refiere al cifrado de blobs, pero no configura el namespace.
- ‚ùå `storage_account_tier`: define rendimiento y redundancia, pero no el namespace.
- ‚ùå `access_tier`: se usa para gesti√≥n de costos de almacenamiento (Hot, Cool, Archive).
- ‚ùå `replication_type`: como LRS o GRS, que no se usa en esta secci√≥n del YAML para registries.

---

### üìö Referencias:

- [Configure registries using YAML](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-registries?tabs=cli#yaml-config-file)
- [Azure Storage account types](https://learn.microsoft.com/en-us/azure/storage/common/storage-account-overview#types-of-storage-accounts)

## Pregunta 49: Configuraci√≥n de m√©trica primaria para clasificaci√≥n de sentimiento

**Tipo:** Selecci√≥n m√∫ltiple  
**Tema:** Azure Machine Learning ‚Äì M√©tricas y optimizaci√≥n de modelos  
**Tecnolog√≠a:** Compatible con SDK v2  

---

### üß† Pregunta:

You use Azure Machine Learning to generate models that will be used to classify the sentiment of customer reviews in text data.  

You need to ensure that model training is optimized for this task.

**Which two actions should you perform?** Each correct answer presents part of the solution.

---

### üîò Opciones:

- [ ] Set the primary metric goal to MINIMIZE.  
- [x] Set the primary metric goal to MAXIMIZE.  
- [x] Configure accuracy as the primary metric.  
- [ ] Configure Spearman correlation as the primary metric.  

---

### ‚úÖ Respuesta Correcta:
**Set the primary metric goal to MAXIMIZE**  
**Configure accuracy as the primary metric**

---

### üßæ Explicaci√≥n:

Dado que el objetivo es **clasificar el sentimiento de rese√±as en texto**, el problema es un **problema de clasificaci√≥n supervisada**, t√≠picamente con clases como *positivo*, *negativo* o *neutral*.

- üîº **MAXIMIZE**: Cuando usas m√©tricas como *accuracy*, *precision*, *recall*, etc., tu objetivo siempre ser√° **maximizarlas**, no minimizarlas.
- ‚úÖ **Accuracy** es una m√©trica cl√°sica para evaluar la calidad de un modelo de clasificaci√≥n. Mide qu√© proporci√≥n de predicciones fueron correctas.
- ‚ùå **MINIMIZE** solo se usa con m√©tricas como *log loss* o *root mean square error (RMSE)* en regresi√≥n.
- ‚ùå **Spearman correlation** es una m√©trica usada para modelos de regresi√≥n donde se busca preservar el orden de los valores, no para clasificaci√≥n.

---

### üìö Referencias:

- [Configure AutoML settings for classification](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#classification-settings)
- [Primary metric definitions in Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#primary-metric)

## Pregunta 51: Interpretaci√≥n del AUC en un modelo binario

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Azure Machine Learning ‚Äì Evaluaci√≥n de modelos  
**Tecnolog√≠a:** Compatible con SDK v2  

---

### üß† Pregunta:

You use an Azure Machine Learning designer to train a binary classification model.  
When you review the model's metrics in the Evaluate Model module, you notice that the Area Under the Curve (AUC) score is 0.4.  
You need to determine the accuracy of the outcomes based on the model AUC score.

**What should you conclude about the trained model?**

---

### üîò Opciones:

- [ ] The model correctly predicts the outcomes 60 percent of the time.  
- [ ] The model has a difference of 40 percent between False Positives and True Negatives.  
- [x] The model correctly predicts the outcomes less than 50 percent of the time.  
- [ ] The model outcomes have an average error rate of 0.4.

---

### ‚úÖ Respuesta Correcta:
**The model correctly predicts the outcomes less than 50 percent of the time.**

---

### üßæ Explicaci√≥n:

Un valor de **AUC (Area Under the Curve) de 0.4** indica que el modelo est√° **prediciendo peor que un modelo aleatorio**. Para un buen modelo de clasificaci√≥n binaria:

- Un **AUC cercano a 1.0** representa un modelo excelente.
- Un **AUC de 0.5** indica un modelo que **predice al azar** (sin valor predictivo).
- Un **AUC inferior a 0.5**, como 0.4, sugiere que el modelo es peor que aleatorio ‚Äî es decir, **predice correctamente menos del 50% de las veces**.

‚ùå Las otras opciones son incorrectas:
- **60% correcto** ser√≠a un AUC > 0.5.  
- **Diferencia entre FPs y TNs** no se mide con AUC.  
- **Error promedio de 0.4** tampoco tiene sentido: AUC ‚â† tasa de error promedio.

---

### üìö Referencias:

- [Azure Machine Learning: Model Evaluation and Threshold Manipulation](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-evaluate-models)  
- [Evaluate automated machine learning experiment results](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml#evaluate-your-model)


## Pregunta 52: Crear una nueva versi√≥n del dataset para bookmarking previo al retrain

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Azure Machine Learning ‚Äì Dataset versioning y gesti√≥n de datos  
**Tecnolog√≠a:** Compatible con SDK v1

---

### üß† Pregunta:

You use Azure Machine Learning to design and train machine learning models. You obtain new data and would like to use the data to retrain an existing machine learning model.

You need to bookmark the state of your data prior to retraining.

**What should you do?**

---

### üîò Opciones:

- [ ] Create and register a tabular dataset. Specify the new version name.  
- [x] Use the register method from the Dataset class to create a new dataset version.  
- [ ] Use the get_by_name method from the Dataset class. Increment the version parameter.  
- [ ] Create and register a new file dataset. Use the from_files method to specify the bookmarked data.

---

### ‚úÖ Respuesta Correcta:
**Use the register method from the Dataset class to create a new dataset version.**

---

### üßæ Explicaci√≥n:

Azure Machine Learning te permite registrar nuevas versiones de datasets usando el mismo nombre de dataset pero con diferentes estados (versiones). Esto es √∫til cuando se necesita **"marcar"** o **bookmark** el estado de los datos antes de un retraining.

Usar `register()` con `create_new_version=True` crea expl√≠citamente una nueva versi√≥n que act√∫a como referencia al estado actual de los datos. Esto es esencial para reproducibilidad y trazabilidad en experimentos.

#### ‚ùå Alternativas incorrectas:

- **`get_by_name()`** se usa para **recuperar** versiones existentes, no para crear una nueva.
- **Registrar un nuevo dataset tabular o desde archivos** implica crear un recurso completamente nuevo, no una versi√≥n del dataset existente. Esto va en contra de la idea de "versioning".

---

### üìö Referencias:

- [Register and version datasets - Microsoft Learn](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-register-datasets)
- [Dataset class (Azure SDK v1)](https://learn.microsoft.com/en-us/python/api/azureml-core/azureml.core.dataset.dataset?view=azure-ml-py)

## Pregunta 54: T√©cnica de interpretabilidad para Responsible AI (SDK v2)

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Interpretabilidad y Responsible AI  
**Tecnolog√≠a:** Azure ML SDK v2  

---

### üß† Pregunta:

Your organization uses Azure Machine Learning (ML) services.

You are using the Azure ML Python Software Development Kit (SDK) v2 for managing experiments.

You plan to use the Responsible AI dashboard and azureml-interpret to train interpretable models.

**Which interpretability technique should you use?**

---

### üîò Opciones:

- [ ] SHAP Tree Explainer  
- [ ] Mimic Explainer (Global Surrogate)  
- [ ] SHAP Deep Explainer  
- [x] Mimic Explainer (Global Surrogate) + SHAP tree  

---

### ‚úÖ Respuesta Correcta:
**Mimic Explainer (Global Surrogate) + SHAP tree**

---

### üßæ Explicaci√≥n:

Dado que est√°s usando **Azure ML SDK v2**, la t√©cnica correcta es:

**Mimic Explainer (Global Surrogate) + SHAP tree**, ya que:

- El **Mimic Explainer** entrena un modelo interpretable (como LightGBM) para imitar las predicciones de un modelo caja-negra.
- Se combina con el **SHAP Tree Explainer**, el cual se especializa en √°rboles de decisi√≥n y ensembles como LightGBM.
- Esta combinaci√≥n permite generar explicaciones **globales** y **locales** para el dashboard de Responsible AI en SDK v2.
- Esta t√©cnica es **agn√≥stica al modelo original** (es decir, se puede usar con modelos opacos).

#### Otras opciones:

- ‚ùå **SHAP Tree Explainer**: solo est√° disponible en SDK v1 y es espec√≠fico para √°rboles, sin el enfoque de surrogate.
- ‚ùå **SHAP Deep Explainer**: funciona solo con redes neuronales (TensorFlow/Keras) y est√° disponible solo en SDK v1.
- ‚ùå **Mimic Explainer (Global Surrogate)** solo: incompleto. No aprovecha la combinaci√≥n con SHAP tree para visualizaci√≥n detallada.

---

### üìö Referencias:

- [Interpretability in Responsible AI (SDK v2)](https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai)  
- [azureml-interpret package](https://learn.microsoft.com/en-us/python/api/azureml-interpret/azureml.interpret)  
- [SHAP Explainability in Azure](https://github.com/microsoft/responsible-ai-toolbox)  

## Pregunta 54-1: Registro de datos visuales y m√©tricas con MLflow

**Tipo:** Selecci√≥n m√∫ltiple con men√∫ desplegable  
**Tema:** Azure ML + MLflow ‚Äì Logging de resultados visuales  
**Tecnolog√≠a:** SDK v2  

---

### üß† Pregunta:

You use Azure Machine Learning to transform images and perform object detection within each image.  
The experiment output appears to be incorrect and you plan to use logs to troubleshoot experiment run errors.

You need to upload each transformed PNG image to the run record along with an array of RGB values from your transformation model.  
The images must be visible in the run record.

**Which logging method should you use to generate the required logging information?**  
To answer, select the appropriate options from the drop-down menus.

---

### üîΩ Opciones:
| Required logging information     | Logging method                           |
|----------------------------------|------------------------------------------|
| RGB array values                 | ‚óâ `mlflow.log_metric()`<br>‚óØ `mlflow.log_dict()`  |
| Transformed PNG image            | ‚óâ `mlflow.log_figure()`<br>‚óØ `mlflow.log_image()`  |
---

### ‚úÖ Respuestas Correctas:

- **RGB array values** ‚Üí `mlflow.log_dict()`
- **Transformed PNG image** ‚Üí `mlflow.log_image()`

---

### üßæ Explicaci√≥n:

- `mlflow.log_dict()` es el m√©todo adecuado para registrar estructuras complejas como diccionarios o arrays (por ejemplo, un arreglo RGB). Estos valores se guardan como artefactos `.json` dentro del experimento, lo que permite analizarlos posteriormente para depuraci√≥n y visualizaci√≥n.

- `mlflow.log_metric()` **no** es v√°lido para arrays. Solo acepta valores escalares como precisi√≥n, p√©rdida, etc.

- `mlflow.log_image()` es la opci√≥n correcta para guardar im√°genes transformadas (PNG) en el run record. Estas im√°genes estar√°n accesibles para revisi√≥n y debugging.

- `mlflow.log_figure()` est√° pensado para guardar visualizaciones generadas con librer√≠as como Matplotlib o Plotly, **no** im√°genes ya renderizadas como PNGs.

---

### üìö Referencias:

- [MLflow Logging Reference](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_dict)
- [Azure ML SDK v2 + MLflow Logging](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-log-data-mlflow?view=azureml-api-2)

## Pregunta 55: Despliegue de modelos con soporte GPU en tiempo real

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Azure Machine Learning ‚Äì Compute Targets  
**Tecnolog√≠a:** SDK v2  

---

### üß† Pregunta:

You create a deep learning classification model for processing large volume of image files.  
Your deployment compute target should support real-time inferencing. You want to ensure that you are able to conduct GPU-based inferencing for your model.  

You need to configure your deployment target for your inferencing model.  
**Which deployment compute target should you use?**

---

### üîò Opciones:

- ‚óØ Azure Container Instances (ACI)  
- ‚óØ Azure Machine Learning compute clusters  
- ‚óØ Azure Machine Learning compute instances  
- ‚úÖ Azure Kubernetes Service (AKS)

---

### ‚úÖ Respuesta correcta:

- **Azure Kubernetes Service (AKS)**

---

### üßæ Explicaci√≥n:

- AKS permite **crear instancias basadas en GPU** para desplegar modelos de inferencia en tiempo real.
- Es el target recomendado para producci√≥n, especialmente en tareas de deep learning con alto volumen de im√°genes.

#### ‚ùå ¬øPor qu√© no las otras?

- **ACI:** solo para pruebas/debugging, **no soporta GPU**.
- **Compute instances:** s√≠ soportan real-time inferencing, pero **sin GPU**.
- **Compute clusters:** s√≠ permiten GPU, pero est√°n enfocados en **inferencia por lotes**, **no tiempo real**.

---

### üìö Referencias:

- [Azure ML compute targets - Microsoft Learn](https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target)
- [Real-time inference in Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-azure-kubernetes-service)

## Pregunta 56: Reutilizaci√≥n de pipelines con nuevos datos de clientes

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Azure Machine Learning ‚Äì Pipelines  
**Tecnolog√≠a:** SDK v2  

---

### üß† Pregunta:

You use a published Azure Machine Learning pipeline to predict which customers should be targeted for marketing a new service offering.  
New customer information has been collected via a survey, and you need to tune your model using this data.  

**What should you do?**

---

### üîò Opciones:

- ‚óØ Create a new training pipeline. Specify a new dataset.  
- ‚óØ Change the pipeline concurrency parameter to 2.  
- ‚úÖ Reuse the pipeline. Change the dataset and parameters.  
- ‚óØ Convert the training pipeline into a real-time inference pipeline.

---

### ‚úÖ Respuesta correcta:

- **Reuse the pipeline. Change the dataset and parameters.**

---

### üßæ Explicaci√≥n:

- Azure Machine Learning pipelines permiten definir flujos de trabajo reutilizables.  
- Puedes registrar nuevos datasets para cada ejecuci√≥n del pipeline y ajustar par√°metros sin necesidad de reescribirlo todo.
- En este escenario, ya tienes un pipeline funcional y solo necesitas ajustar el modelo con nuevos datos ‚Üí ¬°reutil√≠zalo!

#### ‚ùå ¬øPor qu√© no las otras?

- **Crear nuevo pipeline:** innecesario si el flujo actual ya funciona.
- **Cambiar concurrencia:** no afecta el ajuste del modelo con nuevos datos.
- **Convertir a inferencia tiempo real:** no aplica, est√°s en fase de entrenamiento.

---

### üìö Referencias:

- [Create and manage Azure ML pipelines](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-your-first-pipeline)
- [ML pipelines reusability](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-pipelines)

## Pregunta 57: Atributo correcto para verificar si una imagen de instancia est√° actualizada

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Azure Machine Learning ‚Äì Compute Instance  
**Tecnolog√≠a:** SDK v2  

---

### üß† Pregunta:

Your organization uses Azure Machine Learning (ML) services.  

You have been tasked with creating and managing a compute instance in your Azure ML workspace.  
You use the Azure ML Python Software Development Kit (SDK) v2.  

You need to keep track of whether an instance image is current.  

**Which instance attribute should you use?**

---

### üîò Opciones:

- ‚óØ `state`  
- ‚óØ `last_operation`  
- ‚óØ `services`  
- ‚úÖ `os_image_metadata`

---

### ‚úÖ Respuesta correcta:

- **`os_image_metadata`**

---

### üßæ Explicaci√≥n:

- El atributo `os_image_metadata` permite verificar si la imagen del sistema operativo de la instancia est√° actualizada.  
- Microsoft lanza nuevas im√°genes de VM cada mes, pero una instancia ya creada **no se actualiza autom√°ticamente**, por eso es importante rastrear este dato si usas la instancia a largo plazo.
- Usando el atributo `instance.os_image_metadata` con SDK v2 puedes acceder a esa metadata para saber la versi√≥n del sistema operativo instalado.

#### ‚ùå ¬øPor qu√© no las otras?

- `state`: solo indica si la instancia est√° en ejecuci√≥n, detenida, etc., **no da informaci√≥n sobre la imagen del SO**.  
- `last_operation`: muestra la √∫ltima operaci√≥n ejecutada, **pero no sirve para auditar la imagen del sistema operativo**.  
- `services`: da informaci√≥n sobre los servicios activos en la instancia, **pero no sobre la imagen del sistema operativo**.

---

### üìö Referencias:

- [Create an Azure Machine Learning compute instance ‚Äì Microsoft Learn](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-manage-compute-instance)  
- [ComputeInstance Class ‚Äì SDK v2](https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.computeinstance)

## Pregunta 58: Conexi√≥n de Azure ML a base de datos Azure SQL

**Tipo:** Selecci√≥n m√∫ltiple con men√∫ desplegable  
**Tema:** Azure Machine Learning ‚Äì Conexiones externas y autenticaci√≥n  
**Tecnolog√≠a:** SDK v2  

---

### üß† Pregunta:

Your organization uses Azure Machine Learning (ML) services. You use Azure ML Python Software Development Kit (SDK) v2 to create and manage datastores and data assets.  

For a specific project, you have been tasked with connecting to an Azure SQL Database. You have written code, a part of which is exhibited below, to achieve the desired outcome.  

You need to make the data available in the Azure SQL DB to Azure ML Services.  

**How should you complete the code?**  
To answer, select the appropriate options from the drop-down menus.

---

### üîΩ Opciones:

| C√≥digo | Opciones |
|--------|----------|
| ``CODIGO EN LA PARTE INFERIOR DEL RECUADRO`` | **1¬∫ dropdown**:<br>`Workspace`, `WorkspaceKeys`, `WorkspaceConnection`<br><br>**2¬∫ dropdown**:<br>`UsernamePasswordConfiguration`,<br>`ServicePrincipalConfiguration`,<br>`AccessKeyConfiguration` |


```python
wps = [ ? ](name=name, 
          type="azure_sql_db",
          target=target,
          credentials=[ ? ](
              username="XXXX", 
              password="XXXX"
          ))
```

---

### ‚úÖ Respuestas Correctas:

- **Clase de conexi√≥n:** `WorkspaceConnection`  
- **Tipo de autenticaci√≥n:** `UsernamePasswordConfiguration`

---

### üßæ Explicaci√≥n:

Para establecer una conexi√≥n a una base de datos externa como Azure SQL DB desde Azure Machine Learning, debes:

- Usar la clase `WorkspaceConnection`, la cual define una conexi√≥n segura entre el workspace de ML y un recurso externo.  
- Utilizar `UsernamePasswordConfiguration` como el m√©todo de autenticaci√≥n, que almacena las credenciales necesarias (usuario y contrase√±a) para acceder a la base de datos.

#### ‚ùå Opciones incorrectas:

- `Workspace` sirve para inicializar el workspace, no para conexiones externas.  
- `WorkspaceKeys` se usa para almacenar claves para notebooks, no para conexiones a bases de datos.  
- `ServicePrincipalConfiguration` y `AccessKeyConfiguration` se usan para otros tipos de autenticaci√≥n que no aplican a este caso espec√≠fico.

---

### üìö Referencias:

- [Create connections (preview)](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-workspace-connections?view=azureml-api-2)  
- [WorkspaceConnection Class](https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.workspaceconnection?view=azure-python)

## Pregunta 61: Logging con MLflow y XGBoost ‚Äì Validaci√≥n de afirmaciones

**Tipo:** Selecci√≥n m√∫ltiple (S√≠ / No)  
**Tema:** MLflow ‚Äì Registro de modelos y firmas  
**Tecnolog√≠a:** Azure ML SDK v2 + MLflow + XGBoost  

---

### üß† Pregunta:

You are logging your trained machine learning models in Azure Machine Learning (ML) services using MLflow.  

You have written the code as exhibited below:

```python
import mlflow
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from mlflow.models import infer_signature
from mlflow.utils.environment import _mlflow_conda_env

mlflow.autolog(log_models=False)

model = XGBClassifier(use_label_encoder=False, eval_metric="logloss")
model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)
y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
signature = infer_signature(X_test, y_test)

custom_env = _mlflow_conda_env(
    additional_conda_deps=None,
    additional_pip_deps=["xgboost==1.5.2"],
    additional_conda_channels=None,
)
```
You need to implement the solution by validating appropriate components as part of the pipeline.
For each of the following statements, select Yes if the statement is true. Otherwise, select No.


| Statement                                                                 | ‚úÖ True | ‚ùå False |
|---------------------------------------------------------------------------|---------|----------|
| The code logs a machine learning model for an XGBoost classifier.         | ‚¨ú      | ‚¨ú       |
| The `infer_signature` method infers signatures from inputs/outputs.       | ‚¨ú      | ‚¨ú       |
| `mlflow.pyfunc` can be used to log an XGBoost classifier.                 | ‚¨ú      | ‚¨ú       |


‚úÖ Respuestas Correctas:
‚ùå La primera afirmaci√≥n es falsa: el modelo no se registra autom√°ticamente porque log_models=False.

‚úÖ La segunda es verdadera: infer_signature infiere correctamente las firmas de entrada y salida.

‚ùå La tercera es falsa: mlflow.pyfunc no se puede usar para loggear directamente un modelo XGBoost.

üßæ Explicaci√≥n:
mlflow.autolog(log_models=False) desactiva el registro autom√°tico del modelo, por eso no se guarda aunque s√≠ se loguean otros par√°metros.

infer_signature permite obtener autom√°ticamente la firma (inputs/outputs) del modelo a partir de datos reales.

mlflow.pyfunc sirve para loggear modelos personalizados que extienden PythonModel, lo cual no aplica para modelos ya soportados como XGBClassifier.

## Pregunta 62: Clasificaci√≥n de im√°genes con Azure ML ‚Äì Orden correcto de acciones

**Tipo:** Ordenamiento de pasos  
**Tema:** Azure ML ‚Äì Clasificaci√≥n de im√°genes  
**Tecnolog√≠a:** Azure Machine Learning Studio  

---

### üß† Pregunta:

You regularly use Azure to complete machine learning tasks.  

You need to perform machine learning assisted image classification for **1,000,000 images**. Each image is either of a **cat or a dog**.

**Which three actions should you perform in sequence?**  
To answer, move the appropriate actions from the list of possible actions to the answer area and arrange them in the correct order.

---

### üîΩ Acciones disponibles:

- Create an Azure Machine Learning workspace.  
- Define two datasets and split the images between each dataset.  
- Create a multi-label image classification project.  
- Create a multi-class image classification project.  

---

### ‚úÖ Orden correcto:

1. **Create an Azure Machine Learning workspace.**  
2. **Define two datasets and split the images between each dataset.**  
3. **Create a multi-class image classification project.**

---

### üßæ Explicaci√≥n:

- **Workspace**: Se necesita primero para gestionar los recursos y experimentos de Azure ML.  
- **Dataset**: Es esencial dividir las im√°genes para entrenamiento y validaci√≥n.  
- **Clasificaci√≥n multi-clase**: Este problema (gato vs. perro) implica **una sola clase por imagen**, por tanto es una **clasificaci√≥n multi-clase**, **no multi-label**.

---

### üìö Referencias:

- [Azure ML image classification projects](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models)  
- [Train with Azure ML datasets](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-datasets)

## Pregunta 59: Consulta de modelos registrados con MLflow 2.0

**Tipo:** Selecci√≥n √∫nica  
**Tema:** MLflow ‚Äì Registro y consulta de modelos  
**Tecnolog√≠a:** Azure ML SDK v2 + MLflow 2.0

---

### üß† Pregunta:

Your organization uses Azure Machine Learning (ML) services. You are tracking model training by using MLflow 2.0 and Azure ML Python Software Development Kit (SDK) v2.  

You need to query all the registered models in the registry using the MLflow client.  

**Which method should you use?**

---

### üîò Opciones:

- ‚óØ `search_model_versions`  
- ‚óØ `get_registered_model`  
- ‚ùå `list_registered_models`  
- ‚úÖ `search_registered_models`  

---

### ‚úÖ Respuesta correcta:

- **search_registered_models**

---

### üßæ Explicaci√≥n:

- En **MLflow 2.0**, el m√©todo recomendado para **consultar todos los modelos registrados** en el registro es `search_registered_models()`.
- Este m√©todo devuelve una lista de modelos registrados, incluyendo sus versiones, estados, y metadatos relevantes.
  
```python
for model in client.search_registered_models():
    print(model.name)
```

#### ‚ùå ¬øPor qu√© no las otras?

- `list_registered_models()`: Solo se usaba en versiones anteriores de MLflow (<2.0).
- `get_registered_model()`: Solo trae **una versi√≥n espec√≠fica** de un modelo.
- `search_model_versions()`: Se usa cuando necesitas buscar versiones espec√≠ficas de uno o m√°s modelos, no para listar todos.

---

### üìö Referencias:

- [MLflow Model Registry API Reference](https://mlflow.org/docs/latest/python_api/mlflow.tracking.html#mlflow.tracking.MlflowClient.search_registered_models)
- [MLflow 2.0 Updates](https://mlflow.org/docs/latest/releases.html#mlflow-2-0)

## Pregunta 61: M√©todo correcto para importar datos externos en un pipeline

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Azure ML ‚Äì Acceso a datos en pipelines  
**Tecnolog√≠a:** SDK v2  

---

### üß† Pregunta:

You are working on an Azure Machine Learning pipeline and need to access data for your model.  
The data is stored in an external location, but it is too large to be uploaded directly to the Azure Machine Learning workspace.

You need to use Python to access and incorporate information from an external source into the pipeline for use in your model.  

**Which method should you use?**

---

### üîò Opciones:

- ‚óØ `mlclient.data.import_data()`  
- ‚úÖ `mlclient.data.load()`  
- ‚óØ `mlclient.data.to_pandas_dataframe()`  
- ‚óØ `mlclient.data.merge()`

---

### ‚úÖ Respuesta correcta:

- **`mlclient.data.import_data()`**

---

### üßæ Explicaci√≥n:

- `mlclient.data.import_data()` es el m√©todo correcto en Azure ML SDK v2 para **traer datos desde una fuente externa** (como bases de datos, almacenamiento en la nube, HTTP endpoints, etc.) hacia el entorno de Azure ML y registrarlos como *data asset*.

#### ‚ùå Opciones incorrectas:

- `mlclient.data.load()` solo carga datos ya registrados en el workspace. No sirve para traerlos desde fuera.
- `mlclient.data.to_pandas_dataframe()` convierte un dataset en un DataFrame para su an√°lisis, pero **no lo importa** desde fuentes externas.
- `mlclient.data.merge()` es para unir m√∫ltiples data assets existentes, no para importar datos externos.

---

### üìö Referencias:

- [Import data assets (preview)](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-connect-data-python-sdk-v2#use-import_data-to-register-data-from-external-sources)

## Pregunta 64: Configuraci√≥n de entorno local con Anaconda para Azure ML

**Tipo:** Ordenar pasos  
**Tema:** Azure Machine Learning ‚Äì Configuraci√≥n local del entorno  
**Tecnolog√≠a:** SDK v2  

---

### üß† Pregunta:

You want to use your local computer as a development environment to work with Azure Machine Learning.  
You have decided to use Anaconda within your local environment. You want to leverage automated machine learning to tune hyperparameters for your training pipelines.  

You have downloaded and installed Anaconda with Python 3.7 version. You are at the Anaconda prompt.  
You need to create the environment to work with Azure Machine Learning.  

**Which five commands should you execute in sequence?**  
To answer, move the appropriate actions from the list of possible actions to the answer area and arrange them in the correct order.

---

### üß© Comandos posibles:

- `conda create -n devenv python=3.7.7`  
- `conda activate devenv`  
- `pip install azureml-sdk[notebooks,automl]`  
- `conda install notebook ipykernel`  
- `ipython kernel install --user --name devenv --display-name "Python (devenv)"`  
- `jupyter notebook`  
- `conda activate AzureML`  

---

### ‚úÖ Respuesta en orden correcto:

1. `conda create -n devenv python=3.7.7`  
2. `conda activate devenv`  
3. `pip install azureml-sdk[notebooks,automl]`  
4. `conda install notebook ipykernel`  
5. `ipython kernel install --user --name devenv --display-name "Python (devenv)"`  

---

### üßæ Explicaci√≥n:

- `conda create -n devenv python=3.7.7`: crea un nuevo entorno con Python 3.7.7  
- `conda activate devenv`: activa el entorno que acabas de crear  
- `pip install azureml-sdk[notebooks,automl]`: instala el SDK de Azure ML y los m√≥dulos necesarios para AutoML y notebooks  
- `conda install notebook ipykernel`: instala el kernel necesario para Jupyter  
- `ipython kernel install --user --name devenv --display-name "Python (devenv)"`: registra el entorno para usarlo en notebooks  

#### ‚ùå Opciones incorrectas:

- `jupyter notebook`: se usa para abrir notebooks, pero no es parte de la configuraci√≥n  
- `conda activate AzureML`: ese entorno no existe a menos que lo hayas creado previamente, y no es parte del flujo recomendado  

---

### üìö Referencias:

- [Azure ML local setup](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-environment#local-environment)  
- [SDK installation with pip](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-environment#install-the-azure-machine-learning-sdk)

## Pregunta 65: Configuraci√≥n de par√°metros en Azure ML

**Tipo:** Selecci√≥n m√∫ltiple  
**Tema:** Azure Machine Learning  
**Tecnolog√≠a:** SDK v2  

---

### üß† Pregunta:

You are using Azure Machine Learning to develop a custom machine learning model.  
You have prepared the following Python script to configure and submit your training job. You need to complete the inputs parameter to define --data-path for efficient data access during training.
Which code snippet should you use to complete this configuration?

EN CRISTIANO:

Complete el siguiente c√≥digo para configurar el par√°metro `data-path`:

```python
from azure.ai.ml import MLClient, Input
from azure.ai.ml.entities import Command
from azure.ai.ml.constants import AssetTypes
from azure.identity import DefaultAzureCredential

credential = DefaultAzureCredential()
ml_client = MLClient.from_config(credential=credential)

job = Command(
    code="../",
    command="python train.py --data-path ${{inputs.data_path}}",
    inputs={
        "data_path": Input(
            type=AssetTypes.MLTABLE,
            path="azureml://datastores/<datastore_name>/paths/<path>"
        )
    },
    compute="cpu-cluster",
    environment="training-env",
    experiment_name="custom-training-experiment"
)

ml_client.jobs.create_or_update(job)
```

---

### üß© Opciones:

1. [ ] `"data_path": "https://storage.blob.core.windows.net/container/path"`
2. [ ] `"data_path": "azureml://datastores/ds/paths/data"`
3. [ ] `"data_path": Input(type=AssetTypes.MLTABLE, path="azureml://datastores/ds/paths/data")`
4. [ ] `"data_path": Input(type=AssetTypes.URI_FOLDER, path="https://storage.blob.core.windows.net/container/path")`

---

### ‚úÖ Respuesta correcta:

**Opci√≥n 3**  
`Input(type=AssetTypes.MLTABLE, path="azureml://datastores/ds/paths/data")`

---

### üìö Explicaci√≥n:

El formato `MLTABLE` proporciona:
- Manejo optimizado de datos estructurados
- Soporte para metadatos y versionado
- Integraci√≥n completa con Azure ML

Las otras opciones son menos eficientes o no aprovechan las capacidades nativas de Azure ML.

<<<<<<<<<<<## Pregunta 66: Reducci√≥n de errores HTTP 503 en AKS

**Tipo:** Selecci√≥n m√∫ltiple  
**Tema:** Azure Kubernetes Service (AKS) ‚Äì Despliegue y escalado  
**Tecnolog√≠a:** Azure ML + AKS  

---

### üß† Pregunta:

You use Azure Machine Learning to deploy a machine learning model to an Azure Kubernetes Service (AKS) cluster. During testing, you receive a large number of HTTP 503 errors.  
You need to reduce the incidence of HTTP 503 errors.  

**Which three actions could you perform?** Each correct answer presents a complete solution.

---

### üîΩ Opciones:

- Modify the `autoscale_max_replicas` parameter.  
- Change the minimum number of replicas.  
- Change the utilization level at which instances autoscale up.  
- Migrate the service to an Azure Machine Learning compute cluster.  

---

### ‚úÖ Respuestas Correctas:

- ‚úÖ Change the minimum number of replicas.  
- ‚úÖ Change the utilization level at which instances autoscale up.  
- ‚úÖ Modify the `autoscale_max_replicas` parameter.  

---

### üßæ Explicaci√≥n:

- Puedes **cambiar el nivel de utilizaci√≥n** en el que las instancias se escalan autom√°ticamente. Por defecto, AKS escala cuando la utilizaci√≥n del cl√∫ster supera el 70%. Reducir este umbral permite escalar antes de que se saturen los recursos.  
- El error **HTTP 503** indica que el servicio est√° operativo, pero no puede atender solicitudes por falta de recursos.  
- Puedes **modificar `autoscale_max_replicas`** para permitir que el cl√∫ster maneje un mayor n√∫mero de solicitudes simult√°neas (por defecto AKS permite hasta 10 r√©plicas).  
- Tambi√©n puedes **cambiar el n√∫mero m√≠nimo de r√©plicas** que deben estar en l√≠nea para absorber picos de solicitudes. Por defecto esta en 1, se podria aumentar hasta un maximo de 10

#### ‚ùå Opciones incorrectas:

- ‚ùå **Migrar a un Azure ML compute cluster** no es recomendable, ya que este tipo de cl√∫steres no garantiza disponibilidad para producci√≥n.  
- ‚ùå **Aumentar el timeout de solicitud** no soluciona errores 503, sino errores 504.

---


### üìö Referencias:

- [Autoscale in AKS](https://learn.microsoft.com/en-us/azure/aks/autoscaler)  
- [Diagnose HTTP errors in Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-deployment)
## Pregunta 69: Env√≠o de notificaciones HTTP push desde Azure ML

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Azure Machine Learning ‚Äì Automatizaci√≥n y notificaciones  
**Tecnolog√≠a:** Event Grid  

---

### üß† Pregunta:

You manage an Azure Machine Learning workspace.  
You need to send an HTTP push notification to an external system when a machine learning model is registered or deployed in the workspace.  

**What should you do?**

---

### üîΩ Opciones:

- Create an event subscription and set the endpoint type to web hook.  
- Create a service principal and grant it access to your workspace.  
- Stream Azure Machine Learning metric information to Azure Event Hubs.  
- Deploy a real-time endpoint and specify a compute target.

---

### ‚úÖ Respuesta correcta:

- **Create an event subscription and set the endpoint type to web hook.**

---

### üßæ Explicaci√≥n:

Para enviar notificaciones HTTP push cuando se registre o despliegue un modelo, debes usar **Azure Event Grid** con una suscripci√≥n de eventos y configurar el destino como un **webhook**.  

Azure ML se integra con Event Grid para emitir eventos como registros de modelos o despliegues, y Event Grid permite enrutar estos eventos hacia m√∫ltiples destinos, como funciones, colas o webhooks externos.

#### ‚ùå Opciones incorrectas:

- **Stream Azure Machine Learning metric information to Azure Event Hubs**: Event Hubs est√° dise√±ado para an√°lisis de grandes vol√∫menes de datos, no para eventos discretos como los registrados en este caso.  
- **Create a service principal and grant it access to your workspace**: Esto se usa para autenticaci√≥n, pero no para automatizar notificaciones.  
- **Deploy a real-time endpoint and specify a compute target**: Esto es para exponer modelos como servicios, pero no emite notificaciones autom√°ticas.

---

### üìö Referencias:

- [Azure Event Grid Overview](https://learn.microsoft.com/en-us/azure/event-grid/overview)  
- [Azure Machine Learning Events](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-monitor-view-data#events)

## Pregunta 70: Validaci√≥n de Componentes en Azure ML Pipelines

**Tipo:** Verdadero/Falso  
**Tema:** Azure Machine Learning - Componentes de Pipeline  
**Tecnolog√≠a:** SDK v2  

---

### üß† Pregunta:

Your organization uses Azure Machine Learning (ML) services. You build an Azure ML pipeline using Python SDK v2 that performs image classification. The pipeline includes this data-preparation component:

```python
import os
from pathlib import Path
from mldesigner import command_component, Input, Output

@command_component(
    name="myprepfordata",
    version="1",
    display_name="Data for Preparation Component",
    description="Convert data to a CSV file",
    environment=dict(
        conda_file=Path(__file__).parent / "conda.yaml",
        image="mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04",
    ),
)
def prepare_data_component(
    input_data: Input(type="uri_folder"),
    training_data: Output(type="uri_folder"),
    test_data: Output(type="uri_folder"),
):
    # Implementation code here
    ...
```

**For each statement, select Yes if true or No if false:**

| Statement | Yes | No |
|-----------|-----|----|
| The `name` in the code is the unique identifier of the component | ‚óè | ‚óã |
| The `version` in the code can have multiple versions | ‚óè | ‚óã |
| The `environment` specifies a virtual machine image | ‚óã | ‚óè |

---

### ‚úÖ Explicaci√≥n:

1. **El `name` es el identificador √∫nico**  
   ‚óè Correcto: El nombre definido en `@command_component` identifica exclusivamente el componente en el pipeline.

2. **La `version` puede tener m√∫ltiples versiones**  
   ‚óè Correcto: Puedes registrar m√∫ltiples versiones (ej. "1", "2") del mismo componente.

3. **El `environment` especifica una imagen de m√°quina virtual**  
   ‚óã Incorrecto: El bloque `environment` especifica:
   - Imagen Docker (`mcr.microsoft.com/azureml/...`)
   - Archivo Conda (`conda.yaml`)  
   *No* se refiere a una VM de Azure.

---

### üìö Referencias:
- [Azure ML Components Documentation](https://learn.microsoft.com/en-us/azure/machine-learning/concept-component)
- [SDK v2 Environment Configuration](https://learn.microsoft.com/en-us/azure/machine-learning/reference-yaml-component-command)

## Pregunta 68: Pipeline de inferencia por lotes con Azure Machine Learning Designer

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Azure Machine Learning ‚Äì Inferencia por lotes  
**Tecnolog√≠a:** Azure ML Designer  

---

### üß† Pregunta:

You use Azure Machine Learning designer to create a batch inference pipeline.  
You plan to publish the pipeline using a web service.  

You need to ensure that the pipeline can make predictions on the new data supplied at runtime.  

**What should you do?**

---

### üîΩ Opciones:

- Create a parameter for your dataset.  
- Add the Convert to Dataset module to your pipeline.  
- Connect a different dataset to the pipeline.  
- **Publish the pipeline to a new endpoint.** ‚úÖ  

---

### ‚úÖ Respuesta correcta:

- **Create a parameter for your dataset.** ‚úÖ

---

### üßæ Explicaci√≥n:

- **Create a parameter for your dataset**  
  ‚úîÔ∏è Correcto. Esta opci√≥n permite que consumidores suministren un conjunto de datos al pipeline en tiempo de ejecuci√≥n. Es √∫til cuando se entrena un modelo con un dataset, pero se necesita hacer predicciones con nuevos datos en tiempo real.

- **Add the Convert to Dataset module**  
  ‚ùå Incorrecto. Este m√≥dulo se utiliza para normalizaci√≥n de datos y su reutilizaci√≥n en otros pipelines. No es relevante para entrada din√°mica de datos.

- **Connect a different dataset**  
  ‚ùå Incorrecto. Este proceso es manual y no automatiza el ingreso de datos en tiempo de ejecuci√≥n.

- **Publish the pipeline to a new endpoint**  
  ‚ùå Incorrecto. Publicar el pipeline lo expone como servicio web, pero no lo hace parametrizable por s√≠ solo.

---

### üìö Referencias:

- [Run batch predictions using Azure Machine Learning designer](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-designer-batch-inference)  
- [Convert to Dataset module](https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/convert-to-dataset)


## Pregunta 69: Configurar pol√≠tica de truncamiento para optimizar recursos en experimentos de Azure ML

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Azure Machine Learning ‚Äì Early termination policies  
**Tecnolog√≠a:** SDK v2  

---

### üß† Pregunta:

You are working on an Azure Machine Learning experiment that will perform image classification.  
You need to conserve resources by terminating the lowest 25 percent performing runs.  

**What should you do?**

---

### üß© Opciones:

- Create a BanditPolicy object.  
- Define a median stopping policy.  
- **Configure truncation selection.** ‚úÖ  
- Configure Bayesian sampling.  

---

### ‚úÖ Respuesta Correcta:

- ‚úÖ Configure truncation selection.

---

### üßæ Explicaci√≥n:

- **Truncation Selection Policy**: Esta pol√≠tica de finalizaci√≥n temprana cancela un porcentaje de ejecuciones con bajo rendimiento. La m√©trica de rendimiento se eval√∫a y se usa para terminar los jobs menos prometedores. Es ideal cuando quieres ahorrar recursos finalizando anticipadamente los peores candidatos.  
- **Median Stopping Policy**: Cancela ejecuciones cuyo rendimiento est√° por debajo de la mediana, pero no est√° enfocada a un porcentaje fijo como la truncation.  
- **BanditPolicy**: Termina jobs poco prometedores con base en una pol√≠tica de "desempe√±o con tolerancia", pero no es adecuada para este caso de uso espec√≠fico.  
- **Bayesian Sampling**: Es un m√©todo para seleccionar hiperpar√°metros, no se usa para terminaci√≥n temprana.

---

### üìö Referencias:


- [Early termination policies in Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters#early-termination-policies)
- [Azure Machine Learning SDK v2 Documentation](https://learn.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py)


## Pregunta 71: Ejecuci√≥n de pipeline por REST en Azure Machine Learning Designer

**Tipo:** Verdadero/Falso  
**Tema:** Azure Machine Learning - REST API y ejecuci√≥n de pipelines  
**Tecnolog√≠a:** Azure ML Designer  

---

### üß† Pregunta:

You are creating a batch prediction pipeline in the Azure Machine Learning (ML) designer.  
You have published a pipeline with a dataset parameter. The pipeline will use the trained model created in the training pipeline to score the dataset you provide as a parameter.  

You plan to submit the pipeline job using a REST endpoint, using the default pipeline.  

For each of the following statements, select Yes if the statement is true. Otherwise, select No.

---

### ‚úÖ Declaraciones:

| Statement | Yes | No |
|-----------|-----|----|
| You should mention a version number for your pipeline as a parameter in your REST API call when you execute it. | ‚óã | ‚óè |
| When you publish a pipeline, you can choose to make it the new default pipeline for that endpoint. | ‚óè | ‚óã |
| To make a REST call with the default pipeline, you will need an OAuth 2.0 bearer-type authentication header. | ‚óè | ‚óã |

---

### üßæ Explicaci√≥n:

1. **Versi√≥n del pipeline en REST API**  
   - ‚ùå Falso: No necesitas incluir un n√∫mero de versi√≥n si ya tienes un pipeline por defecto definido. Azure ML Designer usa ese por defecto autom√°ticamente.

2. **Pipeline por defecto al publicar**  
   - ‚úÖ Verdadero: Al publicar un pipeline, puedes marcarlo como predeterminado para su endpoint correspondiente.

3. **Autenticaci√≥n OAuth 2.0**  
   - ‚úÖ Verdadero: Para invocar un pipeline por REST, se necesita un header de autenticaci√≥n OAuth 2.0 tipo bearer para autorizar la llamada.

---

### üìö Referencias:

- [Run batch predictions using Azure Machine Learning designer](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-run-batch-predictions-designer?view=azureml-api-1&viewFallbackFrom=azureml-api-2)

## Pregunta 72: Especificaci√≥n de recurso de c√≥mputo para Pipeline en Azure ML

**Tipo:** Opci√≥n √∫nica  
**Tema:** Azure Machine Learning ‚Äì Configuraci√≥n de c√≥mputo en pipelines  
**Tecnolog√≠a:** SDK v2  

---

### üß† Pregunta:

You are a data scientist working on a large-scale machine learning project on Azure.  
You have created a pipeline job that needs to run on a powerful compute target to achieve high performance.  
You have determined that an Azure Synapse Spark compute resource would be the best compute resource to use for this task, as it can optimize performance and scalability.  
The pipeline job has to be run every day, and it is expected to take at least two hours to complete.  

The script is shown below:

```python
from azure.ai.ml import MLClient
from azure.ai.ml.entities import PipelineJob
from azure.identity import DefaultAzureCredential

cred = DefaultAzureCredential()
client = MLClient.from_config(credential=cred)

pipeline_job = PipelineJob(
    compute="spark-cluster-01"
)
```

ou need to specify the compute target in the pipeline job definition so that the pipeline runs on the desired Spark pool compute target.

Which class should you use?

‚úÖ Respuesta correcta:
PipelineJob

‚ùå Opciones incorrectas:
Compute
‚úò Esta clase representa un recurso de c√≥mputo, pero no se usa para asociarlo directamente a un PipelineJob.

MLClient
‚úò Se usa para conectarse al workspace y manejar recursos, pero no para definir el c√≥mputo del pipeline.

Model
‚úò Se usa para registrar y gestionar modelos, no para vincular c√≥mputo.

üßæ Explicaci√≥n:
En Azure ML SDK v2, el PipelineJob permite definir directamente el recurso de c√≥mputo usando el nombre del recurso configurado en el workspace.

Aunque Compute representa recursos disponibles, no es la clase que se usa en la definici√≥n del pipeline.

El nombre de c√≥mputo (como "spark-cluster-01") se pasa como string en el atributo compute del PipelineJob.

## Pregunta 73: Automatizaci√≥n del pipeline diario usando Azure Machine Learning

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Azure Machine Learning ‚Äì Automatizaci√≥n y ejecuci√≥n de pipelines  
**Tecnolog√≠a:** Azure CLI  

---

### üß† Pregunta:

You are a data scientist working for a company that stores large amounts of data on Azure.  
You want to automate the process of running a machine learning pipeline that processes this data and generates insights.

You need to recommend a solution that will schedule the pipeline job to run daily at a specific time using the Azure Machine Learning service.  
The solution must ensure effort is kept to a minimum and be as user-friendly as possible.

**Which solution should you recommend?**

---

### üîò Opciones:

- ‚óã Azure DevOps  
- ‚óè Azure Command-Line Interface (CLI)  
- ‚óã Azure Machine Learning SDK  
- ‚óã Azure Machine Learning studio  

---

### ‚úÖ Respuesta correcta:

- ‚óè Azure Command-Line Interface (CLI)

---

### üßæ Explicaci√≥n:

- **Azure CLI** permite automatizar la ejecuci√≥n de pipelines en AML de forma sencilla y multiplataforma.
- Puedes usar comandos como `az ml run submit-job` con archivos YAML para ejecutar y programar tareas.
- **La autenticaci√≥n integrada** mediante `az login` lo hace m√°s seguro y pr√°ctico.
- Requiere **m√≠nimo esfuerzo**, ideal para agendar ejecuciones autom√°ticas y repetitivas.

---

### üìö Referencias:

- [Schedule machine learning pipeline jobs](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-schedule-pipeline-jobs)

## Pregunta 75: Monitoreo de un cl√∫ster de HDInsight basado en Linux

**Tipo:** Selecci√≥n √∫nica  
**Tema:** Monitoreo y administraci√≥n de cl√∫steres HDInsight  
**Tecnolog√≠a:** Apache Ambari, Azure  

---

### üß† Pregunta:

You design and log a monitoring solution for a Linux-based Azure HDInsight solution that is used to analyze large volumes of data. Various operations will execute continuously on the cluster.  
You need the logging solution to be able to monitor the performance of the cluster. You want to minimize the configuration effort associated with implementing the monitoring solution.

**What should you use?**

---

### üîò Opciones:

- ‚óã Microsoft Sentinel  
- ‚úÖ Apache Ambari  
- ‚óã HDInsight .Net SDK  
- ‚óã Azure Log Analytics  

---

### ‚úÖ Explicaci√≥n:

- **Apache Ambari** es la herramienta recomendada porque simplifica la administraci√≥n y el monitoreo de cl√∫steres Hadoop. Viene preconfigurada en cl√∫steres HDInsight basados en Linux, lo que reduce el esfuerzo de configuraci√≥n.
- **Azure Log Analytics** requiere configuraci√≥n personalizada adicional para acceder a m√©tricas de rendimiento del cl√∫ster, lo que no es ideal si se busca minimizar el esfuerzo.
- **Microsoft Sentinel** es una soluci√≥n de SIEM, no est√° enfocada al monitoreo de rendimiento del cl√∫ster.
- **HDInsight .Net SDK** implicar√≠a crear un marco de trabajo personalizado para el logging, lo cual es menos eficiente que utilizar Ambari.

NOTA: una explicacion mas detallada. e est√°n diciendo que est√°s trabajando con un cl√∫ster de Azure HDInsight basado en Linux, el cual se usa para analizar grandes vol√∫menes de datos (por ejemplo, usando Spark, Hive, Hadoop, etc.).

El objetivo es:

Monitorear el rendimiento del cl√∫ster (uso de CPU, memoria, tareas, etc.).

Minimizar el esfuerzo de configuraci√≥n (no quieres algo que te obligue a escribir mucho c√≥digo o configurar cosas manualmente).

üß† ¬øQu√© necesitas saber antes de responder?
HDInsight es una plataforma de big data que usa tecnolog√≠as como Hadoop, Spark, Hive, etc.

Apache Ambari viene preinstalado y configurado con cl√∫steres HDInsight basados en Linux. Sirve para monitorear y administrar cl√∫steres Hadoop.

Azure tiene otras herramientas de monitoreo, pero no todas est√°n optimizadas para HDInsight ni ofrecen la facilidad de uso inmediato que ofrece Ambari.

‚ùå ¬øPor qu√© descartar las otras opciones?
1. Microsoft Sentinel
Es una soluci√≥n de seguridad SIEM (Security Information and Event Management).

Sirve para detectar amenazas y hacer an√°lisis forense, no para monitorear el rendimiento de un cl√∫ster de datos.

üîª Demasiado avanzada y no enfocada al rendimiento de HDInsight.

2. HDInsight .NET SDK
Es un kit de desarrollo para programadores .NET.

Implica programar y configurar manualmente el monitoreo ‚Üí alto esfuerzo.

üîª Va en contra del objetivo de minimizar la configuraci√≥n.

3. Azure Log Analytics
Es √∫til para logs de diagn√≥stico en general en Azure.

Se puede usar con HDInsight, pero requiere configuraci√≥n manual, como enrutar los logs al workspace.

üîª Es m√°s complejo y no viene preconfigurado.

‚úÖ ¬øPor qu√© la respuesta correcta es Apache Ambari?
Ya viene incluido y preconfigurado en cl√∫steres HDInsight en Linux.

Tiene una interfaz web sencilla y APIs REST para hacer monitoreo y administraci√≥n.

Permite monitorear el uso de recursos, el estado de los nodos, los trabajos que corren, etc.

üîù Es la opci√≥n con menor configuraci√≥n y especializada para este entorno.
---

### üìö Referencias:

- [Manage HDInsight clusters by using the Apache Ambari REST API](https://learn.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-manage-ambari-rest-api)

https://learn.microsoft.com/en-us/azure/sentinel/overview?tabs=azure-portal

https://learn.microsoft.com/en-us/dotnet/api/overview/azure/hdinsight?view=azure-dotnet

## Pregunta 76: An√°lisis de configuraci√≥n de programaci√≥n con CronTrigger en Azure ML SDK v2

**Tipo:** Verdadero/Falso  
**Tema:** Azure Machine Learning - Schedules  
**Tecnolog√≠a:** SDK v2 (Python)  

---

### üß† Pregunta:

Your organization uses Azure Machine Learning (ML) services. You are using the Azure ML Python Software Development Kit (SDK) v2 to manage ML experiments.

You have been tasked with scheduling ML pipeline jobs.

You have the following code that creates a schedule:

```python
schedule_name = "sched_cron_with_python_sdkv2"
schedule_start_time = datetime.utcnow()
cron_trigger = CronTrigger(
    expression="30 8 * * 2",
    start_time=schedule_start_time,
    time_zone="Pacific Standard Time",
)
job_schedule = JobSchedule(
    name=schedule_name, trigger=cron_trigger, create_job=pipeline_job
)
```
You are trying to understand the schedule configuration.

For each of the following statements, select Yes if the statement is true. Otherwise, select No.
## Schedule Configuration Evaluation

**Tipo:** Verdadero/Falso  
**Tema:** Programaci√≥n de Tareas en Azure  
**Tecnolog√≠a:** Azure Scheduler  

---

### üß† Pregunta:

Eval√∫a las siguientes afirmaciones sobre programaci√≥n de tareas:

| Statement | Yes | No |
|-----------|-----|----|
| The schedule fires at 8:30 A.M. on every Tuesday each month | ‚óè | ‚óã |
| If start_time is omitted, the start_time will be equal to the schedule creation time | ‚óè | ‚óã |
| If the recurrence is set to the 31st day of every month, in months with less than 31 days the schedule will automatically trigger on the 30th | ‚óã | ‚óè |

---

### ‚úÖ Explicaci√≥n:

1. **Programaci√≥n semanal**  
   ‚óè Correcto: Se puede configurar para ejecutarse cada martes a las 8:30 AM.

2. **Hora de inicio por defecto**  
   ‚óè Correcto: Cuando no se especifica `start_time`, usa la hora de creaci√≥n.

3. **D√≠as del mes variables**  
   ‚óã Incorrecto: Los schedules para d√≠as 31 no se ajustan autom√°ticamente al 30 en meses m√°s cortos (falla silenciosamente).

---

### üìö Referencias:
- [Azure Schedule Expressions](https://learn.microsoft.com/en-us/azure/scheduler/scheduler-concepts-terms)
- [Recurrence Best Practices](https://learn.microsoft.com/en-us/azure/architecture/best-practices/cron-jobs)

https://learn.microsoft.com/en-us/azure/machine-learning/how-to-schedule-pipeline-job?view=azureml-api-2&tabs=cliv2

https://learn.microsoft.com/en-us/azure/machine-learning/reference-yaml-schedule?view=azureml-api-2

## Pregunta 74: Despliegue de modelos de ML para procesamiento en el borde

**Tipo:** Selecci√≥n M√∫ltiple (Una respuesta correcta)  
**Tema:** Azure Machine Learning - Despliegue en IoT / Edge  
**Tecnolog√≠a:** Azure Stack Edge, IoT Edge, AKS, Azure Functions  

---

### üß† Pregunta:

Your organization uses field-based sensors to monitor electricity usage throughout its manufacturing facilities.  
You need to apply a machine learning model to data collected by your devices before it is shipped to the cloud.  
**What should you do?**

---

### ‚úÖ Respuesta Correcta:

**‚úÖ Create an IoT Edge module. Deploy the module and machine learning model using Azure Stack Edge.**

---

### üîç Opciones:

| Opci√≥n | ¬øCorrecta? | Justificaci√≥n |
|--------|------------|---------------|
| Install the Azure Machine Learning SDK package. Deploy your machine learning model as an app in Azure Functions. | ‚ùå | Azure Functions no es adecuado para escenarios de inferencia en tiempo real en dispositivos de borde. Este enfoque requiere personalizaci√≥n adicional con Docker y no es ideal para procesamiento previo al env√≠o a la nube. |
| Register your model in an Azure Machine Learning workspace. Deploy the model to Azure Kubernetes Service (AKS). | ‚ùå | AKS est√° dise√±ado para cargas de trabajo en la nube altamente escalables. No es adecuado para aplicar inferencia en dispositivos f√≠sicos antes de enviar los datos a la nube. |
| **Create an IoT Edge module. Deploy the module and machine learning model using Azure Stack Edge.** | ‚úÖ | Esta es la soluci√≥n correcta. Azure Stack Edge permite realizar inferencia de ML directamente en dispositivos IoT, filtrando, agregando y optimizando datos antes de enviarlos a la nube. Es hardware especializado para procesamiento local eficiente. |

---

### ‚úÖ Explicaci√≥n:

Para ejecutar inferencias de modelos de ML cerca de donde se generan los datos (en este caso, sensores de electricidad en plantas de manufactura), se necesita una soluci√≥n de **computaci√≥n en el borde (Edge Computing)**.

Azure Stack Edge es una plataforma **hardware-as-a-service** que permite el procesamiento local de datos, ideal para an√°lisis en tiempo real antes de transferirlos a la nube. Combina aceleraci√≥n por hardware y m√≥dulos IoT Edge que se integran directamente con Azure Machine Learning.

Las dem√°s opciones:

- **AKS** es ideal para cargas de trabajo escalables en la nube, no en dispositivos de campo.
- **Azure Functions** puede usarse con modelos contenedorizados, pero no est√° optimizado para inferencia en hardware local ni con aceleraci√≥n.
- **El SDK de Azure ML** y ejecuci√≥n local con Docker no ofrecen el rendimiento ni la integraci√≥n adecuados para producci√≥n en entornos de borde.

---

### üìö Referencias:

- [Azure Stack Edge Overview](https://learn.microsoft.com/en-us/azure/databox-online/)
- [Attach Kubernetes Anywhere (AKS)](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-attach-kubernetes-anywhere?view=azureml-api-2)
- [Azure Functions + Containers](https://learn.microsoft.com/en-us/azure/azure-functions/functions-how-to-custom-container?tabs=core-tools%2Cacr%2Cazure-cli2%2Cazure-cli&pivots=container-apps)
- [Deploy ML Models to Online Endpoints](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-online-endpoints?view=azureml-api-2&tabs=cli)

---

## Pregunta 78: Registro de m√©tricas en MLflow con SDK v2

**Tipo:** Selecci√≥n √∫nica  
**Tema:** MLflow Tracking en Azure Machine Learning  
**Tecnolog√≠a:** SDK v2 + MLflow  

---

### üß† Pregunta:

You are using Azure ML Python Software Development Kit (SDK) v2 to manage the projects. You are logging and tracking experiments using MLflow Tracking with jobs.

You need to capture the MLflow tracking capabilities directly in your training scripts.

What should you do?

---

### ‚úÖ Opciones:

- ‚≠ï Create an active experiment, use `mlflow.active_run()` to retrieve the run currently being used in the job, use `mlflow.log_metric` to log metrics and information, and then end the job.
- ‚úîÔ∏è Use `mlflow.autolog()` and then use `mlflow.log_metric` to log metrics and information.
- ‚≠ï Create an active experiment, use `mlflow.start_run()` to start the job, use `mlflow.log_metric` to log metrics and information, and then end the job.
- ‚≠ï Use `mlflow.autolog()` and then use `log_batch` to log metrics and information.

---

### ‚úÖ Explicaci√≥n:

La mejor pr√°ctica cuando trabajas con el SDK v2 y quieres registrar autom√°ticamente informaci√≥n del entrenamiento es usar `mlflow.autolog()`, ya que este m√©todo habilita autom√°ticamente el tracking de modelos, par√°metros, m√©tricas y artefactos para frameworks comunes como scikit-learn, TensorFlow, PyTorch, entre otros.

Luego, si deseas registrar manualmente m√©tricas adicionales, puedes complementar con `mlflow.log_metric()` sin necesidad de usar `start_run()` expl√≠citamente, ya que `autolog()` maneja eso internamente.

#### ‚ùå Opci√≥n 1:
Usar `mlflow.active_run()` es √∫til en notebooks o scripts interactivos, pero no es necesario ni ideal en scripts automatizados con `autolog`.

#### ‚úî Opci√≥n 2:
La combinaci√≥n de `mlflow.autolog()` + `mlflow.log_metric()` es adecuada, simple y eficiente para capturar el tracking en scripts de entrenamiento.

#### ‚ùå Opci√≥n 3:
Usar expl√≠citamente `mlflow.start_run()` es redundante cuando ya se usa `mlflow.autolog()`.

#### ‚ùå Opci√≥n 4:
`mlflow.log_batch()` se usa para registrar m√∫ltiples m√©tricas o valores al mismo tiempo, generalmente en casos donde se tiene una lista de valores o alta frecuencia. No es lo ideal para registros simples en este escenario.

---

### üìö Referencias:
- [Tracking metrics with MLflow in Azure ML (MS Docs)](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-log-view-metrics?view=azureml-api-2&tabs=interactive)  
- [MLflow Python API Reference](https://mlflow.org/docs/latest/api_reference/python_api/mlflow.html)

## Pregunta 79: Evaluaci√≥n de m√©tricas en modelos de clasificaci√≥n con AutoML

**Tipo:** Opci√≥n M√∫ltiple (una respuesta)  
**Tema:** Azure Machine Learning - AutoML  
**Tecnolog√≠a:** SDK v2  

---

### üß† Pregunta:

You evaluate Automated Machine Learning training results based on the metrics generated during the training run.  

The classification model you evaluate metrics for is used to predict the possibilities of a person getting a viral infection based on the location, gender, and age of an individual. The dataset available is highly imbalanced.  

You need to find the optimal metric to evaluate the efficiency of the model.  

**Which metric should you use?**

---

### ‚úÖ Opciones:

- ‚óã `normalized_root_mean_squared_error`
- ‚óè `AUC_Weighted`
- ‚óã `accuracy`
- ‚óã `log_loss`

---

### ‚úÖ Respuesta Correcta:
**AUC_Weighted**

---

### üß† Explicaci√≥n Detallada:

1. **AUC_Weighted**  
   ‚úîÔ∏è Correcto. Esta m√©trica es ideal para modelos de clasificaci√≥n especialmente cuando el conjunto de datos est√° desbalanceado (es decir, cuando hay una clase significativamente m√°s representada que otra).  
   `AUC_Weighted` es el promedio ponderado del AUC (√°rea bajo la curva ROC) para cada clase, ponderado por la cantidad de instancias reales en cada clase. Esta medida tiene en cuenta tanto la sensibilidad como la especificidad del modelo, y no se ve tan afectada por el desbalanceo como la precisi√≥n.

2. **accuracy**  
   ‚ùå Incorrecto. Aunque la precisi√≥n mide qu√© tan frecuentemente el modelo predice correctamente, no es fiable en datasets desbalanceados. Por ejemplo, si el 95% de los casos son negativos, un modelo que siempre predice ‚Äúnegativo‚Äù tendr√° 95% de precisi√≥n, pero no ser√° √∫til.

3. **normalized_root_mean_squared_error**  
   ‚ùå Incorrecto. Esta m√©trica es apropiada para modelos de **regresi√≥n**, no de clasificaci√≥n. Mide la diferencia entre valores reales y predichos, pero no aplica para tareas donde la predicci√≥n es una clase categ√≥rica.

4. **log_loss**  
   ‚ùå Aunque `log_loss` puede ser √∫til en problemas de clasificaci√≥n, no es tan robusta como `AUC_Weighted` en situaciones con desbalance de clases. Tiende a ser m√°s sensible a las predicciones de baja probabilidad.

---

### üìö Referencias:

- [Understanding automated ML metrics in Azure](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml?view=azureml-api-2)  
- [Evaluate Model - Azure ML Component Reference](https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/evaluate-model?view=azureml-api-2)

## Pregunta 80: Evaluaci√≥n de modelos con contrafactuales en Azure ML

**Tipo:** Verdadero/Falso  
**Tema:** Responsible AI ‚Äì Contrafactual What-If Analysis  
**Tecnolog√≠a:** Azure ML + DiCE + Responsible AI Dashboard  

---

### üß† Pregunta:

Tu organizaci√≥n utiliza los servicios de Azure Machine Learning. Est√°s construyendo un modelo de IA y deseas evaluarlo con base en el est√°ndar de Microsoft Responsible AI. Decides usar _model-driven insights_ disponibles a trav√©s del componente de _counterfactual what-if_ del dashboard de Responsible AI.

Planeas usar la librer√≠a **DiCE** para generar contrafactuales sobre un modelo tipo KD-Tree. Tienes el siguiente c√≥digo:

```python
m = dice_ml.Model(model=model, backend="sklearn")
exp = dice_ml.Dice(d, m, method="random")
e1 = exp.generate_counterfactuals(x_test[0:1], total_CFs=2, desired_class="opposite")
e1.visualize_as_dataframe(show_only_changes=True)
```

Necesitas generar puntajes de importancia de caracter√≠sticas usando un resumen de los contrafactuales generados.

Selecciona "Yes" si la afirmaci√≥n es verdadera. En caso contrario, selecciona "No".


| Statement | Yes | No |
|-----------|-----|----|
| DiCE is using a public training dataset and a pre-trained ML model | ‚óã | ‚óè |
| The `method="random"` parameter specifies the explanation method | ‚óè | ‚óã |
| The `show_only_changes` parameter shows the full feature values for the counterfactuals | ‚óã | ‚óè |

---

### ‚úÖ Explicaci√≥n detallada:

#### 1. **Uso de dataset p√∫blico y modelo pre-entrenado** ‚ùå FALSO
   - **Justificaci√≥n**: 
     - DiCE no requiere datasets p√∫blicos por defecto
     - El c√≥digo muestra uso de un modelo personalizado (`model=model`) y datos propios (`x_test`)
     - KD-Tree (que s√≠ requiere datos p√∫blicos) no est√° siendo usado en este caso
     - El backend especificado (`"sklearn"`) indica un modelo custom, no pre-entrenado

#### 2. **Par√°metro `method="random"`** ‚úÖ VERDADERO
   - **M√©todos disponibles**:
     ```python
     "random": B√∫squeda aleatoria
     "genetic": Algoritmos gen√©ticos
     "kdtree": KD-Tree (para datos p√∫blicos)
     ```
   - **Confirmaci√≥n**: El valor "random" selecciona expl√≠citamente este m√©todo

#### 3. **Par√°metro `show_only_changes`** ‚ùå FALSO
   - **Comportamiento real**:
     ```python
     show_only_changes=True ‚Üí Muestra solo caracter√≠sticas modificadas
     show_only_changes=False ‚Üí Muestra todos los valores
     ```
   - **En el c√≥digo**: No se especifica, por lo que usa el valor por defecto (True)

---

### üìò Conceptos Clave:

| T√©rmino | Definici√≥n |
|---------|------------|
| **DiCE** | Librer√≠a para generar contrafactuales que muestran cambios m√≠nimos para alterar predicciones |
| **Contrafactuales** | "¬øQu√© cambiar√≠a si...?" Ej: "Si el ingreso fuera $500 mayor, el cr√©dito ser√≠a aprobado" |
| **Responsible AI Dashboard** | Suite de herramientas Azure para evaluar equidad, explicabilidad y errores |
| **KD-Tree** | Estructura de datos para b√∫squeda eficiente (incompatible con datos privados en DiCE) |


### Understanding the questions itself
üß† ¬øQu√© te est√°n preguntando?
Te est√°n diciendo que tienes un modelo de aprendizaje autom√°tico y que quieres evaluarlo √©ticamente usando las buenas pr√°cticas del est√°ndar de IA Responsable de Microsoft.

Para eso, usas un componente llamado ‚ÄúCounterfactual What-If‚Äù (lo encuentras dentro del Responsible AI dashboard). Este componente permite generar ejemplos alternativos que te ayuden a entender qu√© tendr√≠a que cambiar en una entrada para que el modelo diera un resultado diferente.

Entonces:
üëâ Vas a usar DiCE (una librer√≠a de Python) para generar ejemplos contrafactuales de entrada, y luego interpretar c√≥mo el modelo toma decisiones

üß™ ¬øQu√© es un ejemplo contrafactual?
Un contrafactual es una versi√≥n modificada de un dato real, con peque√±os cambios, pero que logra un resultado diferente.
Por ejemplo:

|Edad	|Ingreso|	Resultado actual|	Resultado contrafactual|
|---|---|---|---|
|30|	2000|	‚ùå Cr√©dito denegado|	‚úÖ Cr√©dito aprobado|

La idea es: ¬øQu√© cambios m√≠nimos necesita una persona para que el modelo cambie de opini√≥n? Esa es la base de la explicabilidad contrafactual.

¬øQu√© hace el c√≥digo?

```python
m = dice_ml.Model(model=model, backend="sklearn")
```
Aqu√≠ defines el modelo que vas a usar. El modelo est√° entrenado previamente (t√∫ lo creaste) y usas sklearn como backend.

```python
exp = dice_ml.Dice(d, m, method="random")  
```
Aqu√≠ creas el objeto que va a generar contrafactuales. Le dices que lo haga usando el m√©todo aleatorio ("random").

```python
e1 = exp.generate_counterfactuals(
    x_test[0:1],
    total_CFs=2,
    desired_class="opposite"
)
```

Esto dice:
‚û°Ô∏è Para el primer dato en x_test, genera 2 contrafactuales que cambien la predicci√≥n (por ejemplo, de ‚Äúno‚Äù a ‚Äús√≠‚Äù).


```python
e1.visualize_as_dataframe(show_only_changes=True)
```
Esto imprime los contrafactuales mostrando solo lo que cambi√≥ respecto al dato original.


### üéì ¬øQu√© necesitas recordar para este tipo de preguntas?
Responsible AI dashboard tiene una herramienta que usa contrafactuales para entender decisiones del modelo.

DiCE es una librer√≠a que puede generar estos contrafactuales.

method="random" te dice c√≥mo se generan: aleatoriamente.

show_only_changes=True solo muestra las columnas que cambiaron.

No todos los modelos ni datasets son p√∫blicos, y t√∫ decides qu√© modelo pasarle.



---


### üìö Referencias:
- [Documentaci√≥n oficial de DiCE](https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai?view=azureml-api-2)
- [Azure Responsible AI](https://learn.microsoft.com/en-us/azure/machine-learning/concept-counterfactual-analysis?view=azureml-api-2)
## Pregunta 82: An√°lisis de ejecuci√≥n de trabajos con Azure ML SDK v2

**Tipo:** Verdadero/Falso  
**Tema:** Azure Machine Learning - Command Jobs  
**Tecnolog√≠a:** Azure ML SDK v2  

---

### üß† Pregunta:

You are training a model using Azure ML Python Software Development Kit (SDK) v2.

You write the following script:

```python
from azure.ai.ml import command, Input

command_job = command(
    code="./src",
    command="python main.py --iris-csv ${{inputs.iris_csv}} --learning-rate ${{inputs.learning_rate}} --boosting ${{inputs.boosting}}",
    environment="AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu@latest",
    inputs={
        "iris_csv": Input(
            type="uri_file",
            path="https://mymlcode.blob.core.windows.net/mydatasets/iris.csv",
        ),
        "learning_rate": 0.4,
        "boosting": "gbdt",
    },
    compute="cpu-cluster",
)

returned_job = ml_client.jobs.create_or_update(command_job)

```
You need to validate what each line in the configuration means.

## Evaluaci√≥n de Configuraci√≥n en Azure ML

**Tipo:** Verdadero/Falso  
**Tema:** Azure Machine Learning - SDK v2  

---

### üß† Pregunta:

Eval√∫a las siguientes afirmaciones sobre configuraci√≥n de jobs en Azure ML:

| Statement | Yes | No |
|-----------|-----|----|
| El par√°metro `"code"` representa el comando que necesita ejecutarse | ‚óã | ‚óè |
| El par√°metro `"environment"` representa una imagen curada proporcionada por Azure ML | ‚óè | ‚óã |
| El estado actual del job puede verificarse usando `returned_job.status` | ‚óè | ‚óã |

---

### ‚úÖ Explicaci√≥n:

1. **Sobre el par√°metro `code`** ‚ùå Falso  
   - `code="./src"` especifica la ubicaci√≥n del c√≥digo fuente, no el comando a ejecutar
   - El comando real se define en el par√°metro `command`

2. **Sobre el par√°metro `environment`** ‚úÖ Verdadero  
   - `"AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu@latest"` es un entorno curado por Azure ML
   - Incluye todas las dependencias necesarias preconfiguradas

3. **Sobre el monitoreo del job** ‚úÖ Verdadero  
   - `returned_job.status` proporciona el estado actual (Running, Completed, Failed, etc.)
   - Alternativa: Verificar en Azure ML Studio UI

---

### üìö Referencias:
- [Documentaci√≥n oficial de Azure ML Jobs](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-train-model?view=azureml-api-2&tabs=python)
- [Entornos curados en Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/overview-what-is-azure-machine-learning?view=azureml-api-2s)

## Pregunta 83: Tareas de ML seg√∫n el tipo de recurso computacional

**Tipo:** Selecci√≥n m√∫ltiple (Drop-down)  
**Tema:** Azure Machine Learning Designer v2 ‚Äì Compute Targets  
**Tecnolog√≠a:** SDK v2  

---

### üß† Pregunta:

You use Azure Machine Learning Designer v2 to create and publish machine learning pipelines as web services.

You need to configure the correct machine learning task for each compute target.

**Based on the compute target, which machine learning task should you perform?**

> To answer, select the most appropriate machine learning task from the drop-down menus.

---

### ‚úÖ Respuestas correctas:

| Compute Target                                 | ML Task         |
|------------------------------------------------|-----------------|
| Azure Machine Learning compute cluster         | Training only   |
| Azure Machine Learning compute instance        | Training only   |
| Azure Kubernetes Service (AKS)                 | Deployment only |

---

### üß† Explicaci√≥n:

**1. Azure Machine Learning Compute Cluster ‚Äì Solo entrenamiento:**  
Los *compute clusters* son cl√∫steres escalables de m√°quinas virtuales dise√±ados para tareas de entrenamiento de modelos. Pueden escalar desde cero hasta cientos de nodos, lo que los hace ideales para cargas de trabajo intensivas como pipelines de entrenamiento. Sin embargo, no est√°n dise√±ados para despliegue en producci√≥n.

**2. Azure Machine Learning Compute Instance ‚Äì Solo entrenamiento:**  
Un *compute instance* es una m√°quina virtual administrada individualmente. Se utiliza normalmente para desarrollo y pruebas, y tambi√©n puede ejecutar pipelines de entrenamiento. Pero **no** es compatible con el despliegue de pipelines en Azure ML Designer v2.

**3. Azure Kubernetes Service (AKS) ‚Äì Solo despliegue:**  
AKS est√° pensado para tareas de **despliegue en producci√≥n** en tiempo real. Permite escalar autom√°ticamente seg√∫n la carga de trabajo, y soporta recursos intensivos como GPU y FPGAs. Es el target ideal para modelos entrenados que se van a servir como endpoints.

---

### üìö Referencias:

- [Azure ML Designer - Concept](https://learn.microsoft.com/en-us/azure/machine-learning/concept-designer?view=azureml-api-2)  
- [Compute targets in Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target?view=azureml-api-2)


##  Question 85: Sobol parameter sampling method

You are using **Azure Machine Learning SDK v2** to manage experiments.

You are performing **hyperparameter tuning** and need to use the **Sobol parameter sampling method** over the hyperparameter space.

#### üí° Question
Which sampling class should you use?

- [ ] RandomParameterSampling  
- [ ] GridParameterSampling  
- [ ] BayesianParameterSampling  
- ‚úÖ **Correct answer**: `RandomParameterSampling`

---

### ‚úÖ Explanation

To use **Sobol sampling** in Azure ML SDK v2, you must use the `RandomParameterSampling` class with the `rule="sobol"` argument.

```python
from azure.ai.ml.sweep import RandomParameterSampling

sweep_job = command_job_for_sweep.sweep(
    compute="cpu-cluster",
    sampling_algorithm=RandomParameterSampling(
        seed=341,
        rule="sobol"  # ‚úÖ this specifies the Sobol sampling method
    ),
)
```

``El truco esta en que Sobol es una regla del RandomParameterSampling,solo de esa clase en particular.``

El m√©todo Sobol es una t√©cnica de muestreo cuasi-aleatorio que se basa en secuencias Sobol. Es √∫til cuando quieres cubrir un espacio de b√∫squeda de forma m√°s uniforme y reproducible que el muestreo aleatorio puro.

### ‚ùå Why the others are wrong:
GridParameterSampling: This performs exhaustive search over all combinations and is not compatible with Sobol, which requires stochastic sampling.

BayesianParameterSampling: This is based on Bayesian optimization and learns from previous samples ‚Äî you cannot combine it with Sobol.

### üìö References

- [üîó Hyperparameter tuning a model (v2)](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters?view=azureml-api-2)  
- [üîó RandomParameterSampling Class](https://learn.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.randomparametersampling?view=azure-ml-py)  
- [üîó GridParameterSampling Class](https://learn.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.gridparametersampling?view=azure-ml-py)  
- [üîó BayesianParameterSampling Class](https://learn.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.bayesianparametersampling?view=azure-ml-py)

## Pregunta 86 - Azure CLI: Automatizar creaci√≥n de recursos ML

**Contexto:**  
Est√°s automatizando la creaci√≥n de un **Azure Machine Learning workspace** y recursos de c√≥mputo para entrenamiento usando la **CLI de Azure** (Azure Command-Line Interface). Ya has instalado el CLI y has iniciado sesi√≥n.

Necesitas ejecutar comandos de Azure ML por primera vez, as√≠ que debes completar el script de automatizaci√≥n para crear un espacio de trabajo y los recursos de c√≥mputo asociados.

---

### ‚ùì ¬øQu√© tres comandos debes usar en secuencia?

Ordena los comandos correctos desde la lista de posibles comandos:

#### ‚úÖ Respuesta correcta en orden:

1. `az extension add -n azure-cli-ml`  
2. `az ml workspace create -w <workspace-name> -g <resource-group-name>`  
3. `az ml compute create --name <compute-name> --workspace-name <workspace-name> --resource-group <resource-group-name> [otros par√°metros]`

---

### üìò Explicaci√≥n detallada

#### üîπ 1. `az extension add -n azure-cli-ml`
Antes de poder usar cualquier comando de ML (como `az ml workspace`), necesitas registrar la extensi√≥n de Machine Learning con el CLI. Esto a√±ade soporte para comandos como `az ml compute`, `az ml job`, `az ml environment`, etc.

#### üîπ 2. `az ml workspace create`
Este comando crea un nuevo **espacio de trabajo** de Azure ML dentro de un **grupo de recursos existente**. Es un paso esencial para usar cualquier servicio de Azure ML.  
Par√°metros:
- `-w` es el nombre del workspace.
- `-g` es el grupo de recursos donde se va a crear.

#### üîπ 3. `az ml compute create`
Este comando crea un **target de c√≥mputo** (por ejemplo, un cluster para entrenamiento).  
Par√°metros clave:
- `--name` ‚Üí nombre del recurso de c√≥mputo.
- `--workspace-name` ‚Üí el workspace donde se va a alojar.
- `--resource-group` ‚Üí grupo de recursos correspondiente.

---

### ‚ùå Comandos incorrectos y por qu√©

- `az ml workspace list`:  
  Este comando **solo muestra** los workspaces existentes. **No crea nada**.

- `az ml workspace update -w -g`:  
  Este comando **actualiza** un workspace ya existente, pero no lo crea. No es √∫til si el objetivo es crear un nuevo workspace.

---

### üìé Referencias oficiales

- [Documentaci√≥n oficial de CLI - Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace-cli?view=azureml-api-2)
- [Azure CLI - `az ml` comandos](https://learn.microsoft.com/en-us/cli/azure/ml?view=azure-cli-latest)

---

## Pregunta 87: Configurar un trabajo en Azure ML para que se ejecute en paralelo

### üß† Pregunta
You are working on an Azure Machine pipeline job. You have access to a compute target and a dataset that contains the data you need to train your model. You have imported all necessary packages in Python.

You need to set up the execution environment so that you can run multiple experiments in parallel and monitor the performance of each experiment.

**Which of the following Python SDK attributes should you use?**

- job.inputs  
- job.compute ‚úÖ  
- job.environment  
- job.services

---

### ‚úÖ Respuesta correcta
**`job.compute`**

---

### üß© Explicaci√≥n

#### üîπ Contexto:
Est√°s configurando un **pipeline job** en Azure Machine Learning utilizando el **SDK de Python v2**. Este tipo de trabajos permite orquestar pasos como preparaci√≥n de datos, entrenamiento y evaluaci√≥n de modelos. Es crucial definir **d√≥nde** (en qu√© recurso de c√≥mputo) se ejecutar√° cada paso del pipeline para poder correr m√∫ltiples experimentos en paralelo.

---

### üîß ¬øQu√© hace `job.compute`?

```python
job.compute = "nombre-de-tu-cluster"
```

Este atributo define expl√≠citamente el recurso de c√≥mputo (por ejemplo, un cluster o instancia) donde debe ejecutarse el trabajo.

Es compatible con CommandJob, PipelineJob, SweepJob, etc.

Es la forma moderna (SDK v2) de reemplazar runconfig.target = "my-compute" del SDK v1.

### ‚ùå Opciones incorrectas
üî∏ job.inputs
Define los datos o par√°metros que necesita tu pipeline.

No controla d√≥nde se ejecuta el pipeline.

Ejemplo:

```python
job.inputs = {
    "training_data": Input(type="uri_file", path="azureml:my_data:1")
}
```
üî∏ job.environment
Define el entorno de ejecuci√≥n (imagen Docker, dependencias).

Controla el c√≥mo se ejecuta el trabajo, no el d√≥nde.

üî∏ job.services
Se usa para exponer servicios de inferencia despu√©s del entrenamiento, como puntos finales.

No es relevante para definir computaci√≥n paralela ni entrenamiento.

### üß™ SDK usado
Azure ML SDK v2 (moderno)
Se puede reconocer porque:

Usa objetos como CommandJob, PipelineJob.

No usa run_config, Experiment o ScriptRunConfig (que son de SDK v1).

Usa m√©todos como job.compute, job.inputs, ml_client.jobs.create_or_update().

### üìò Referencias

- [Run a job in Azure ML with SDK v2](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-train-cli)
- [Train models with pipelines (SDK v2)](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-machine-learning-pipelines)
- [PipelineJob class (SDK v2)](https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.pipelinejob)
- [Set compute target for jobs](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets)


## Pregunta 89

**Tipo:** Selecci√≥n de opciones en lista desplegable  
**Tema:** Azure CLI ‚Äì Creaci√≥n de un workspace de Azure Machine Learning

---

### Enunciado:

You need to create an Azure Machine Learning workspace using Azure Cloud Shell.  
How should you complete the command? To answer, select the appropriate options from the drop-down menus.

---

### Comando esperado:

```bash
az ml workspace create -w AML-Workspace -g AML-ResourceGroup
```	

Opciones correctas:
Primer men√∫ desplegable: -w

Segundo men√∫ desplegable: -g

Explicaci√≥n:
Para crear un workspace de Azure Machine Learning desde el Azure Cloud Shell usando la Azure CLI, debes especificar:

-w (o --workspace-name): Este par√°metro indica el nombre del workspace a crear.

-g (o --resource-group): Indica el grupo de recursos en el que se ubicar√° el workspace. Este grupo de recursos debe existir antes de ejecutar el comando.

Opciones incorrectas y por qu√©:
--sku: Define la edici√≥n del workspace (Basic o Enterprise), pero no es obligatoria (por defecto se usa Basic).

-l: Especifica la regi√≥n donde se ubicar√° el workspace. Aunque puede ser √∫til, no es obligatorio en este contexto.

--keyvault: Especifica un Azure Key Vault para gestionar credenciales, pero no es requerido para crear el workspace.

## ‚ùì Question 90

You are configuring an advanced model monitoring setup in Azure Machine Learning for a company to track data drift and quality for a fraud detection model deployed in production. The company wants to track changes over time in sensitive attributes related to the model‚Äôs inputs, ensuring that monitoring reflects any critical shifts affecting reliability and model performance accuracy.

You need to adjust the configuration to fulfill the company‚Äôs requirement.

```python
from azure.ai.ml import Input, MLClient
from azure.ai.ml.constants import MonitorDatasetContext
from azure.ai.ml.entities import (
    DataDriftSignal, DataDriftMetricThreshold, NumericalDriftMetrics,
    CategoricalDriftMetrics, MonitorFeatureFilter, ProductionData, ReferenceData,
    MonitorDefinition, MonitorSchedule, RecurrenceTrigger
)

ml_client = MLClient(InteractiveBrowserCredential(), subscription_id, resource_group, workspace)

production_data = ProductionData(
    input_data=Input(type="uri_folder", path="azureml:my_model_production_data:1"),
    data_context=MonitorDatasetContext.MODEL_INPUTS
)

reference_data_training = ReferenceData(
    input_data=Input(type="mltable", path="azureml:my_model_training_data:1"),
    data_context=MonitorDatasetContext.TRAINING
)

features = MonitorFeatureFilter(top_n_feature_importance=20)

drift_thresholds = DataDriftMetricThreshold(
    numerical=NumericalDriftMetrics(jensen_shannon_distance=0.01),
    categorical=CategoricalDriftMetrics(pearsons_chi_squared_test=0.02)
)

data_drift_signal = DataDriftSignal(
    production_data=production_data,
    reference_data=reference_data_training,
    features=features,
    metric_thresholds=drift_thresholds
)

monitor_definition = MonitorDefinition(
    monitoring_signals={'data_drift': data_drift_signal}
)

trigger = RecurrenceTrigger(frequency="day", interval=1)

model_monitor = MonitorSchedule(
    name="fraud_detection_model_monitoring_advanced",
    trigger=trigger,
    create_monitor=monitor_definition
)

poller = ml_client.schedules.begin_create_or_update(model_monitor)
created_monitor = poller.result()
```

### ‚úÖ Correct Answer:
Use MonitorFeatureFilter with feature lists representing key input data segments.

### ‚ùå Incorrect Options:
Add a target_column parameter in ReferenceData.

Set alert_enabled to True for DataQualitySignal.

Specify data_context as MODEL_OUTPUTS for ProductionData.

### üß† Explanation:
The correct configuration ensures that sensitive input segments are monitored for drift. This is done using MonitorFeatureFilter, which isolates key features known to influence model decisions and ensures any critical shift in these features will be detected.

MonitorFeatureFilter(top_n_feature_importance=20) ensures only the top 20 features are monitored.

Setting data_context=MonitorDatasetContext.MODEL_INPUTS ensures that input features, not outputs, are being tracked.

DataDriftMetricThreshold uses statistical tests:

Jensen-Shannon Distance for numerical features.

Pearson‚Äôs Chi-squared test for categorical features.

Real-time alerts (alert_enabled) are not needed here since the monitoring goal is periodic input drift detection, not output consistency or immediate feedback.

## ‚ùì Pregunta 91: Selecci√≥n de targets de c√≥mputo compatibles con GPU

**Enunciado:**  
You create compute targets for Azure Machine Learning training experiments.  
You need to ensure that each target supports GPU for training.  
What should you do?

**Opciones:**  
A. Install Docker on your local machine. Deploy your experiments using a local web service.  
B. Install the Azure Machine Learning SDK preview package. Deploy your machine learning model as an app in Azure Functions.  
C. Register the model in a workspace. Deploy the model to Azure Kubernetes Service (AKS). ‚úÖ  
D. Provision Azure Internet of Things (IoT) Hub and register IoT devices. Deploy machine learning models on your IoT devices.

---

### ‚úÖ Respuesta Correcta:
**C. Register the model in a workspace. Deploy the model to Azure Kubernetes Service (AKS).**

---

### üß† Explicaci√≥n:

Azure Kubernetes Service (AKS) es la opci√≥n correcta porque:

- **Soporta aceleraci√≥n por GPU o FPGA.**
- Permite escalar din√°micamente la disponibilidad computacional seg√∫n la carga.
- Es ideal para experimentos de alto rendimiento y m√∫ltiples nodos.
- Microsoft est√° promoviendo el uso del t√©rmino *Azure Machine Learning Kubernetes* como sin√≥nimo de AKS para despliegues.

---

### ‚ùå Otras opciones incorrectas:

- **A. Docker + local web service:**  
  Solo se recomienda para pruebas locales o troubleshooting. No garantiza soporte de GPU.

- **B. Azure Functions:**  
  No es apto para entrenamiento. Es m√°s adecuado para inferencia ligera usando contenedores.

- **D. IoT Hub:**  
  Este enfoque se llama **Azure Stack Edge**. Es √∫til para inferencia en el borde (edge computing), no para entrenamiento.

---

### üìö Referencias:

- [Deploy ML models to AKS](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-azure-kubernetes-service)  
- [What is Azure Kubernetes Service](https://learn.microsoft.com/en-us/azure/aks/intro-kubernetes)  
- [Azure Stack Edge for ML models](https://learn.microsoft.com/en-us/azure/databox-online/azure-stack-edge-overview)


## Pregunta 92: Configurar un proyecto de etiquetado de im√°genes para clasificaci√≥n

#### Enunciado
Una empresa de comercio electr√≥nico quiere que configures un proyecto de etiquetado de im√°genes en Azure Machine Learning Studio para clasificar productos recibidos de varios proveedores. Cada imagen debe ser etiquetada con una sola clase y todas las etiquetas deben asignarse manualmente. Se espera que se a√±adan nuevas im√°genes semanalmente al conjunto de datos.

#### Requerimientos:
- Cada imagen debe tener solo **una etiqueta**.
- Las etiquetas **no cambian**.
- El etiquetado debe ser **manual** (sin ML asistido).
- Se agregar√°n **im√°genes nuevas cada semana**.

---

### Orden correcto de pasos para configurar el proyecto:

1. **Choose Image Classification Multi-class as the labeling task type.**  
   Porque cada imagen debe tener solo **una etiqueta**.
   
2. **Select or create a dataset associated with storage where the images reside.**  
   Para que el proyecto de etiquetado tenga acceso a las im√°genes.

3. **Ensure that the Incremental refresh option is turned on.**  
   Esto permite que el dataset se actualice autom√°ticamente cuando se a√±aden nuevas im√°genes.

4. **Create the list of label classes against which you want to categorize your images.**  
   Se definen las clases de etiquetas disponibles (por ejemplo, ‚Äúropa‚Äù, ‚Äúelectr√≥nica‚Äù, etc).

5. **Provide any instructions for the labelers on the process of classification.**  
   Para garantizar que los etiquetadores sigan un criterio coherente.

6. **Ensure that the Enable ML assisted labeling is turned off.**  
   Porque el etiquetado debe hacerse **manualmente**, sin sugerencias autom√°ticas del modelo.

---

### Explicaci√≥n Detallada

1. **Image Classification Multi-class**:  
   - Esta tarea asigna **una sola clase** por imagen.
   - Es adecuada cuando las im√°genes tienen una √∫nica categor√≠a asociada.
   - No se debe usar **Multi-label** ni **Bounding Box**, porque estas opciones permiten m√∫ltiples etiquetas o identificaciones dentro de la imagen.

2. **Dataset asociado al almacenamiento**:  
   - Es necesario crear o seleccionar un conjunto de datos donde est√©n almacenadas las im√°genes.
   - Este dataset se conecta al proyecto de etiquetado para que los trabajadores humanos puedan acceder a las im√°genes.

3. **Incremental Refresh ON**:  
   - Esta opci√≥n permite que el proyecto se **actualice autom√°ticamente** con nuevas im√°genes cuando se agregan al datastore (cada semana).
   - No debe estar desactivado, porque eso impedir√≠a que las im√°genes nuevas se integren sin intervenci√≥n manual.

4. **Lista de etiquetas**:  
   - Define las posibles **categor√≠as** que se van a asignar a las im√°genes.
   - Ejemplo: `["ropa", "zapatos", "tecnolog√≠a"]`.

5. **Instrucciones para etiquetadores**:  
   - Es buena pr√°ctica explicar c√≥mo clasificar: criterios, ejemplos, o reglas espec√≠ficas.
   - Esto reduce errores humanos y asegura coherencia en el etiquetado.

6. **ML assisted labeling OFF**:  
   - Se debe desactivar para que **no se utilicen predicciones autom√°ticas del modelo**.
   - Esto es crucial si se quiere tener **control humano total sobre las etiquetas**.

---

### Lo que NO debes hacer

- ‚ùå **Enable ML assisted labeling**: va contra el requerimiento de etiquetado manual.
- ‚ùå **Incremental refresh OFF**: impedir√≠a que se actualice con nuevas im√°genes autom√°ticamente.
- ‚ùå **Image Classification Multi-label**: cada imagen tendr√≠a m√°s de una clase ‚Üí contradice el enunciado.
- ‚ùå **Object Identification (Bounding Box)**: se usa para tareas de detecci√≥n de objetos, no clasificaci√≥n de imagen completa.

---

### ¬øQu√© es un proyecto de etiquetado en Azure ML?

Un proyecto de etiquetado es una herramienta visual para asignar etiquetas a tus datos (im√°genes, texto, audio). Sirve para construir datasets de entrenamiento para modelos de machine learning supervisado. En este caso, el proyecto est√° centrado en im√°genes, y se usa para clasificaci√≥n manual.

---

### ¬øQu√© es Incremental Refresh?

- Es una opci√≥n que le indica al dataset que **escanee peri√≥dicamente** el origen de datos en busca de nuevos archivos.
- Es √∫til cuando **las im√°genes llegan por lotes**, como en este caso cada semana.

---

### ¬øQu√© es el ML Assisted Labeling?

- Es una opci√≥n donde el sistema usa un modelo ML preentrenado para **sugerir etiquetas** autom√°ticamente.
- Ahorra tiempo, pero puede introducir errores si no se revisa.
- En este caso **est√° desactivado** porque se exige etiquetado manual.

---

### En resumen

Este tipo de pregunta eval√∫a:
- Configuraci√≥n paso a paso de proyectos de etiquetado de im√°genes.
- Comprensi√≥n de tareas ML: clasificaci√≥n vs. detecci√≥n.
- Opciones adecuadas seg√∫n requisitos del cliente.
- Buenas pr√°cticas en etiquetado y dataset management.

```python
# NO ES UN C√ìDIGO DE IMPLEMENTACI√ìN, PERO SI FUERA, INCLUIR√çA:
labeling_project = {
  "task_type": "multi-class",
  "dataset": "dataset_linked_to_blob",
  "labels": ["ropa", "zapatos", "tecnolog√≠a"],
  "manual_labeling": True,
  "incremental_refresh": True
}
```	
## Pregunta 94 - Azure ML SDK - AutoMLConfig para datos dispersos

**Pregunta:**

You are using the Azure Machine Learning SDK to create experiments that will process sparse data. Your code includes code to create an AutoMLConfig object:

```python
automl_config = AutoMLConfig(
    task='regression',
    compute_target=my_target,
    training_data=my_data,
    label_column_name=my_label,
    **automl_experiment
)
```

ou need to ensure that your data is not scaled and normalized.

What should you do?

### Opciones:

A. Add the primary_metric parameter when creating the AutoMLConfig object
B. Add the from azureml.widgets import RunDetails line to your script
C. Move the task = 'regression' line to the automl_experiment data dictionary
D. ‚úÖ Define the featurization parameter in the automl_experiment data dictionary

Respuesta correcta: D. Define the featurization parameter in the automl_experiment data dictionary

### Explicaci√≥n detallada:

Cuando se configura un experimento en Azure Machine Learning usando AutoMLConfig, puedes pasar par√°metros de configuraci√≥n como diccionario a trav√©s de **automl_experiment.

Uno de estos par√°metros es featurization.
Por defecto, si no configuras featurization, Azure AutoML intentar√° escalar, normalizar, rellenar valores nulos y transformar autom√°ticamente las variables. Esto puede ser problem√°tico con datos dispersos (sparse data) porque podr√≠as perder su estructura.

Para desactivar este comportamiento autom√°tico y evitar la normalizaci√≥n y escalado, debes especificar:

```python
automl_experiment = {
    "featurization": "off"
}
```
Esto le indica a AutoML que no haga ninguna transformaci√≥n autom√°tica, √∫til cuando t√∫ ya hiciste el preprocesamiento de forma personalizada o est√°s trabajando con datos que no deben ser transformados por AutoML (por ejemplo, datos dispersos o codificados espec√≠ficamente).

Por qu√© las otras opciones son incorrectas:

A. primary_metric se usa para definir la m√©trica de evaluaci√≥n, pero no afecta el preprocesamiento ni la normalizaci√≥n de los datos.

B. RunDetails solo sirve para visualizar los detalles del experimento en un Jupyter Notebook, no tiene efecto en el comportamiento del experimento.

C. Aunque se pueden pasar par√°metros dentro de **automl_experiment, task es obligatorio como argumento expl√≠cito del constructor AutoMLConfig, no se debe mover al diccionario.

## Pregunta 95

You plan to train a scikit-learn model from the ground up using Azure ML Python Software Development Kit (SDK) v2.  
You need to build the training job.

**What should you use?**

### Opciones:
- ‚≠ï `azure.ai.ml.load_job`  
- ‚≠ï `azure.ai.ml.entities.BatchDeployment`  
- ‚≠ï `azure.ai.ml.entities.CommandJob`  
- ‚úÖ `azure.ai.ml.command`  

---

### Respuesta Correcta:
‚úÖ `azure.ai.ml.command`

---

### Explicaci√≥n:

Debes usar el recurso `azure.ai.ml.command` para enviar el trabajo de entrenamiento.  
Un **Azure ML command** es un recurso que te permite definir todos los detalles necesarios para ejecutar tu c√≥digo de entrenamiento en Azure.

Estos detalles incluyen:
- Los **inputs** y **outputs**
- El tipo de hardware a usar (ej. GPU, CPU)
- El entorno de ejecuci√≥n (environment)
- El c√≥digo que se ejecutar√°
- El comando para lanzar el entrenamiento

### Ejemplo:

```python
job = command(
    inputs=dict(kernel="linear", penalty=1.0),
    compute=cpu_compute_target,
    environment=f"{job_env.name}:{job_env.version}",
    code="./src/",
    command="python train_iris.py --kernel ${{inputs.kernel}} --penalty ${{inputs.penalty}}",
    experiment_name="sklearn-iris-flowers",
    display_name="sklearn-classify-iris-flower-images",
)
```

#### ‚ùå Opci√≥n incorrecta:
‚ùå azure.ai.ml.entities.BatchDeployment
Este recurso se usa para el despliegue batch, no para el entrenamiento.

‚ùå azure.ai.ml.entities.CommandJob
Este objeto te permite ver detalles del trabajo en MLflow y visualizar el estado, pero no se utiliza para construir el job desde cero.

‚ùå azure.ai.ml.load_job
Se usa para cargar un trabajo desde un archivo YAML, no para definirlo directamente en c√≥digo Python.

## Pregunta 96: Configuraci√≥n de una DSVM con soporte CUDA para entrenamiento de modelos de clasificaci√≥n de im√°genes

### Escenario
You plan to create a compute environment for your Image Classification Deep Learning model leveraging Compute Unified Device Architecture (CUDA) computations. You plan to use the Data Science Virtual Machine (DSVM) for this purpose.

You need to configure your VM to support CUDA.

**To which series should you configure your VM size?**

### Opciones
- [ ] NCv3 ‚úÖ
- [ ] Fasv6  
- [ ] Dsv5  
- [ ] Lsv3

### Respuesta correcta
‚úÖ **NCv3**

### Explicaci√≥n detallada

Debes configurar tu m√°quina virtual (VM) con una serie que soporte procesamiento gr√°fico acelerado por GPU, ya que los modelos de deep learning que utilizan CUDA (Compute Unified Device Architecture) requieren compatibilidad con GPU para acelerar la computaci√≥n.

- **NCv3 series**: ‚úÖ *La opci√≥n correcta*. Estas VMs est√°n optimizadas para cargas de trabajo de aprendizaje profundo con soporte CUDA y NVIDIA Tesla V100 GPUs, ideales para tareas como clasificaci√≥n de im√°genes.
  
- **Dsv5 series**: ‚ùå Son VMs de prop√≥sito general, no ofrecen soporte de GPU. No sirven para deep learning con CUDA.

- **Fasv6 series**: ‚ùå Son VMs optimizadas para c√≥mputo, pero no tienen GPU. Se usan para tareas que dependen intensivamente del CPU.

- **Lsv3 series**: ‚ùå Est√°n optimizadas para operaciones intensivas en disco, como bases de datos. No est√°n pensadas para procesamiento gr√°fico ni deep learning.

### Resumen
Para ejecutar modelos de deep learning con CUDA en una DSVM, es necesario seleccionar una VM que incluya GPU con soporte para CUDA. Las series **NCv3** cumplen con estos requisitos.

---

### Referencias

- [5 steps to more interactive deep learning - Medium](https://aribornstein.medium.com/5-steps-to-more-interactive-deep-learning-79126f089696)
- [CUDA Toolkit - NVIDIA Developer](https://developer.nvidia.com/cuda-toolkit)
- [Azure DSVM tools for deep learning frameworks](https://learn.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/dsvm-tools-deep-learning-frameworks?view=azureml-api-2)
- [Azure VM sizes overview](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/overview?tabs=breakdownseries%2Cgeneralsizelist%2Ccomputesizelist%2Cmemorysizelist%2Cstoragesizelist%2Cgpusizelist%2Cfpgasizelist%2Chpcsizelist)
- [NCv3-series VMs - GPU optimized](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/gpu-accelerated/ncv3-series?tabs=sizebasic)
- [Dsv5-series VMs - General purpose](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/general-purpose/dsv5-series?tabs=sizebasic)
- [Lsv3-series VMs - Storage optimized](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/storage-optimized/lsv3-series?tabs=sizebasic)
- [Fasv6-series VMs - Compute optimized](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/compute-optimized/fasv6-series?tabs=sizebasic)

## Pregunta 96

You are developing a financial markets prediction model. You create a tabular timeseries dataset named `time_series_ds` with a partition timestamp by date.

You are leveraging Azure ML SDK to query the dataset. You want to view 100 records from the dataset for January 2020.

You need to write the code to view the records in a Pandas dataframe.

### ‚úÖ Respuesta correcta:

```python
jan_ds = time_series_ds.time_between(
    start_time=datetime(2019, 12, 31),
    end_time=datetime(2020, 2, 1),
    include_boundary=False
)

jan_ds.take(100).to_pandas_dataframe()
```
### üß† Explicaci√≥n:
time_between() filtra las filas del dataset seg√∫n un rango de fechas.

include_boundary=False asegura que las fechas del 31 de diciembre de 2019 y del 1 de febrero de 2020 no se incluyan.

take(100) selecciona los primeros 100 registros del resultado filtrado.

to_pandas_dataframe() convierte ese resultado en un dataframe de pandas.

Esto te da justo lo que necesitas: 100 registros del mes de enero 2020 en formato Pandas.
## Pregunta 97

**You are creating an Automated Machine Learning experiment to evaluate a regression model.**

You plan to export your Auto ML generated model to an Open Neural Network Exchange (ONNX) model.

You need to choose algorithms that can be used by Auto ML models and support exporting to ONNX models.

**Which two algorithms can you use to meet your goal?**

### ‚úÖ Respuestas correctas:
- Decision Tree
- Random Forest

### ‚ùå Opciones incorrectas:
- Linear SVC  
  > Aunque Linear SVC puede exportarse a ONNX, **solo sirve para clasificaci√≥n**, no para regresi√≥n.
- Auto-ARIMA  
  > Solo sirve para series de tiempo y **no puede exportarse** a ONNX.

---

### üí° Explicaci√≥n:

Tanto **Decision Tree** como **Random Forest** pueden utilizarse en AutoML para tareas de regresi√≥n y **son compatibles con la exportaci√≥n a ONNX**. Estas opciones son las √∫nicas que satisfacen ambos requisitos: ser compatibles con AutoML y exportables a ONNX en escenarios de regresi√≥n.

- **Auto-ARIMA**: solo se usa para *time-series forecasting*, y no se puede exportar a ONNX.
- **Linear SVC**: es un modelo de clasificaci√≥n, no de regresi√≥n.

---

### üìö Referencias oficiales:

- [ONNX and Azure Machine Learning](https://learn.microsoft.com/en-us/azure/machine-learning/concept-onnx?view=azureml-api-2)  
- [Set up AutoML training for tabular data](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train?view=azureml-api-2&tabs=python)


## Pregunta 98: Acceso seguro a datos en ADLS Gen2 desde Spark en Azure Machine Learning

### üß† Escenario

Est√°s trabajando en una tarea de *data wrangling* en **Azure Machine Learning**, donde necesitas procesar datos almacenados en un **Azure Data Lake Storage (ADLS) Gen2**. Piensas usar un **Synapse Spark Pool adjunto** para acceder de forma segura a estos datos.

### üéØ Objetivo

Debes configurar el entorno para garantizar el **acceso seguro** a los datos desde Spark.

### ‚ùì Pregunta

¬øCu√°les dos acciones debes realizar para cumplir con el requerimiento?

Cada respuesta correcta representa **parte de la soluci√≥n**.

### ‚úÖ Respuestas correctas

- `‚úîÔ∏è` **Asignar el rol "Storage Blob Data Contributor" a la identidad de la aplicaci√≥n con permisos sobre la cuenta de almacenamiento.**
- `‚úîÔ∏è` **Almacenar credenciales en Azure Key Vault dentro de la configuraci√≥n de la sesi√≥n Spark.**

---

### ‚ùå Opciones incorrectas

- `‚úñÔ∏è` **Usar el protocolo `abfss://` para especificar la ubicaci√≥n de datos en la sesi√≥n Spark.**  
  ‚Üí Este protocolo **s√≥lo define la ruta**, no gestiona autenticaci√≥n ni acceso seguro.

- `‚úñÔ∏è` **Configurar Spark sin servidor (serverless) para acceder a los datos.**  
  ‚Üí Esto **no aplica cuando ya est√°s usando un Synapse Spark Pool adjunto** que se encarga de eso.

- `‚úñÔ∏è` **Establecer directamente la clave de la cuenta de almacenamiento en la configuraci√≥n de Spark.**  
  ‚Üí Esto **no es seguro** y **no sigue las buenas pr√°cticas de acceso basado en identidad.**

---

### üß† Explicaci√≥n tipo masterclass

#### 1. ¬øPor qu√© usar **Storage Blob Data Contributor**?
Este rol otorga a la identidad de la aplicaci√≥n (por ejemplo, un servicio gestionado o identidad asignada a Spark) el permiso para **leer y escribir** en el ADLS Gen2. Es mucho m√°s seguro que usar claves de cuenta o SAS tokens.

> üîê Seguridad basada en identidad = acceso controlado + auditable

#### 2. ¬øPor qu√© usar **Azure Key Vault**?
Almacenar secretos como `tenant ID`, `client ID` o `client secret` directamente en scripts es peligroso. Key Vault es la opci√≥n **m√°s segura y profesional** porque:
- Centraliza el almacenamiento de credenciales
- Permite acceso granular
- Soporta integraci√≥n con Spark

#### 3. ¬øPor qu√© NO usar `abfss://` como √∫nica soluci√≥n?
El protocolo `abfss://` simplemente **indica la ruta** a un archivo en ADLS Gen2, pero **no autentica ni autoriza** el acceso. Es como decir "ese archivo est√° ah√≠", pero sin las llaves para abrirlo.

#### 4. ¬øPor qu√© NO usar claves de cuenta directamente?
Copiar y pegar claves de acceso directo en Spark es:
- Inseguro (si alguien accede al script, ve la clave)
- No sigue pr√°cticas modernas de control de acceso (como RBAC o Key Vault)

#### 5. ¬øPor qu√© NO usar Spark serverless?
Cuando usas un **Synapse Spark Pool adjunto**, ese recurso ya se encarga de manejar los recursos Spark. No necesitas crear ni configurar Spark serverless en Azure ML para esto.

---

### üìö Referencias oficiales

- [Interactive Data Wrangling with Apache Spark](https://learn.microsoft.com/en-us/azure/machine-learning/interactive-data-wrangling-with-apache-spark-azure-ml?view=azureml-api-2)  
- [Apache Spark in Azure Machine Learning](https://learn.microsoft.com/en-us/azure/machine-learning/apache-spark-azure-ml-concepts?view=azureml-api-2)  
- [Azure Data Lake Storage URI](https://learn.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction-abfs-uri)  
- [Azure Storage Access from Spark](https://learn.microsoft.com/en-us/azure/databricks/connect/storage/azure-storage)  

## Pregunta 102: Registrar un Datastore en Azure ML SDK v2

### Escenario
Trabajas en una organizaci√≥n del sector salud y eres responsable de configurar datastores para archivos de datos grandes. Usas el Azure Machine Learning Python SDK v2 para gestionar estos datastores.

Vas a crear un datastore utilizando archivos almacenados en Azure Blob, y deseas realizar esta operaci√≥n de forma asincr√≥nica. Necesitas registrar el datastore.

### ¬øQu√© m√©todo de Python deber√≠as usar?
‚úÖ `ml_client.begin_create_or_update`

### Opciones incorrectas
‚ùå `ml_client.create_or_update()`  
‚ùå `ml_client.from_config`

---

### Explicaci√≥n detallada

Azure ML SDK v2 ofrece **tres m√©todos principales** en el cliente `ml_client` para registrar recursos como datastores:

- `create_or_update()`: realiza la operaci√≥n de forma **sincr√≥nica**, es decir, **bloquea el hilo de ejecuci√≥n** hasta que se completa.
- `begin_create_or_update()`: realiza la operaci√≥n de forma **asincr√≥nica**, permitiendo que el flujo del programa contin√∫e sin esperar a que termine.
- `from_config()`: no se utiliza para crear recursos, sino para cargar configuraci√≥n de un workspace ya existente.

#### ‚úÖ ¬øPor qu√© usar `begin_create_or_update()`?
Porque en el escenario se indica que **la operaci√≥n debe ser asincr√≥nica**. Esto es clave cuando se trabaja con archivos grandes en Azure Blob Storage. Este m√©todo permite:

- Crear o actualizar un recurso de Azure (como un datastore)
- Sin bloquear el hilo principal
- Mientras Azure Machine Learning termina la operaci√≥n en segundo plano

Este enfoque es √∫til para evitar tiempos muertos en procesos largos o pesados.

#### ‚ùå ¬øPor qu√© NO usar `create_or_update()`?
Aunque tambi√©n crea o actualiza un recurso, lo hace de forma sincr√≥nica. Esto significa que:

- Tu c√≥digo se quedar√≠a esperando a que la operaci√≥n termine
- No es eficiente para manejar cargas grandes
- Va en contra del requisito del enunciado: "como una operaci√≥n asincr√≥nica"

#### ‚ùå ¬øPor qu√© NO usar `from_config()`?
Este m√©todo simplemente **carga la configuraci√≥n del workspace** desde un archivo de configuraci√≥n (como `config.json`). No se usa para registrar datastores ni para ejecutar operaciones en Azure.

---

### Referencias
- [Azure SDK v2: Datastore management](https://learn.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-python)
- [Azure MLClient Docs](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-datastores-v2)

## Pregunta: ¬øQu√© comando deber√≠as usar para ejecutar un proyecto MLflow en una m√°quina de c√≥mputo de Azure?

### üß† Escenario:
Eres un cient√≠fico de datos que trabaja con Azure Machine Learning y MLflow. Tienes un proyecto MLflow ya existente. Quieres ejecutar ese proyecto en una m√°quina de c√≥mputo de Azure, usando la CLI de MLflow (Command Line Interface).

### ‚úÖ Respuesta Correcta:
```bash
mlflow run [experiment_id] -e [environment_name] --backend azure
```

### ‚úÖ Explicaci√≥n detallada (Estilo Masterclass):
Cuando trabajas con MLflow y Azure Machine Learning, puedes lanzar ejecuciones de proyectos usando el comando mlflow run. Este comando se encarga de ejecutar el c√≥digo de entrenamiento o pipeline que definiste dentro del proyecto MLflow.

Pero si lo vas a correr en la nube usando Azure, necesitas decirle expl√≠citamente a MLflow que utilice Azure como backend de ejecuci√≥n.

mlflow run: Este es el comando que ejecuta un proyecto MLflow.

[experiment_id]: Reemplaza esto con el ID del experimento o la ruta del proyecto (puede ser un repositorio Git o un directorio local).

-e [environment_name]: Especifica el entorno con el que quieres ejecutar el experimento (opcional si no defines un entry_point).

--backend azure: Clave para esta pregunta. Le dice a MLflow que la ejecuci√≥n se har√° en Azure Machine Learning, no localmente ni con otro backend.

### üõë Opciones incorrectas:
mlflow models serve [model_path]: Sirve un modelo MLflow localmente para hacer inferencia, no ejecuta el proyecto.

mlflow artifacts list [run_id]: Lista archivos artefactos generados por una corrida, no inicia nada.

mlflow logs [run_id]: Muestra logs de una ejecuci√≥n previa, no lanza un experimento.

mlflow run [experiment_id] -P key=value: Ejecuta el experimento localmente, pero no lo lanza en Azure (falta --backend azure)

## Pregunta 204

### üí¨ Enunciado
You are a data scientist at a company that uses Azure Machine Learning and MLflow. You have an existing MLflow project.

You need to initiate the execution of the project on an Azure Machine Learning compute using the MLflow's command line interface (CLI).

**Which command should you use?**

### ‚úÖ Respuesta correcta

```bash
mlflow run [experiment_id] -e [environment_name] --backend azure
```

### üß† Explicaci√≥n detallada

#### üéØ Objetivo
Se busca iniciar la ejecuci√≥n de un proyecto MLflow utilizando la **CLI** (Command Line Interface), pero **espec√≠ficamente ejecut√°ndolo en un entorno de c√≥mputo de Azure Machine Learning**.

#### üß™ ¬øQu√© es `mlflow run`?
`mlflow run` es el comando usado para ejecutar un proyecto de MLflow. Este comando permite especificar:
- El directorio o URI del proyecto.
- Variables de entorno y par√°metros del experimento.
- El backend, es decir, d√≥nde se ejecutar√° el experimento.

#### ‚öôÔ∏è ¬øQu√© hace `--backend azure`?
El flag `--backend azure` le indica a MLflow que **la ejecuci√≥n del experimento no se har√° localmente**, sino **en la infraestructura de Azure Machine Learning**, lo que te permite:

- Aprovechar c√≥mputo escalable.
- Integraci√≥n directa con tu workspace de Azure ML.
- Tracking autom√°tico de m√©tricas, par√°metros y artefactos.

#### üßæ ¬øY qu√© significa `-e [environment_name]`?
Este par√°metro define el **nombre del entorno** que se usar√° dentro del proyecto MLflow. Es √∫til si est√°s trabajando con m√∫ltiples entornos o entry points dentro de tu proyecto.

---

### ‚ùå Opciones incorrectas y por qu√©

- `mlflow models serve [model_path]`  
  üîª Sirve para desplegar un modelo **ya entrenado** como un servicio REST. No ejecuta un proyecto MLflow.

- `mlflow artifacts list [run_id]`  
  üîª Lista los artefactos de un experimento ya ejecutado. Tampoco ejecuta nada.

- `mlflow run [experiment_id] -P key=value`  
  ‚ö†Ô∏è Esta opci√≥n podr√≠a usarse, pero solo **localmente o con otro backend**. **No lanza la ejecuci√≥n en Azure**, porque **falta `--backend azure`**.

- `mlflow logs [run_id]`  
  üîª Se usa para visualizar los logs de un experimento que ya se ejecut√≥. No sirve para lanzarlo.

---

### üìö Recurso √∫til
- [MLflow CLI documentation](https://mlflow.org/docs/latest/cli.html#mlflow-run)
- [MLflow on Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow-cli)

---

### ‚úÖ Conclusi√≥n
Cuando te piden lanzar un proyecto de MLflow **en Azure Machine Learning desde la CLI**, **siempre** debes usar el comando:

## Pregunta 105: Ajuste de hiperpar√°metros con Azure ML SDK v2

### Enunciado

Est√°s realizando el ajuste de hiperpar√°metros para un modelo de machine learning.

Est√°s utilizando Azure Machine Learning SDK (v2).

Tienes el siguiente fragmento de c√≥digo:

```python
from azure.ai.ml.sweep import Normal, Uniform

command_job_for_sweep = command_job(
    learning_rate=Normal(mu=15, sigma=2),
    keep_probability=Uniform(min_value=0.03, max_value=0.2),
)
```
Necesitas ajustar los hiperpar√°metros para obtener el mejor rendimiento posible de tu modelo de ML. Para cada una de las siguientes afirmaciones, selecciona S√≠ si es verdadera o No si es falsa.

### Respuestas correctas

| Par√°metro         | Tipo de Distribuci√≥n | Par√°metros de la Distribuci√≥n       |
|-------------------|----------------------|-------------------------------------|
| learning_rate     | Normal               | Desviaci√≥n est√°ndar = 15            |
| keep_probability  | Uniforme             | Rango = [0.03, 0.2]                 |

### Explicaci√≥n detallada
¬øEs un espacio de b√∫squeda de par√°metros discretos?
No. Normal y Uniform definen espacios de b√∫squeda continuos. Para definir un espacio discreto, se debe usar Choice(...).
Por lo tanto, la afirmaci√≥n es falsa.

¬øTiene learning_rate una desviaci√≥n est√°ndar de 15?
No. En Normal(mu=15, sigma=2):

mu=15 es la media.

sigma=2 es la desviaci√≥n est√°ndar.
La afirmaci√≥n es falsa.

¬økeep_probability devuelve un valor uniformemente distribuido entre 0.03 y 0.2?
S√≠. La funci√≥n Uniform(min_value=0.03, max_value=0.2) genera valores continuos uniformes dentro de ese rango.
La afirmaci√≥n es verdadera.

## Pregunta

Tienes un conjunto de datos sobre el cual deseas ejecutar un algoritmo de clasificaci√≥n. Al analizar el conjunto de datos, descubres que una clase de elementos tiene una cantidad mucho menor de registros.

Necesitas seleccionar una estrategia de muestreo apropiada para abordar el desequilibrio de clases.

**¬øQu√© componente de transformaci√≥n de datos deber√≠as seleccionar?**

### ‚úÖ Respuesta correcta:
- Synthetic Minority Oversampling Technique (SMOTE)

---

## Explicaci√≥n

Debes seleccionar el componente **SMOTE (Synthetic Minority Oversampling Technique)**.  
SMOTE es una t√©cnica estad√≠stica utilizada para **aumentar el n√∫mero de muestras de la clase minoritaria**, asegurando as√≠ un mayor equilibrio con respecto a la clase mayoritaria.  
Esta t√©cnica genera **nuevas instancias sint√©ticas** basadas en las observaciones existentes, eliminando el desequilibrio de clases sin simplemente replicar los datos.

### ‚ùå Otras opciones incorrectas:

- **Normalize Data**: Este componente sirve para normalizar los valores num√©ricos en el conjunto de datos, escal√°ndolos a un rango com√∫n (por ejemplo, de 0 a 1). No aborda el problema de desequilibrio de clases.

- **Partition and Sample**: Este componente permite particionar el conjunto de datos y tomar muestras manteniendo las proporciones originales, pero **no modifica el desequilibrio de clases** existente.

- **Split Data**: Se utiliza para dividir el conjunto de datos en subconjuntos (por ejemplo, entrenamiento y prueba), **sin modificar la distribuci√≥n de clases**.

---

## Referencia

SMOTE es una pr√°ctica com√∫nmente recomendada en tareas de clasificaci√≥n donde hay un claro desequilibrio entre clases. Es compatible con Azure Machine Learning como parte del procesamiento previo a la modelaci√≥n.

## Pregunta 109: Desplegar un modelo en tiempo real usando Azure ML Studio

Est√°s creando y entrenando un modelo de Machine Learning (ML) en Azure ML Studio. El modelo toma como fuente datos en formato CSV.

Necesitas identificar los pasos para desplegar este modelo como un servicio en tiempo real y garantizar que los endpoints sean accesibles para los usuarios del servicio.

### ¬øQu√© cuatro acciones debes realizar?

Selecciona las acciones apropiadas y ord√©nalas en cualquier orden:

---

### ‚úÖ Respuesta correcta (en cualquier orden):

- Crear un pipeline de inferencia en tiempo real.  
- Crear un cl√∫ster de inferencia (inferencing cluster).  
- Desplegar el endpoint en tiempo real.  
- Probar el endpoint en tiempo real.

---

### ‚ùå Acciones incorrectas:

- **Crear un pipeline de inferencia por lotes**: este se usa para procesar grandes vol√∫menes de datos y no es adecuado para servicios en tiempo real.  
- **Crear un cl√∫ster de c√≥mputo (compute cluster)**: este se usa para entrenamiento, no para hosting de endpoints.

---

### üß† Explicaci√≥n:

1. **Crear un pipeline de inferencia en tiempo real**: Este pipeline se genera a partir del modelo entrenado y te permite configurar el servicio web que responder√° a las predicciones en tiempo real.

2. **Crear un cl√∫ster de inferencia (inferencing cluster)**: Este es el entorno donde se desplegar√° el modelo para hacer inferencias. Este paso puede realizarse antes o despu√©s de crear el pipeline.

3. **Desplegar el endpoint en tiempo real**: Una vez configurado el pipeline y el entorno de inferencia, se selecciona la opci√≥n ‚ÄúDeploy‚Äù para desplegar el modelo como un servicio.

4. **Probar el endpoint en tiempo real**: Luego del despliegue, puedes acceder a la pesta√±a ‚ÄúTest‚Äù para verificar que el endpoint funciona correctamente enviando una fila de datos de prueba.

---

### üîó Referencias √∫tiles:

- [Deploy and score a machine learning model in real time in Azure Machine Learning](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=python)
- [What is an Azure Machine Learning inference pipeline?](https://learn.microsoft.com/en-us/azure/machine-learning/concept-endpoints)

## ‚ùì Pregunta 111

### üí¨ Enunciado

Est√°s ajustando hiperpar√°metros para un modelo de machine learning. Usas el SDK v2 de Azure ML. Tienes el siguiente c√≥digo:

```python
from azure.ai.ml.sweep import Normal, Uniform

command_job_for_sweep = command_job(
    learning_rate=Normal(mu=15, sigma=2),
    keep_probability=Uniform(min_value=0.03, max_value=0.2)
)
```

Necesitas ajustar los hiperpar√°metros para obtener el mejor rendimiento posible de tu modelo de ML. Para cada una de las siguientes afirmaciones, selecciona S√≠ si es verdadera o No si es falsa.

### ‚úÖ Respuestas correctas

| Par√°metro         | Tipo de Distribuci√≥n | Par√°metros de la Distribuci√≥n              |
|-------------------|----------------------|--------------------------------------------|
| learning_rate     | Normal               | Desviaci√≥n est√°ndar = 15                   |
| keep_probability  | Uniforme             | Rango = M√≠nimo 0.03, M√°ximo 0.2           |

### üß† Explicaci√≥n
El c√≥digo no define par√°metros discretos, sino continuos. Para definir valores discretos se debe usar Choice de azure.ai.ml.sweep, no Normal o Uniform.

learning_rate=Normal(mu=15, sigma=2) indica que la media es 15 y la desviaci√≥n est√°ndar es 2, no 15.

keep_probability est√° correctamente definido como un valor con distribuci√≥n uniforme entre 0.03 y 0.2.

## üß† Pregunta 112: Preservar el endpoint de un pipeline en Azure ML al probar cambios

Est√°s utilizando **Azure Machine Learning** para crear y publicar un pipeline de inferencia por lotes (batch inference pipeline). Debido a requisitos regulatorios, el endpoint del pipeline ha sido escaneado por vulnerabilidades y no debe ser modificado.

Tu objetivo es **probar algunos cambios** sin alterar el pipeline actual y asegurarte de que el **endpoint se mantenga intacto**.

---

### ‚úÖ Acciones correctas en orden:

1. **Create a new pipeline that implements your changes.**  
   > Crea un nuevo pipeline que contenga los cambios que deseas probar. No debes modificar el pipeline actual.

2. **Publish the pipeline to your scanned endpoint.**  
   > Publica el nuevo pipeline bajo el mismo endpoint ya escaneado. Azure ML permite m√∫ltiples versiones de pipeline bajo el mismo endpoint.

3. **Include the test pipeline version in your REST calls.**  
   > Para probar el pipeline nuevo sin afectar el actual, indica el n√∫mero de versi√≥n del pipeline en las llamadas REST (esto lo puedes hacer usando el par√°metro `version` del endpoint REST).

---

### ‚ùå Acci√≥n que NO debes realizar:

- **Determine the ID of the default published pipeline**  
  > No es necesario identificar el ID del pipeline actual porque cada pipeline publicado obtiene un n√∫mero de versi√≥n, y puedes usarlo directamente para hacer pruebas sin reemplazar el pipeline por defecto.

---

### üìò Explicaci√≥n t√©cnica:

- Azure ML te permite **publicar m√∫ltiples versiones** de un pipeline bajo un mismo endpoint HTTP.
- Al hacerlo, puedes **invocar una versi√≥n espec√≠fica** de ese pipeline en llamadas REST sin afectar al pipeline por defecto.
- Este enfoque es ideal cuando necesitas mantener un pipeline certificado o validado en producci√≥n mientras pruebas nuevas versiones en paralelo.

---

### üìö Referencias:

- [Microsoft Learn: Deploy and test pipelines in Azure Machine Learning](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-pipelines)
### Pregunta: ¬øQu√© m√©todo del objeto `run` deber√≠as usar para registrar una gr√°fica generada con Matplotlib durante un experimento, usando MLflow Tracking con Azure ML SDK v2?

Tu organizaci√≥n usa los servicios de Azure Machine Learning (ML). Est√°s usando el SDK v2 de Azure ML para gestionar un experimento.

Tu experimento usa Matplotlib para generar gr√°ficas de l√≠neas. Planeas configurar el registro y seguimiento del experimento con MLflow Tracking.

Necesitas usar el m√©todo adecuado para registrar la gr√°fica como parte del objeto de ejecuci√≥n (`run object`).

---

#### Opciones:
- A) `mlflow.log_artifact()`
- B) `mlflow.log_image()`
- C) `mlflow.log_figure()`
- D) `mlflow.log_dict()`

---

### ‚úÖ Respuesta correcta:
**C) `mlflow.log_figure()`**

---

### üßæ Explicaci√≥n:
El m√©todo `mlflow.log_figure()` es el m√°s adecuado cuando trabajas con figuras generadas con **Matplotlib**. Este m√©todo permite registrar una figura directamente en MLflow como un artefacto del experimento.

#### Ejemplo:
```python
import matplotlib.pyplot as plt
import mlflow

fig, ax = plt.subplots()
ax.plot([1, 2, 3], [4, 5, 6])
mlflow.log_figure(fig, "plot.png")
```
### ‚ùå ¬øPor qu√© no las otras opciones?
A) mlflow.log_artifact()
Se usa para registrar archivos existentes ya guardados en el disco, como .pkl, .txt, etc. No se usa directamente para objetos Matplotlib.

B) mlflow.log_image()
Se usa para objetos tipo numpy.ndarray o PIL.Image, no para objetos matplotlib.figure.Figure.

D) mlflow.log_dict()
Se usa para registrar diccionarios como archivos JSON o YAML, no para im√°genes ni visualizaciones.

## Pregunta sobre SDK v2 y definici√≥n de componentes en Azure ML

Est√°s utilizando Azure Machine Learning con el SDK v2 para construir un pipeline de clasificaci√≥n de im√°genes. Parte del c√≥digo de definici√≥n de componentes se muestra a continuaci√≥n:

```python
@command_component(
    name="prep_data",
    version="1",
    display_name="Prep Data",
    environment=dict(
        conda_file=Path(__file__).parent / "conda.yaml",
        image="mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04",
    ),
)
def prepare_data_component(
    input_data: Input(type="uri_folder"),
    training_data: Output(type="uri_folder"),
    test_data: Output(type="uri_folder"),
):
    convert(
        os.path.join(input_data, "train-images-idx3-ubyte"),
        os.path.join(input_data, "train-labels-idx1-ubyte"),
        os.path.join(training_data, "mnist_train.csv"),
        90000,
    )
```
¬øQu√© afirmaciones sobre este componente son verdaderas?
Selecciona S√≠ si la afirmaci√≥n es verdadera, o No si es falsa.

| Afirmaci√≥n                                                                 | Detalle clave                                  |
|----------------------------------------------------------------------------|-----------------------------------------------|
| 1. El c√≥digo convierte datos de `input_data` en `training_data` y `test_data` | Transformaci√≥n de datos para entrenamiento y prueba |
| 2. El nombre mostrado en `display_name` debe ser √∫nico dentro del workspace   | Requisito de unicidad para identificaci√≥n    |
| 3. Los campos `input_data`, `training_data` y `test_data` se conocen como "ports" | T√©rmino t√©cnico para interfaces de datos     |

### ‚úÖ Respuesta correcta
S√≠ ‚Äî El componente convierte datos del input hacia dos salidas, training_data y test_data. El archivo mnist_train.csv es generado como parte de training_data.

No ‚Äî El display_name es simplemente una etiqueta amigable para el usuario en la UI de Azure ML y no necesita ser √∫nico.

S√≠ ‚Äî En Azure ML, los Input y Output definidos en un componente act√∫an como ports o puertos para la comunicaci√≥n de datos entre componentes dentro de un pipeline.

## ‚ùì Pregunta 115 ‚Äî Despliegue local de un modelo con Azure ML

**Contexto:**  
Est√°s usando Azure Machine Learning para crear un modelo de machine learning. Planeas desplegar este modelo como un servicio web en l√≠nea utilizando tu sistema local.

Debes configurar las opciones adecuadas de despliegue.

---

#### üß† Enunciado:

**¬øQu√© dos acciones deber√≠as realizar?**  
Cada respuesta correcta representa parte de la soluci√≥n.

---

### üîò Opciones m√∫ltiples:

- ‚¨ú **Install Docker on your local machine.**  
- ‚úÖ **Set `auth_enabled` to `True` in your deployment configuration.**  
- ‚úÖ **Specify the service‚Äôs endpoint port where requests will be accepted.**  
- ‚¨ú **Use `Aciwebservice.deployconfiguration` to specify the number of CPU cores.**

---

### ‚úÖ Respuesta correcta:

- **Install Docker on your local machine.**
- **Specify the service‚Äôs endpoint port where requests will be accepted.**

---

### üìò Explicaci√≥n detallada (estilo masterclass):

Para desplegar un modelo localmente como un servicio web usando Azure Machine Learning, se requiere un contenedor que encapsule el modelo y todos sus recursos. Aqu√≠ es donde **Docker** entra en acci√≥n.

#### ‚úÖ 1. **Instalar Docker en tu m√°quina local:**
Docker es una plataforma de virtualizaci√≥n que permite empaquetar tu aplicaci√≥n (en este caso, el modelo ML) junto con sus dependencias. Al usar despliegue local, **Azure ML construye un contenedor Docker localmente** para emular el entorno donde se ejecutar√≠a el modelo.

> Sin Docker instalado, **no podr√°s simular el servicio localmente**, ya que no se puede crear el contenedor donde se va a servir el modelo.

---

#### ‚úÖ 2. **Especificar el puerto del endpoint:**
Los servicios web necesitan escuchar en un puerto definido para recibir peticiones HTTP. Cuando el contenedor est√© corriendo, Azure ML necesitar√° saber en qu√© puerto debe esperar esas peticiones.

> Por ejemplo: podr√≠as especificar que escuche en el puerto `5001` para que las peticiones REST se dirijan correctamente a ese punto del servicio.

---

#### ‚ùå 3. **`auth_enabled=True` no es obligatorio:**
Aunque este par√°metro permite proteger tu servicio usando autenticaci√≥n con tokens o claves API, **no es un requerimiento obligatorio**. Es solo √∫til si deseas implementar seguridad adicional.

> De hecho, si activas esta opci√≥n, todos los consumidores del modelo necesitar√°n una clave para hacer peticiones. Si est√°s solo haciendo pruebas locales o desarrollo inicial, puede ser innecesario.

---

#### ‚ùå 4. **No uses `Aciwebservice.deployconfiguration`:**
Este m√©todo se usa **√∫nicamente** cuando est√°s desplegando tu modelo **en Azure Container Instances (ACI)**. No es v√°lido para despliegues locales.

> Si lo usas, simplemente estar√≠as especificando configuraci√≥n de CPU/memoria para la nube, pero no tendr√≠a efecto en un despliegue local.

---

### üìå Conclusi√≥n:
Cuando despliegas un modelo **en tu m√°quina local usando Azure ML**, lo **m√≠nimo necesario** es:

1. Tener **Docker instalado**.
2. **Especificar el puerto HTTP** que debe usar el servicio para aceptar conexiones.

Las otras configuraciones pueden ser √∫tiles en la nube, pero no aplican al contexto **local**.

---

## Pregunta 116: de examen DP-100 ‚Äì Tuning autom√°tico con terminaci√≥n anticipada

### Enunciado

You use Azure Machine Learning to tune hyperparameters for your model.

You need to ensure that underperforming runs are terminated automatically.

Which two actions should you perform? Each correct answer presents part of the solution.

---

### Opciones

- [x] Create and configure a `BanditPolicy` object.  
- [ ] Use Bayesian sampling to select hyperparameter samples.  
- [x] Create a `RandomParameterSampling` object and specify a `parameter_space` dictionary.  
- [ ] Define a `PipelineParameter` object and specify a default pipeline parameter value.

---

### Respuesta correcta

‚úÖ **Create and configure a BanditPolicy object.**  
‚úÖ **Create a RandomParameterSampling object and specify a parameter_space dictionary.**

---

### Explicaci√≥n detallada

Cuando est√°s usando **Azure Machine Learning** para **optimizar hiperpar√°metros**, una estrategia clave es asegurarte de que los entrenamientos que van mal (underperforming runs) se **terminen autom√°ticamente**. Esto ahorra tiempo y recursos computacionales.

#### 1. `RandomParameterSampling`

Este objeto define el espacio de b√∫squeda de hiperpar√°metros. Al usar esta t√©cnica:

- Puedes pasar un diccionario `parameter_space` que define los rangos de valores posibles para cada hiperpar√°metro.
- Azure ML selecciona valores aleatorios de estos rangos.
- **Compatible con early termination**, es decir, puede trabajar con pol√≠ticas como BanditPolicy.

```python
from azure.ai.ml.sweep import RandomParameterSampling
param_sampling = RandomParameterSampling({
    "learning_rate": uniform(0.01, 0.1),
    "batch_size": choice(16, 32, 64)
})
```	

#### 2. BanditPolicy
Esta pol√≠tica de terminaci√≥n anticipada revisa peri√≥dicamente los experimentos en ejecuci√≥n. Si el rendimiento de uno de ellos es mucho menor que el mejor hasta ahora (seg√∫n un slack factor definido), se cancela autom√°ticamente.

Eval√∫a cada evaluation_interval pasos.

Puedes establecer slack_factor o slack_amount como tolerancia.

Ayuda a ahorrar recursos descartando entrenamientos que van mal desde el principio.

```python
from azure.ai.ml.sweep import BanditPolicy
early_termination_policy = BanditPolicy(
    evaluation_interval=2,
    slack_factor=0.2
)
```

### Opciones incorrectas
‚ùå Bayesian sampling: es √∫til para seleccionar hiperpar√°metros basados en ejecuciones anteriores, pero no soporta early termination.

‚ùå PipelineParameter: se usa para definir par√°metros reutilizables al publicar un pipeline, no tiene relaci√≥n con la cancelaci√≥n autom√°tica de experimentos.


## Pregunta 117- Efecto del bot√≥n Publish en Azure ML Designer

**Contexto:**  
Has creado un modelo de Machine Learning (ML) usando Azure ML Designer. Despu√©s de entrenar el modelo, haces clic en el bot√≥n **Publish** desde el canvas del dise√±ador, seleccionas la opci√≥n "Create new", y haces clic en Publish.

Tu objetivo es entender qu√© efecto tiene la acci√≥n de "publicar" en el servicio de Azure ML.

---

### Opciones m√∫ltiples

1. **The Publish button will deploy the model as a web service endpoint.**  
   ‚õî **No**

2. **The Publish button publishes the pipeline with a REST endpoint.**  
   ‚úÖ **S√≠**

3. **The Publish button runs the pipeline against the test data provided.**  
   ‚õî **No**

---

### Respuesta correcta

- ‚úÖ **The Publish button publishes the pipeline with a REST endpoint.**
- ‚ùå **The Publish button will deploy the model as a web service endpoint.**
- ‚ùå **The Publish button runs the pipeline against the test data provided.**

---

### Explicaci√≥n detallada

El bot√≥n **Publish** en Azure ML Designer no despliega el modelo como un servicio web (web service endpoint). Para realizar ese tipo de despliegue, debes ir al men√∫ **Models** en Azure ML Studio, seleccionar el modelo entrenado, y usar el bot√≥n **Deploy** para convertirlo en un endpoint de inferencia real.

Sin embargo, cuando haces clic en **Publish** en el dise√±ador, lo que realmente sucede es que se genera un **endpoint REST del pipeline**, lo cual permite a otros usuarios o servicios llamar ese pipeline mediante una solicitud HTTP. Este endpoint est√° protegido por autenticaci√≥n mediante clave.

Adem√°s, el bot√≥n **Publish** **no ejecuta** el pipeline con los datos de prueba proporcionados. Para ejecutar el pipeline contra esos datos, debes hacer clic en el bot√≥n **Submit** en el canvas del dise√±ador.

---

### Recursos recomendados

- [Microsoft Learn - Deploy and Publish Pipelines](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-register-publish-pipelines)
- [Azure ML Designer documentation](https://learn.microsoft.com/en-us/azure/machine-learning/concept-designer)

## ‚ùì Pregunta 118 de examen DP-100 (SDK v2)  
**Contexto:**  
Est√°s configurando un experimento de *AutoML* usando el **Azure Machine Learning Python SDK v2** para entrenar un modelo de clasificaci√≥n.

El c√≥digo presentado define lo siguiente:

```python
classification_job = automl.classification(
    compute=my_compute_name,
    experiment_name=my_exp_name,
    training_data=my_training_data_input,
    target_column_name="y",
    primary_metric="accuracy",
    n_cross_validations=7,
    enable_model_explainability=True,
    tags={"my_custom_tag": "My custom value"}
)

classification_job.set_limits(
    timeout_minutes=900,
    trial_timeout_minutes=30,
    max_trials=7,
    enable_early_termination=True,
)

classification_job.set_training(
    blocked_training_algorithms=["LogisticRegression"],
    enable_onnx_compatible_models=True
)
```	
### ‚úÖ Selecciona S√≠ si la afirmaci√≥n es verdadera, de lo contrario No.

| Afirmaci√≥n | Detalle |
|------------|---------|
| AutoML optimizar√° para accuracy | Enfoque principal en la m√©trica de precisi√≥n |
| max_trials tiene valor por defecto 500 y no es configurable | L√≠mite fijo de 500 iteraciones |
| La ejecuci√≥n se detendr√° si no hay mejora a corto plazo | Mecanismo de early stopping implementado |


### ‚úÖ Respuesta Correcta:
AutoML will optimize for accuracy: ‚úîÔ∏è Verdadero
Se est√° utilizando el par√°metro primary_metric="accuracy" que indica que el objetivo de optimizaci√≥n del AutoML ser√° la precisi√≥n del modelo.

The max_trials value is set to default 500 trials and cannot be customized: ‚ùå Falso
El valor por defecto es 1000 si no se especifica, pero en este caso el c√≥digo s√≠ define max_trials=7, lo que significa que el valor s√≠ se puede personalizar.

The run will be terminated if the score fails to improve in the short term: ‚úîÔ∏è Verdadero
La l√≠nea enable_early_termination=True dentro de set_limits indica que Azure AutoML terminar√° anticipadamente las ejecuciones que no muestren mejoras en el rendimiento.

üìö Explicaci√≥n extendida
primary_metric define el criterio por el cual se seleccionar√° el mejor modelo entrenado. En este caso es "accuracy".

max_trials es el n√∫mero m√°ximo de combinaciones de algoritmos e hiperpar√°metros que AutoML intentar√° durante el proceso. Puede ser definido manualmente como en este ejemplo.

enable_early_termination activa la pol√≠tica de terminaci√≥n anticipada, la cual detiene ejecuciones que no son prometedoras para ahorrar tiempo y recursos.

## ‚ùì Pregunta 119

You use the Azure Machine Learning SDK to create an automated machine learning pipeline. Your source data contains salary information, and some values may be missing.

You need to ensure the pipeline can load your data and run without errors.

**Which two actions should you perform?** Each correct answer presents part of the solution.

---

### üîò Opciones m√∫ltiples:

- [x] **Create a MLTable.**  
- [x] **Set the featurization experiment parameter to auto.**  
- [ ] Create a FileDataset.  
- [ ] Configure a local compute target.  
- [ ] Store source data files in the ./logs directory.

---

### ‚úÖ Respuesta correcta

- **Create a MLTable.**
- **Set the featurization experiment parameter to auto.**

---

### üß† Explicaci√≥n

Para que AutoML en Azure Machine Learning SDK v2 pueda cargar los datos correctamente y manejar valores faltantes:

1. **MLTable**:  
   Es el formato requerido en SDK v2 para representar datos tabulares. Un `MLTable` es una abstracci√≥n sobre archivos tabulares (por ejemplo, CSVs) y permite definir esquemas, particiones, y transformaciones.

2. **Featurization = "auto"**:  
   Establecer este par√°metro permite que el sistema se encargue autom√°ticamente del preprocesamiento de los datos, incluyendo imputaci√≥n de valores faltantes, codificaci√≥n de variables categ√≥ricas, normalizaci√≥n, etc.

---

### üîç Por qu√© las otras opciones son incorrectas:

- ‚ùå **Create a FileDataset**:  
  Este es un enfoque del SDK v1. En el SDK v2 se utiliza `MLTable` para datos tabulares.

- ‚ùå **Configure a local compute target**:  
  AutoML pipelines deben ejecutarse en targets remotos, no en locales.

- ‚ùå **Store source data files in the ./logs directory**:  
  `./logs` est√° reservado para logs de salida, no para archivos de entrada.

---

### üß™ Referencia oficial

> - [MLTable documentation ‚Äì Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-mltable)
> - [Featurization in AutoML ‚Äì Microsoft Learn](https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml#data-preprocessing)
>
### Pregunta 120

**Contexto:**

Usas Azure Machine Learning Studio para administrar los objetivos de c√≥mputo.  
Necesitas crear el objetivo de c√≥mputo apropiado para distintas tareas de aprendizaje autom√°tico.

Selecciona el objetivo de c√≥mputo correcto para cada tarea desde los men√∫s desplegables.

---

#### Machine Learning tasks y Compute targets:

| Machine Learning Task                                                                 | Compute Target         |
|----------------------------------------------------------------------------------------|------------------------|
| Deploy trained models to provide real-time predictive services at scale.              | Inference clusters     |
| Support scalable, on-demand processing using low-priority VMs.                        | Compute clusters       |
| Use Azure Databrick clusters.                                                         | Attached compute       |

---

### ‚úÖ Respuesta correcta:

- **Inference clusters** para *real-time predictive services at scale*.
- **Compute clusters** para *low-priority VMs*.
- **Attached compute** para *Azure Databricks clusters*.

---

### üìò Explicaci√≥n detallada:

- **Inference Clusters (AKS)**: Son usados para desplegar modelos entrenados que entregan predicciones en tiempo real. Estos cl√∫steres est√°n basados en Azure Kubernetes Service (AKS), dise√±ados para manejar servicios de inferencia escalables con alta disponibilidad.

- **Compute Clusters**: Soportan procesamiento bajo demanda y escalable. Pueden utilizarse nodos de baja prioridad (low-priority VMs), lo cual ayuda a reducir costos. No son adecuados para inferencia en tiempo real porque no garantizan disponibilidad constante.

- **Attached Compute (Azure Databricks)**: Se utiliza para conectar recursos de c√≥mputo en la nube como m√°quinas virtuales o clusters de Azure Databricks. Databricks es una plataforma basada en Apache Spark y es √∫til para pipelines de ML colaborativos o para tareas intensivas en datos.

---

### üîó Referencias oficiales:

- [What is Azure Kubernetes Service (AKS)?](https://learn.microsoft.com/en-us/azure/aks/intro-kubernetes)
- [Create and manage compute targets in Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-attach-compute-cluster)
- [Use Azure Databricks with Azure Machine Learning](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-databricks)

## Pregunta 121: Selecci√≥n del target de c√≥mputo √≥ptimo

**Contexto:**  
Eres responsable de entrenar modelos de *machine learning (ML)* para tu organizaci√≥n. Tienes diferentes requerimientos para entrenar y evaluar modelos, y necesitas seleccionar el recurso de c√≥mputo m√°s adecuado con la m√≠nima configuraci√≥n posible.

### ¬øQu√© recurso de c√≥mputo deber√≠as seleccionar para cada requerimiento?

Arrastra el recurso apropiado al requerimiento correspondiente. Un recurso puede usarse una o varias veces o no ser usado.

---

### Opciones disponibles:
- **Azure ML compute cluster**
- **Azure HDInsight**
- **Remote VM**

---

### Requerimientos y respuestas correctas:

NOTA: Esta pregunta es un drag and drop. Las opciones en las casillas son las correctas que arratra el usuario. A manera de ejemplo coloqu√© de una las respuestas correcctas en sus correspondientes casillas. 

| Requerimiento                                                                 | Recurso de c√≥mputo correcto     |
|------------------------------------------------------------------------------|----------------------------------|
| Tune hyperparameters using Azure Machine Learning designer                   | ‚úÖ Azure ML compute cluster       |
| Use your own virtual machine, attached to your virtual network, for hyperparameter tuning | ‚úÖ Remote VM                     |
| Use Apache Spark to train your model                                         | ‚úÖ Azure HDInsight                |
| Auto scale instances for models based on compute requirements                | ‚úÖ Azure ML compute cluster       |

---

### Explicaci√≥n:

1. **Azure ML compute cluster**  
   Es el √∫nico recurso de c√≥mputo soportado por el dise√±ador de Azure Machine Learning para tareas de *Automated ML* como el ajuste de hiperpar√°metros. Tambi√©n permite *autoescalado*, ajustando el n√∫mero de nodos autom√°ticamente seg√∫n la carga de trabajo.

2. **Remote VM**  
   Se selecciona cuando deseas usar tu propia m√°quina virtual dentro de una red virtual. Azure ML permite conectar VMs existentes para tareas espec√≠ficas, como entrenamientos que dependen de entornos personalizados como Conda.

3. **Azure HDInsight**  
   Es una plataforma preconfigurada basada en Apache Spark. Se utiliza cuando quieres entrenar modelos sobre Spark, aprovechando su procesamiento distribuido para grandes vol√∫menes de datos.

---

## Pregunta 122: Ver resultados de entrenamiento en Azure Machine Learning Studio

**Contexto:**  
Est√°s usando el Azure Machine Learning SDK (Python SDK v1) dentro de un notebook en Azure Machine Learning Studio. Creaste un trabajo de aprendizaje autom√°tico llamado `job_1`, cargaste datos y entrenaste un modelo.

### Objetivo:
Necesitas visualizar los resultados del entrenamiento en **Azure Machine Learning Studio**.

---

### ¬øQu√© deber√≠as hacer?

#### Opciones:

- ‚úÖ **A.** Call the `create_or_update` method. Specify the variable for the job.  
- ‚≠ï **B.** Call the `mlflow.sklearn.autolog` method.  
- ‚≠ï **C.** Call the `complete` method from the `Run` class. Set the status to True.  
- ‚≠ï **D.** Call the `run.upload_file` method. Specify the model name and path.

---

### ‚úÖ Respuesta correcta:
**A. Call the `create_or_update` method. Specify the variable for the job.**

---

### üìò Explicaci√≥n:

Para que un trabajo de entrenamiento se registre y pueda ser visualizado en **Azure Machine Learning Studio**, es necesario enviarlo al servicio utilizando el m√©todo:

```python
ml_client.jobs.create_or_update(job_1)
```
Este m√©todo registra el trabajo en Azure, lo env√≠a a ejecuci√≥n (si a√∫n no se ha ejecutado) y permite que sus resultados est√©n disponibles en el portal de Azure ML Studio. Solo al realizar este paso, los detalles del entrenamiento ‚Äîcomo m√©tricas, artefactos, logs‚Äî estar√°n disponibles en la interfaz gr√°fica.

### ‚ùå Opciones incorrectas:
B. mlflow.sklearn.autolog: Activa el registro autom√°tico de m√©tricas y par√°metros de entrenamiento con MLflow, pero no publica ni lanza el trabajo.

C. run.complete(): En el SDK v1 este m√©todo marca un trabajo como completado, pero no aplica para registrar un trabajo en Azure desde un notebook.

D. run.upload_file(): Sirve para cargar archivos como artefactos del experimento, pero no lanza ni registra el trabajo

### üîÅ Notas adicionales:
Aunque se mencionen m√©todos como run.complete() y run.upload_file(), en este contexto lo relevante es registrar y enviar el trabajo al servicio, lo cual se logra con create_or_update.


## Question 123: Monitor pipeline execution using Azure Application Insights

You are working on a machine learning project and you want to log the performance of your pipelines to monitor and troubleshoot issues. You have set up **Azure Application Insights** and you want to use it to log your pipeline runs.

You need to use a solution that can log the execution of the pipelines and capture the following information:

- Start time of the pipeline  
- End time of the pipeline  
- Execution duration  
- Status of the pipeline (succeeded, failed, canceled)  

The solution must ensure effort is kept to a minimum and is optimal in terms of **scalability**, **maintainability**, and **flexibility**.

### Which solution should you use?

#### Options:
- [ ] Custom code  
- [ ] Azure Monitor  
- [ ] Azure portal  
- [ ] Azure Storage  

---

### ‚úÖ Correct answer:
- [x] **Custom code**

---

### ‚úî Explanation:

To log execution details like start time, end time, duration, and status of the pipeline directly to **Azure Application Insights**, the most effective solution is to write **custom code**. This provides full control and flexibility to log exactly what you need.

Using custom code:
- You can capture events such as `start`, `end`, and compute `duration`.
- You can log the `status` of the pipeline using values like `"succeeded"`, `"failed"` or `"canceled"`.
- You can send all these logs directly to **Application Insights** using its API, and later review them through the Azure Portal or programmatically.

> ‚úÖ This approach is **scalable**, **maintainable**, and **adaptable** to different technologies (Python, .NET, Node.js, etc.).

---

### ‚ùå Why not the others?

- **Azure Monitor**: Although it's a powerful tool for monitoring Azure resources, it does **not** directly support custom pipeline execution tracking unless paired with custom logging code.

- **Azure portal**: Only allows viewing existing logs; it does not provide logging capabilities by itself.

- **Azure Storage**: Can store files and data, but it‚Äôs not a logging framework. It lacks the integration and ease of querying that Application Insights offers.

---

### üß† Pro Tip:
If you're using Azure ML SDK (v1 or v2), integrate **custom logging** inside your pipeline components or orchestrators to send tracking data to Application Insights for effective observability.

---

### Pregunta 124

**Scenario**:  
You use Azure Blob Storage as input to train a machine learning model.  
You need to ensure that files can be passed between pipeline components using a named datastore.  
Which three actions should you perform in sequence?  

**Answer Type**: Ordered List (Sequence)

---

### ‚úÖ Respuesta correcta:

1. **Define new components.**  
2. **Load new components.**  
3. **Build the pipeline.**

---

### ‚ùå Opciones no seleccionadas:

- Retrieve the default datastore from the current workspace.  
- Register a new dataset version for each pipeline pass.

---

### üß† Explicaci√≥n:

Azure ML pipelines use **components** to encapsulate functional steps such as data prep, training, and evaluation. Each component must be defined, loaded, and assembled into a pipeline.

1. **Define new components**:  
   You must define each component using either the `@command_component` decorator in Python or via a YAML specification. This step captures interface metadata, input/output types, and environment details.

2. **Load new components**:  
   After defining components, you load them for use in a pipeline. If you're using YAML, the `load_component()` function helps bring them into your code environment.

3. **Build the pipeline**:  
   Once all components are ready, you define the workflow by wiring components together through inputs and outputs. You also assign a compute target and submit the pipeline for execution.

---

### üìù Por qu√© las otras opciones son incorrectas:

- **Retrieve the default datastore from the current workspace**:  
  Although retrieving datastores is part of dataset handling, it is not required for setting up pipeline steps. If necessary, this action would occur earlier in data registration‚Äînot in pipeline construction.

- **Register a new dataset version for each pipeline pass**:  
  Azure ML supports dataset versioning for reusability, but this is **not mandatory** for each pipeline run and is unrelated to pipeline component construction.

---

### üîó Referencia oficial:
[Create and manage pipelines using Azure ML SDK v2](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-component-pipelines-sdk-v2)

---

## Pregunta 125: Crear un Azure Machine Learning Workspace usando recursos existentes

**Escenario:**  
Trabajas para una empresa de consultor√≠a de TI. Tu cliente tiene una suscripci√≥n de Azure con los siguientes recursos en el grupo de recursos `mlResources`:

- Azure Storage Account: `mlStorage`
- Azure Application Insights: `mlAppInsights`
- Azure Key Vault: `mlKeyVault`
- Azure Container Registry: `mlACR`

Se te ha pedido crear un **script que use estos recursos existentes** para crear un workspace llamado `mlWorkspace`.

---

### ‚úÖ Completaci√≥n correcta del c√≥digo:

```bash
workspaceName="mlWorkspace"

storageId=$(az storage account show --name "mlStorage" --query "id")
appInsightsId=$(az monitor app-insights component show \
  --app "mlAppInsights" \
  -g "mlResources" --query "id")
keyVaultId=$(az keyvault show --name "mlKeyVault" --query "id")
acrId=$(az acr show --name "mlACR" -g "mlResources" --query "id")

az ml workspace create \
  -w $workspaceName \
  -g mlResources \
  --container-registry $acrId \
  --storage-account $storageId \
  --application-insights $appInsightsId \
  --keyvault $keyVaultId
```
### Explicaci√≥n paso a paso:
1. Declarar el nombre del workspace

```bash
workspaceName="mlWorkspace"
```

Esto guarda el nombre del nuevo workspace que quieres crear en una variable.

### 2. Recuperar los IDs de los recursos existentes
Usamos az CLI con --query "id" para extraer el identificador √∫nico de cada recurso:

```bash
az storage account show --name "mlStorage" --query "id"
az monitor app-insights component show --app "mlAppInsights" -g "mlResources" --query "id"
az keyvault show --name "mlKeyVault" --query "id"
az acr show --name "mlACR" -g "mlResources" --query "id"
```

### 3. Crear el workspace con los recursos especificados
La instrucci√≥n az ml workspace create con los par√°metros adecuados enlaza todos los recursos existentes al nuevo workspace:

```bash
az ml workspace create -w $workspaceName -g mlResources ...
```
### üõë Opciones incorrectas:
ml environment: se usa para manejar entornos de ejecuci√≥n, no workspaces.

ml service: se refiere a servicios publicados, no workspaces.

workspace (sin ml): gestiona Log Analytics, no Azure ML.

list o update: son comandos para ver o modificar workspaces existentes, no para crear uno nuevo.

\$mlWorkspace: es solo el nombre, no es una variable v√°lida en este contexto, a diferencia de   \$workspaceName.


## Pregunta 126: Configurar cl√∫ster para minimizar costo durante el tiempo inactivo

**Escenario:**

Quieres reducir el costo de los cl√∫steres de c√≥mputo de entrenamiento en Azure Machine Learning. El entrenamiento se realiza de forma intermitente sobre archivos de texto y el tiempo de ejecuci√≥n no es un factor importante. Se utiliza una m√°quina virtual de tipo `Standard_D1`.

**Objetivo:**

Configurar el cl√∫ster para minimizar los costos cuando est√© inactivo.

---

### ‚úÖ Respuesta correcta:

| Configuraci√≥n              | Valor seleccionado             |
|---------------------------|--------------------------------|
| Virtual machine type       | CPU (Central Processing Unit)  |
| Virtual machine priority   | Low priority                   |
| Minimum number of nodes    | 0                              |

---

### üß† Explicaci√≥n:

- **CPU (Central Processing Unit):**
  - Ideal para procesamiento de texto.
  - Mucho m√°s econ√≥mico que una GPU.
  - No es necesario el poder gr√°fico de una GPU para esta tarea.

- **Low priority:**
  - Usa capacidad libre (preemptible VMs) en Azure a un costo significativamente menor.
  - Puede ser interrumpido por Azure si se requiere para otros clientes, pero es ideal cuando el tiempo de ejecuci√≥n no es cr√≠tico.

- **Minimum number of nodes = 0:**
  - Asegura que no se mantenga ning√∫n nodo activo cuando no hay tareas en ejecuci√≥n.
  - Esto elimina los costos asociados al tiempo ocioso.

---

### ‚ùå Opciones incorrectas:

| Opci√≥n                    | Raz√≥n por la que es incorrecta |
|--------------------------|--------------------------------|
| GPU                      | Costosa y no necesaria para texto. |
| Dedicated                | Mayor costo, menor ahorro.       |
| Minimum number of nodes > 0 | Mantiene nodos activos todo el tiempo, generando costos innecesarios. |

---

### üìò Referencia oficial:

- [Azure Machine Learning compute targets](https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target)
- [Create and manage Azure Machine Learning compute clusters](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-attach-compute-cluster?tabs=python)

## Pregunta 127: Crear un dataset .csv en ADLS Gen2 usando Azure ML SDK v2

Est√°s utilizando Azure Machine Learning Python Software Development Kit (SDK) v2 para crear y administrar data assets.

Deseas evitar la necesidad de recordar largas URIs de almacenamiento.  
Debes crear un dataset en formato .csv en ADLS Gen2.  

¬øC√≥mo deber√≠as completar el siguiente c√≥digo?

---

#### C√≥digo Base

```python
from azure.ai.ml.entities import Data
from azure.ai.ml.constants import AssetTypes

my_path = '<Selecciona aqu√≠>'
my_data = Data(
    path=my_path,
    type=AssetTypes.<Selecciona aqu√≠>,
    description="<description>",
    name="<name>",
    version="<version>"
)
ml_client.<Selecciona aqu√≠>.create_or_update(my_data)
```

#### Opciones:

**Para my_path:**
azureml://datastores/<data_store_name>/paths/<path>

abfss://<file_system>@<account_name>.dfs.core.windows.net/<path>

wasbs://<containername>@<accountname>.blob.core.windows.net/<path_to_data>/

./home/username/data/my_data

**Para type:**
URI_FILE

URI_FOLDER

MLTABLE

**Para ml_client.<...>:**
connections

data

datastores

registries

### ‚úÖ Respuesta Correcta:

```python	
my_path = 'abfss://<file_system>@<account_name>.dfs.core.windows.net/<path>'
my_data = Data(
    path=my_path,
    type=AssetTypes.URI_FILE,
    description="<description>",
    name="<name>",
    version="<version>"
)
ml_client.data.create_or_update(my_data)
```
### Explicaci√≥n:

abfss://... es el esquema correcto para trabajar con Azure Data Lake Storage Gen2, ya que habilita seguridad TLS por defecto.

AssetTypes.URI_FILE se usa cuando el archivo es individual (como un .csv).

ml_client.data es el atributo adecuado para operaciones relacionadas con Data (crear, actualizar, etc.).

### ‚ùå Opciones incorrectas:
azureml://datastores/... apunta a un DataStore, no directamente a ADLS Gen2.

wasbs://... corresponde a Azure Blob Storage con el driver WASB (legacy).

registries, connections, datastores no se usan para registrar assets de tipo Data.

## Pregunta 128: Publicar un pipeline con par√°metros en Azure Machine Learning (SDK v2)

Usas Azure Machine Learning para crear un pipeline de machine learning.  
Una vez completado, necesitas asegurarte de que otros usuarios puedan ejecutarlo con un valor personalizado de entrada.

---

#### ¬øCu√°les son las **cuatro acciones** que debes realizar en orden?

> Arrastra las acciones correctas a la lista de la derecha y ord√©nalas correctamente.

---

#### Opciones disponibles:

- Define a `PipelineParameter` object.
- Specify a default pipeline parameter value.
- Add the `PipelineParameter` object as a script argument.
- Use the `publish_pipeline` method to publish the pipeline.
- Save the pipeline to a YAML file.

---

#### Respuesta correcta (ordenada):

1. **Define a `PipelineParameter` object.**  
   Crea un par√°metro reutilizable usando `PipelineParameter`, permitiendo valores din√°micos al ejecutar el pipeline.

2. **Specify a default pipeline parameter value.**  
   Define el valor por defecto del par√°metro que se usar√° si el usuario no lo especifica al ejecutar.

3. **Add the `PipelineParameter` object as a script argument.**  
   Asocia el par√°metro como argumento de entrada del componente del pipeline (`command()` o `pipeline()`).

4. **Use the `publish_pipeline` method to publish the pipeline.**  
   Publica el pipeline en Azure ML, creando un endpoint REST que otros usuarios pueden utilizar.

---

### Explicaci√≥n enriquecida

En Azure ML SDK v2:

- El uso de `PipelineParameter` permite definir par√°metros de entrada reutilizables que se pueden pasar din√°micamente al ejecutar el pipeline.
- Publicar el pipeline lo expone como un recurso accesible a otros usuarios de forma program√°tica o v√≠a interfaz.
- La serializaci√≥n a YAML (`save_to_yaml()`) es √∫til para exportaci√≥n/interoperabilidad, **pero no es necesaria ni recomendada para publicaci√≥n** en este contexto.

üîÅ **Ejemplo de c√≥digo simplificado** (SDK v2):

```python
from azure.ai.ml import command, Input
from azure.ai.ml.dsl import pipeline
from azure.ai.ml.entities import PipelineJob
from azure.ai.ml.entities._job.pipeline._io import PipelineInput

# Paso 1: Definir par√°metro
data_param = PipelineInput(name="input_data", default=Input(type="uri_file"))

# Paso 2: Usar par√°metro en el pipeline
@pipeline()
def my_pipeline(input_data):
    train_step = command(
        inputs={"data": input_data},
        ...
    )
    return train_step.outputs

job = my_pipeline(input_data=data_param)

# Paso 3: Publicar pipeline
job.name = "my_pipeline"
job.description = "Pipeline con par√°metro"
published_pipeline = ml_client.jobs.create_or_update(job)
```

### üß† DP-100 ‚Äî Mimic Explainer for Black Box Models

**Question:**  
You use Azure Machine Learning as part of a project that will evaluate a black box machine learning model.  
You need to ensure that the mimic explainer interpretability technique can be used to evaluate the black box model.  

**What should you do first?**

---

#### üü¶ Options:
- [x] **Train a global surrogate model.**
- [ ] Configure Permutation Feature Importance Explainer (PFI).
- [ ] Create a multi-label image classification project.
- [ ] Implement Shapley Additive Explanations (SHAP) linear explainer.

---

### ‚úÖ Correct Answer:
**Train a global surrogate model.**

---

### üìò Explanation:

A **global surrogate model** is an interpretable model trained to approximate the predictions of a more complex, opaque (black box) model. This approximation makes it possible to analyze and interpret how the black box model works, even when its internal logic isn't directly accessible. Once this surrogate is trained, the **mimic explainer** technique can be applied on it to extract insights.

Azure Machine Learning supports this approach as part of its interpretability capabilities.

---

### ‚ùå Incorrect Options Breakdown:

- **Permutation Feature Importance (PFI):**  
  PFI is used to determine the impact of each feature by shuffling feature values and observing changes in model performance. It's not the first step for applying mimic explainers and doesn‚Äôt create a surrogate model.

- **SHAP Linear Explainer:**  
  SHAP explainers are tailored for specific types of models. The **linear explainer** only works with linear models and is not suitable for black-box models unless they're linear, which contradicts the question‚Äôs premise.

- **Multi-label image classification project:**  
  This refers to a specific modeling task unrelated to model interpretability. It‚Äôs not required for mimic explanation and is out of context.

---

### üìö References:
- [Interpret ML in Azure](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability)
- [Mimic Explainer](https://learn.microsoft.com/en-us/python/api/azureml-interpret/azureml.interpret.explanation.explainermodel?view=azure-ml-py)


## üß† Pregunta 130: Despliegue de pipeline como servicio web

**Contexto:**  
Usas Azure Machine Learning Designer para crear un pipeline de inferencia y entrenar un modelo predictivo. Ahora necesitas desplegar tu pipeline como un servicio web.

**Pregunta:**  
¬øCu√°les tres acciones debes realizar en orden secuencial para cumplir este objetivo?

### üîò Opciones posibles:
- Convert the training pipeline into a real-time inference pipeline  
- Submit a real-time inference pipeline job  
- Deploy a real-time endpoint  
- Set the pipeline as the default for the endpoint

---

## ‚úÖ Respuesta correcta (en orden):

1. **Convert the training pipeline into a real-time inference pipeline**  
2. **Submit a real-time inference pipeline job**  
3. **Deploy a real-time endpoint**

---

## üìò Explicaci√≥n:

En Azure Machine Learning (AML), un pipeline de inferencia es utilizado para realizar predicciones en tiempo real, tambi√©n conocido como **model scoring**.

1. **Convertir a pipeline de inferencia en tiempo real**  
   Primero debes transformar el pipeline de entrenamiento en un pipeline de inferencia, lo cual a√±ade m√≥dulos como **Web Service Input** y **Web Service Output**. Esto lo convierte en un pipeline desplegable.

2. **Enviar un trabajo de inferencia en tiempo real**  
   Antes de poder desplegar el pipeline, debes ejecutarlo al menos una vez. Esto valida el pipeline y genera los artefactos necesarios para el despliegue.

3. **Desplegar el endpoint en tiempo real**  
   Finalmente, creas un endpoint en tiempo real. Este endpoint act√∫a como un puerto de acceso a tu modelo para servicios externos a trav√©s de una **REST API**.

> üí° **Importante:** El despliegue de endpoints en tiempo real requiere un cl√∫ster de inferencia basado en AKS. Si no existe, deber√°s crear uno previamente.

---

## üîó Referencias √∫tiles:

- [Deploy and score a machine learning pipeline](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-pipeline?tabs=designer)
- [Deploy a real-time inference pipeline using Azure ML Designer](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-inference-pipeline-designer)

## Pregunta 131

**Contexto:**  
You are determining the type of sampling to use for tuning hyperparameters for your experiment.  
You need to use the sampling methods that will let you associate an early termination policy.  
You want to reduce the tuning effort involved with configuring various hyperparameters.

**Pregunta:**  
Which two sampling methods can you use to meet the goal?  
Each correct answer presents a complete solution.

---

### Opciones:

- [x] Random  
- [x] Grid  
- [ ] Bayesian

---

### Respuesta correcta:

- ‚úÖ Random  
- ‚úÖ Grid

---

### Explicaci√≥n:

En Azure Machine Learning, puedes usar una **early termination policy** (pol√≠tica de terminaci√≥n temprana) para evitar gastar recursos innecesarios en ejecuciones que claramente no producir√°n buenos resultados. Sin embargo, **no todos los m√©todos de muestreo** permiten asociar este tipo de pol√≠tica.

#### M√©todos compatibles con early termination:

- **Random sampling**  
  Permite seleccionar valores aleatorios dentro de los rangos definidos. Es compatible con pol√≠ticas de terminaci√≥n temprana.

- **Grid sampling**  
  Eval√∫a todas las combinaciones posibles de hiperpar√°metros definidos. Tambi√©n es compatible con pol√≠ticas de terminaci√≥n temprana.

#### M√©todo no compatible:

- **Bayesian sampling**  
  Construye un modelo probabil√≠stico basado en ejecuciones anteriores. **No permite el uso de pol√≠ticas de early termination**, ya que necesita explorar el espacio de b√∫squeda de forma m√°s estructurada y dependiente de resultados previos.

---

### C√≥digo de ejemplo:

```python
from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy

param_sampling = RandomParameterSampling({
    'learning_rate': uniform(0.01, 0.1),
    'batch_size': choice(16, 32, 64)
})

early_termination_policy = BanditPolicy(
    slack_factor=0.2,
    evaluation_interval=1,
    delay_evaluation=5
)

# En cambio, para Bayesian:
from azureml.train.hyperdrive import BayesianParameterSampling

param_sampling = BayesianParameterSampling({
    'learning_rate': uniform(0.01, 0.1),
    'batch_size': choice(16, 32, 64)
})

# Nota: No se debe establecer una pol√≠tica de terminaci√≥n anticipada aqu√≠.
# early_termination_policy = None

```

## Pregunta 132: Monitoreo con MLflow

### Contexto
Has creado y entrenado un modelo de machine learning en un workspace de Azure Machine Learning. Planeas monitorear e interpretar las salidas del modelo tanto durante el proceso de entrenamiento como despu√©s de su finalizaci√≥n.

Necesitas usar MLflow para:
1. Guardar las salidas del modelo en el workspace durante el entrenamiento para monitorear su rendimiento
2. Acceder a las salidas del modelo despu√©s de que el entrenamiento haya finalizado

### Opciones disponibles

#### Para Requirement1 (Monitoreo durante entrenamiento):
- Model artifacts
- Parameters
- TensorBoard

#### Para Requirement2 (Acceso post-entrenamiento):
- MLflow Code Repository
- MLflow Model Metrics
- MLflow Model Deployment

### Respuesta Correcta Completa

| Requisito               | Funci√≥n de MLflow a utilizar | Justificaci√≥n |
|-------------------------|-----------------------------|---------------|
| Monitoreo durante entrenamiento | **Parameters** | Permite registrar y trackear hiperpar√°metros y m√©tricas en tiempo real durante el entrenamiento |
| Acceso post-entrenamiento | **MLflow Model Metrics** | Proporciona acceso hist√≥rico a todas las m√©tricas registradas durante y despu√©s del entrenamiento |

### Soluci√≥n Detallada

1. **Para el monitoreo durante el entrenamiento**:
   - Usar `Parameters` de MLflow es esencial porque:
     * Registra todos los hiperpar√°metros del modelo
     * Permite trackear m√©tricas de rendimiento en cada iteraci√≥n
     * Se integra directamente con el experiment tracking de Azure ML

2. **Para el acceso post-entrenamiento**:
   - `MLflow Model Metrics` es la opci√≥n correcta porque:
     * Almacena hist√≥ricamente todas las m√©tricas registradas
     * Permite comparar diferentes ejecuciones
     * Proporciona visualizaciones integradas en Azure ML Studio
     * Facilita el an√°lisis del rendimiento del modelo a lo largo del tiempo

Nota: TensorBoard ser√≠a una alternativa para visualizaci√≥n durante el entrenamiento, pero no cumple con el requisito de almacenamiento estructurado. MLflow Model Deployment se enfoca en implementaci√≥n, no en monitoreo.

## Pregunta 132 - MLflow features en SDK v2

### Enunciado

You have created and trained a machine learning model in an Azure Machine Learning workspace.  
You plan to monitor and interpret the model's outputs during the training process and after it has completed.

You need to use MLflow to:

1. Save the model‚Äôs outputs to an Azure Machine Learning workspace during training to monitor the model‚Äôs performance.
2. Access the model‚Äôs outputs after the training is finished.

Which MLflow feature should you use to fulfill the requirements?  
To answer, select the appropriate options from the drop-down menus.

---

### Opciones posibles

**Para Requirement 1:**

- Model artifacts  
- Parameters  
- TensorBoard

**Para Requirement 2:**

- MLflow Code Repository  
- MLflow Model Metrics  
- MLflow Model Deployment

---

### Respuestas correctas

| Requirement   | Feature                |
|---------------|------------------------|
| Requirement 1 | Model artifacts        |
| Requirement 2 | MLflow Model Metrics   |

---

### Explicaci√≥n

#### ‚úÖ Model artifacts

MLflow model artifacts are used to **save the model‚Äôs outputs during training**, including code and dependencies. These are stored in a defined location (e.g., Azure Blob Storage) and can be accessed to monitor training.

#### ‚úÖ MLflow Model Metrics

MLflow model metrics allow you to **access the model‚Äôs outputs after training**, such as loss, accuracy, etc., for evaluation and interpretation. These are stored in MLflow run logs.

#### ‚ùå TensorBoard

Es una herramienta de visualizaci√≥n, no dise√±ada para guardar salidas del modelo.

#### ‚ùå Parameters

Se usan para registrar hiperpar√°metros, pero no para guardar outputs del modelo.

#### ‚ùå MLflow Code Repository

Es para versionamiento de c√≥digo, no para outputs de modelo entrenado.

#### ‚ùå MLflow Model Deployment

Sirve para desplegar el modelo, no para consultar sus resultados.

---

### Pregunta 133

**Enunciado:**

You use Azure Machine Learning Python Software Development Kit (SDK) v2 to manage machine learning datastores.  
You create a service principal account in Azure AD and use it for authentication.  
You need to create an Azure Data Lake Gen2 datastore **synchronously**.

How should you complete the code?  
To answer, select the appropriate options from the drop-down menus.

---

**C√≥digo incompleto:**

```python
from azure.ai.ml.entities import AzureDataLakeGen2Datastore
from azure.ai.ml.entities._datastore.credentials import ServicePrincipalCredentials
from azure.ai.ml import MLClient

ml_client = MLClient.from_config()

store = AzureDataLakeGen2Datastore(
    name="an_example_of_adlsgen2",
    description="Datastore pointing to ADLS Gen2",
    account_name="testadlsgen2",
    filesystem="testadlsgen2container",
    credentials=ServicePrincipalCredentials(
        tenant_id="XXXXXXX-XXXX-XXXX-XXXX",
        client_id="XXXXXXX-XXXX-XXXX-XXXX",
        client_secret="XXXXXXXXXXXXXXXXXXXXX",
    ),
)

ml_client.‚¨áÔ∏è(‚¨áÔ∏è)
```	
### Opciones disponibles:

üîπ Primera lista desplegable (m√©todo a usar):

``begin_create_or_update``

``create_or_update``

``from_config``

üîπ Segunda lista desplegable (par√°metro que se pasa):

``store``

``workspace``

``config``

### ‚úÖ Respuesta correcta

M√©todo: `create_or_update`

Par√°metro: `store`

### Explicaci√≥n

Para crear un recurso de Azure de manera **sincr√≥nica** (como se pide en el enunciado), debes usar el m√©todo `create_or_update` de la clase `ml_client`.

store es el objeto de tipo AzureDataLakeGen2Datastore correctamente configurado.

No debes usar:

 * begin_create_or_update() ‚Üí es asincr√≥nico.

 * from_config() ‚Üí se usa para cargar configuraciones, no para registrar datastores.

 * workspace o config como par√°metro ‚Üí no son instancias del datastore a crear.


### Pregunta 135

You use Azure Machine Learning to train models to play video games.

To increase training performance, you need to ensure your training jobs can use multiple compute targets.

**What should you do?**

#### Opciones:
- [ ] Create a generic Estimator class object. Populate the compute_target parameter.
- [ ] Create a FileDataset. Download the dataset files to each compute target.
- [x] Specify a virtual network. Ensure that head and worker nodes can communicate with each other.
- [ ] Use the SKLearn class to create an Estimator. Use a script_params dictionary to pass parameters to the estimator.

---

### ‚úÖ Respuesta correcta:
**Specify a virtual network. Ensure that head and worker nodes can communicate with each other.**

### üí° Explicaci√≥n:
Para entrenar modelos de videojuegos, usualmente se usa aprendizaje por refuerzo, el cual es intensivo en c√≥mputo. Esto implica distribuir la tarea entre m√∫ltiples nodos de c√≥mputo, incluyendo un nodo "head" y varios "worker nodes".

Para que estos nodos puedan comunicarse adecuadamente durante el entrenamiento, debes especificar una red virtual (VNet) que permita el tr√°fico entre ellos sin restricciones de puertos.

- ‚ùå *FileDataset*: solo se usa para referenciar datos, no afecta la comunicaci√≥n entre nodos.
- ‚ùå *Generic Estimator o SKLearn Estimator*: no son adecuados aqu√≠ porque se centran en tareas de entrenamiento simples o mononodo, no distribuidas.

---

## Pregunta 136

You use Azure Machine Learning to train models on data collected from Internet of Things (IoT) devices.

You need to monitor and analyze drift in your data as new information is collected from your IoT devices.

**What should you do?**

---

### üîò Choose the correct answer

- ( ) Add logging functions to your pipeline with the Execute Python Script component.  
- ( ) Stream Azure Machine Learning metric information to Azure Event Hubs.  
- ( ) Use ScriptRunConfig to add logging functions to your training scripts.  
- (‚úÖ) Define a dataset monitor and configure a target dataset with a timeseries trait.

---

### ‚úÖ Respuesta correcta

**Define a dataset monitor and configure a target dataset with a timeseries trait.**

---

### üß† Explicaci√≥n

- **Data drift** es el fen√≥meno donde los datos usados para entrenar un modelo comienzan a diferir significativamente de los datos nuevos. Esto puede afectar negativamente el rendimiento del modelo si no se detecta y controla.

- **Dataset monitor** es una herramienta de Azure ML que permite monitorear cambios estad√≠sticos en los datos. Para configurarlo correctamente:
  - Se necesita un **baseline dataset** (normalmente el dataset original usado para entrenar el modelo).
  - Se necesita un **target dataset**, que debe tener el atributo de **timeseries trait** (columna de timestamp para detectar cambios a lo largo del tiempo).

- Una vez configurado el monitor, puedes ver los resultados del an√°lisis de drift en el portal de Azure ML.

---

### ‚ùå Opciones incorrectas

- **Execute Python Script component**: Este componente se usa en pipelines de Azure ML Designer para ejecutar c√≥digo Python. No sirve para an√°lisis de drift.
- **Azure Event Hubs**: Se usa para ingesta de eventos y datos en tiempo real, pero no es adecuado para monitorear drift de datos en modelos de ML.
- **ScriptRunConfig**: Esta clase se utiliza para configurar y lanzar entrenamientos, pero no est√° dise√±ada para monitorear datasets.

---

### üìö Referencias oficiales

- [Monitor data drift in datasets - Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-monitor-datasets)
- [Data drift and model monitoring overview](https://learn.microsoft.com/en-us/azure/machine-learning/concept-model-monitor)
